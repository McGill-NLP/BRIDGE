{"instance_id": "astropy__astropy-7671", "repo": "astropy/astropy", "estimated_minutes": 120.0, "justification": "The issue is well-reproduced and localized to version comparison logic in `astropy.utils.introspection.minversion`, but it requires some investigation to understand what changed in PR #7647 and how the previous regex workaround behaved. The fix itself is likely small (reintroducing a regex-based normalization of dev/pre-release strings before feeding into `LooseVersion`), but it must be done carefully to preserve compatibility across many version formats. Writing targeted regression tests for the failing cases (e.g., `1.14.3` vs `1.14dev`) and running the relevant test suite to ensure no regressions will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 25, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-reproduced and localized to version comparison logic in `astropy.utils.introspection.minversion`, but it requires some investigation to understand what changed in PR #7647 and how the previous regex workaround behaved. The fix itself is likely small (reintroducing a regex-based normalization of dev/pre-release strings before feeding into `LooseVersion`), but it must be done carefully to preserve compatibility across many version formats. Writing targeted regression tests for the failing cases (e.g., `1.14.3` vs `1.14dev`) and running the relevant test suite to ensure no regressions will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 25,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:26.511886"}
{"instance_id": "astropy__astropy-14365", "repo": "astropy/astropy", "estimated_minutes": 120.0, "justification": "The issue is well-scoped with a clear reproducer: the QDP command-parsing logic (likely a regex) is case-sensitive when it should not be. An experienced engineer will need moderate time to locate the relevant parser in astropy.io.ascii.qdp, implement a case-insensitive match without breaking existing command handling, and add a focused regression test. Running the relevant test suite and checking for any unintended parsing changes (e.g., mixed-case commands, whitespace variations) accounts for a significant portion of the total time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped with a clear reproducer: the QDP command-parsing logic (likely a regex) is case-sensitive when it should not be. An experienced engineer will need moderate time to locate the relevant parser in astropy.io.ascii.qdp, implement a case-insensitive match without breaking existing command handling, and add a focused regression test. Running the relevant test suite and checking for any unintended parsing changes (e.g., mixed-case commands, whitespace variations) accounts for a significant portion of the total time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:27.046994"}
{"instance_id": "astropy__astropy-13033", "repo": "astropy/astropy", "estimated_minutes": 110.0, "justification": "The issue is well-scoped with a clear reproduction and a pointer to the relevant lines in `astropy/timeseries/core.py`, but it still requires understanding how `TimeSeries` validates required columns and how column-removal interacts with that validation. The actual code change is small (adjusting the validation logic and error message to handle multiple required columns), but Astropy\u2019s conventions require adding/adjusting unit tests and ensuring no regressions in related `TimeSeries` behaviors. Time is also allocated for running targeted tests and possibly a small subset of the suite to confirm the change does not break other table/timeseries interactions.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 110,\n  \"justification\": \"The issue is well-scoped with a clear reproduction and a pointer to the relevant lines in `astropy/timeseries/core.py`, but it still requires understanding how `TimeSeries` validates required columns and how column-removal interacts with that validation. The actual code change is small (adjusting the validation logic and error message to handle multiple required columns), but Astropy\u2019s conventions require adding/adjusting unit tests and ensuring no regressions in related `TimeSeries` behaviors. Time is also allocated for running targeted tests and possibly a small subset of the suite to confirm the change does not break other table/timeseries interactions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:27.415615"}
{"instance_id": "astropy__astropy-14508", "repo": "astropy/astropy", "estimated_minutes": 150.0, "justification": "Although the code change is likely small (adjusting Card float formatting to prefer Python's shorter, round-trippable string form), it sits in a core FITS serialization path where subtle regressions are possible (e.g., exponent formatting, special values, and exact 80-column card layout constraints). An engineer will need time to inspect existing formatting logic, confirm FITS compliance implications, and ensure the change doesn\u2019t break other float edge cases. Adding focused regression tests (including the provided HIERARCH example and suggested boundary-float cases) and running the relevant astropy.io.fits test suite will take a significant portion of the effort.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the code change is likely small (adjusting Card float formatting to prefer Python's shorter, round-trippable string form), it sits in a core FITS serialization path where subtle regressions are possible (e.g., exponent formatting, special values, and exact 80-column card layout constraints). An engineer will need time to inspect existing formatting logic, confirm FITS compliance implications, and ensure the change doesn\u2019t break other float edge cases. Adding focused regression tests (including the provided HIERARCH example and suggested boundary-float cases) and running the relevant astropy.io.fits test suite will take a significant portion of the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:27.417937"}
{"instance_id": "astropy__astropy-14995", "repo": "astropy/astropy", "estimated_minutes": 120.0, "justification": "The issue is well-reproduced and the discussion already narrows the root cause to a small conditional change in NDDataRef mask propagation logic introduced in v5.3, so the code fix itself is likely small. However, an experienced engineer will still need time to locate the relevant arithmetic/mask-handling code path, confirm behavior for both boolean and integer/bitmask masks (including commutativity), and add regression tests to prevent reintroduction. Running and iterating on the nddata test suite (and possibly a broader subset) will dominate the effort to ensure no regressions in mask propagation semantics.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 20, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-reproduced and the discussion already narrows the root cause to a small conditional change in NDDataRef mask propagation logic introduced in v5.3, so the code fix itself is likely small. However, an experienced engineer will still need time to locate the relevant arithmetic/mask-handling code path, confirm behavior for both boolean and integer/bitmask masks (including commutativity), and add regression tests to prevent reintroduction. Running and iterating on the nddata test suite (and possibly a broader subset) will dominate the effort to ensure no regressions in mask propagation semantics.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 20,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:27.854038"}
{"instance_id": "astropy__astropy-14539", "repo": "astropy/astropy", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and includes a strong hint pointing to a specific conditional in `astropy/io/fits/diff.py` where `P` (VLA) is handled but `Q` is not, so the core code change is likely small. However, an engineer will still need to confirm the underlying failure mode for `Q`-format VLAs, ensure the fix is correct for both numeric and non-numeric VLAs, and add a regression test that fails before the change and passes after. Astropy\u2019s FITS diff behavior is subtle and test expectations need to be carefully written to avoid platform/endianness-related flakiness, which pushes most of the time into testing and verification.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 20, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and includes a strong hint pointing to a specific conditional in `astropy/io/fits/diff.py` where `P` (VLA) is handled but `Q` is not, so the core code change is likely small. However, an engineer will still need to confirm the underlying failure mode for `Q`-format VLAs, ensure the fix is correct for both numeric and non-numeric VLAs, and add a regression test that fails before the change and passes after. Astropy\u2019s FITS diff behavior is subtle and test expectations need to be carefully written to avoid platform/endianness-related flakiness, which pushes most of the time into testing and verification.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 20,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:27.984305"}
{"instance_id": "astropy__astropy-14309", "repo": "astropy/astropy", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and the traceback points to a specific identifier function (`astropy/io/fits/connect.py:is_fits`) incorrectly indexing `args[0]` when `identify_format` is invoked with an empty `args` tuple. An experienced engineer will still need to inspect the recent behavioral change referenced by the commit, confirm the expected semantics of format identifiers for the \"write\" path, and ensure the fix does not alter legitimate FITS detection. Adding a focused regression test and running the relevant I/O registry and FITS-related test suites will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 20, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and the traceback points to a specific identifier function (`astropy/io/fits/connect.py:is_fits`) incorrectly indexing `args[0]` when `identify_format` is invoked with an empty `args` tuple. An experienced engineer will still need to inspect the recent behavioral change referenced by the commit, confirm the expected semantics of format identifiers for the \\\"write\\\" path, and ensure the fix does not alter legitimate FITS detection. Adding a focused regression test and running the relevant I/O registry and FITS-related test suites will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 20,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:28.066097"}
{"instance_id": "astropy__astropy-7166", "repo": "astropy/astropy", "estimated_minutes": 150.0, "justification": "Fixing InheritDocstrings to support properties requires locating the metaclass implementation, understanding how it currently copies docstrings (likely only for functions via inspect.isfunction), and adjusting the logic to also cover properties/data descriptors while preserving existing behavior. Although the code change itself is probably small, validating the correct behavior needs targeted regression tests for overridden properties/methods with missing docstrings and ensuring no unintended effects on other descriptors or Sphinx/autodoc-related behavior.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing InheritDocstrings to support properties requires locating the metaclass implementation, understanding how it currently copies docstrings (likely only for functions via inspect.isfunction), and adjusting the logic to also cover properties/data descriptors while preserving existing behavior. Although the code change itself is probably small, validating the correct behavior needs targeted regression tests for overridden properties/methods with missing docstrings and ensuring no unintended effects on other descriptors or Sphinx/autodoc-related behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:28.132915"}
{"instance_id": "astropy__astropy-7336", "repo": "astropy/astropy", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and localized to the `units.quantity_input` decorator\u2019s return-annotation handling, but it requires some investigation to confirm how Astropy currently interprets return annotations and how signatures are wrapped (especially for methods like `__init__`). The actual code change is likely small (special-casing `None`/`NoneType` annotations and/or `None` return values), but care is needed to avoid changing behavior for valid Quantity-returning functions. Proper regression tests should cover constructors and potentially other functions with `-> None`, and verification requires running the relevant Astropy unit test suite segments.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and localized to the `units.quantity_input` decorator\u2019s return-annotation handling, but it requires some investigation to confirm how Astropy currently interprets return annotations and how signatures are wrapped (especially for methods like `__init__`). The actual code change is likely small (special-casing `None`/`NoneType` annotations and/or `None` return values), but care is needed to avoid changing behavior for valid Quantity-returning functions. Proper regression tests should cover constructors and potentially other functions with `-> None`, and verification requires running the relevant Astropy unit test suite segments.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:28.428821"}
{"instance_id": "astropy__astropy-13453", "repo": "astropy/astropy", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and already narrowed down to the HTML ASCII writer code path, but an engineer will still need to understand how `formats` is propagated through `astropy.io.ascii` and why HTML bypasses the shared formatting machinery. The fix itself is likely small (setting per-column `info.format` from `self.data.formats` or invoking the appropriate helper), but care is needed to match existing conventions and avoid breaking other HTML writer behaviors. Proper regression tests are required to assert both string format specifications and callable formatters work for HTML output and to ensure no unintended changes in existing HTML writer tests.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and already narrowed down to the HTML ASCII writer code path, but an engineer will still need to understand how `formats` is propagated through `astropy.io.ascii` and why HTML bypasses the shared formatting machinery. The fix itself is likely small (setting per-column `info.format` from `self.data.formats` or invoking the appropriate helper), but care is needed to match existing conventions and avoid breaking other HTML writer behaviors. Proper regression tests are required to assert both string format specifications and callable formatters work for HTML output and to ensure no unintended changes in existing HTML writer tests.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:29.278045"}
{"instance_id": "astropy__astropy-13236", "repo": "astropy/astropy", "estimated_minutes": 150.0, "justification": "This change is conceptually straightforward (stop viewing structured ndarrays as NdarrayMixin), but it requires moderate investigation to confirm the relevant Table/Column initialization paths, existing mixin-detection logic, and any I/O/representation assumptions that may implicitly rely on the current behavior. Implementation is likely a small edit in one core table-construction location, but care is needed to ensure structured arrays become regular Columns consistently (including when passed via Table(), add_column, or assignment). Writing/adjusting tests to assert the new class/type behavior and running the table test suite to catch any regressions will take the bulk of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This change is conceptually straightforward (stop viewing structured ndarrays as NdarrayMixin), but it requires moderate investigation to confirm the relevant Table/Column initialization paths, existing mixin-detection logic, and any I/O/representation assumptions that may implicitly rely on the current behavior. Implementation is likely a small edit in one core table-construction location, but care is needed to ensure structured arrays become regular Columns consistently (including when passed via Table(), add_column, or assignment). Writing/adjusting tests to assert the new class/type behavior and running the table test suite to catch any regressions will take the bulk of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:30.052959"}
{"instance_id": "astropy__astropy-13977", "repo": "astropy/astropy", "estimated_minutes": 210.0, "justification": "Although the user provides a clear reproducer, changing `Quantity.__array_ufunc__` dispatch semantics is subtle because it affects numpy ufunc resolution order and interoperability with other Astropy classes (notably `Column`). An engineer will need to trace the current conversion logic, decide precisely where to return `NotImplemented` (likely via a targeted `try/except` around conversion), and ensure common-case performance is not degraded. Writing regression tests for the duck-type interaction plus verifying that existing `Quantity`-`Column` and normal `Quantity` behavior is unchanged will take a significant portion of the effort.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 60, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the user provides a clear reproducer, changing `Quantity.__array_ufunc__` dispatch semantics is subtle because it affects numpy ufunc resolution order and interoperability with other Astropy classes (notably `Column`). An engineer will need to trace the current conversion logic, decide precisely where to return `NotImplemented` (likely via a targeted `try/except` around conversion), and ensure common-case performance is not degraded. Writing regression tests for the duck-type interaction plus verifying that existing `Quantity`-`Column` and normal `Quantity` behavior is unchanged will take a significant portion of the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 60,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:30.172178"}
{"instance_id": "astropy__astropy-13579", "repo": "astropy/astropy", "estimated_minutes": 180.0, "justification": "Although the issue is well-reproduced and the likely root cause is already pinpointed to a specific line in SlicedLowLevelWCS, an engineer still needs to understand how the sliced wrapper constructs inputs for the underlying WCS inverse transform and how fixed/sliced axes should be represented in world space. The fix will require correctly deriving the dropped axis world coordinate corresponding to the slice pixel index (rather than using a constant placeholder), and ensuring this works across different slice specifications and axis couplings. Proper regression tests should be added (including the provided minimal reproduction) and the relevant WCSAPI wrapper test suite run to ensure no regressions in other slicing behaviors.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the issue is well-reproduced and the likely root cause is already pinpointed to a specific line in SlicedLowLevelWCS, an engineer still needs to understand how the sliced wrapper constructs inputs for the underlying WCS inverse transform and how fixed/sliced axes should be represented in world space. The fix will require correctly deriving the dropped axis world coordinate corresponding to the slice pixel index (rather than using a constant placeholder), and ensuring this works across different slice specifications and axis couplings. Proper regression tests should be added (including the provided minimal reproduction) and the relevant WCSAPI wrapper test suite run to ensure no regressions in other slicing behaviors.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:30.234850"}
{"instance_id": "astropy__astropy-14598", "repo": "astropy/astropy", "estimated_minutes": 240.0, "justification": "This bug is reproducible but likely rooted in subtle FITS card string parsing/serialization edge cases around the 80-character boundary, quoting rules (embedded ''), and possibly CONTINUE/long-string handling. An engineer will need to trace the full round-trip path (Card -> image/string -> fromstring) and identify where quotes or trailing substrings are dropped, which typically requires careful reading of parsing logic and FITS conventions. Implementing the fix is moderate in size but must be done cautiously to avoid regressions in comment parsing, whitespace handling, and long-string continuation behavior. Proper coverage will require several targeted tests spanning boundary lengths and variations (end-of-card, interior quotes, whitespace after quotes).", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 70, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"This bug is reproducible but likely rooted in subtle FITS card string parsing/serialization edge cases around the 80-character boundary, quoting rules (embedded ''), and possibly CONTINUE/long-string handling. An engineer will need to trace the full round-trip path (Card -> image/string -> fromstring) and identify where quotes or trailing substrings are dropped, which typically requires careful reading of parsing logic and FITS conventions. Implementing the fix is moderate in size but must be done cautiously to avoid regressions in comment parsing, whitespace handling, and long-string continuation behavior. Proper coverage will require several targeted tests spanning boundary lengths and variations (end-of-card, interior quotes, whitespace after quotes).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 70,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:44:30.465363"}
{"instance_id": "astropy__astropy-12907", "repo": "astropy/astropy", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible but likely stems from how `separability_matrix` traverses or flattens nested `CompoundModel` trees, which requires moderate code reading and debugging to understand the recursion/shape bookkeeping. The fix will probably involve adjusting the logic that combines separability blocks for compound submodels (e.g., ensuring nested \"&\" models preserve block-diagonal structure rather than being treated as fully coupled). Proper regression tests must cover both nested and non-nested compound constructions and verify no regressions for other compound operators, which adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 55, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible but likely stems from how `separability_matrix` traverses or flattens nested `CompoundModel` trees, which requires moderate code reading and debugging to understand the recursion/shape bookkeeping. The fix will probably involve adjusting the logic that combines separability blocks for compound submodels (e.g., ensuring nested \\\"&\\\" models preserve block-diagonal structure rather than being treated as fully coupled). Proper regression tests must cover both nested and non-nested compound constructions and verify no regressions for other compound operators, which adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 55,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:30.964623"}
{"instance_id": "django__django-10999", "repo": "django/django", "estimated_minutes": 140.0, "justification": "Although the regex change is small, the issue involves nuanced semantics about how negative signs should be interpreted in duration strings and which forms should be considered invalid. An engineer will need to reproduce the failing cases, inspect existing tests (including historical behavior from prior fixes like #27699), and ensure the updated regex doesn\u2019t unintentionally broaden accepted formats. Writing/adjusting focused tests for edge cases and running Django\u2019s dateparse-related test suite adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 20, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 140,\n  \"justification\": \"Although the regex change is small, the issue involves nuanced semantics about how negative signs should be interpreted in duration strings and which forms should be considered invalid. An engineer will need to reproduce the failing cases, inspect existing tests (including historical behavior from prior fixes like #27699), and ensure the updated regex doesn\u2019t unintentionally broaden accepted formats. Writing/adjusting focused tests for edge cases and running Django\u2019s dateparse-related test suite adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 20,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:31.404273"}
{"instance_id": "astropy__astropy-14182", "repo": "astropy/astropy", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible: the RST writer class does not accept the standard `header_rows` keyword, causing an immediate `TypeError`. Fixing it likely requires updating the `astropy.io.ascii.rst` writer to accept and render multiple header rows in the reStructuredText \u201csimple table\u201d format, aligning behavior with other ASCII writers (e.g., fixed width). Properly implementing this while preserving formatting/alignment and adding regression tests for both `Table` and `QTable` (including units) makes this a moderate-scope change.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 55, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible: the RST writer class does not accept the standard `header_rows` keyword, causing an immediate `TypeError`. Fixing it likely requires updating the `astropy.io.ascii.rst` writer to accept and render multiple header rows in the reStructuredText \u201csimple table\u201d format, aligning behavior with other ASCII writers (e.g., fixed width). Properly implementing this while preserving formatting/alignment and adding regression tests for both `Table` and `QTable` (including units) makes this a moderate-scope change.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 55,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:32.005433"}
{"instance_id": "astropy__astropy-13398", "repo": "astropy/astropy", "estimated_minutes": 480.0, "justification": "This change touches Astropy's coordinate transformation graph in a domain-sensitive area (ITRS/AltAz/HADec behavior with observer location, distance handling, and obstime semantics), so an engineer will need significant time to understand current transforms and the source of the reported inaccuracies. Implementation requires adding or modifying frame transforms (and likely their finite-difference differentials behavior), plus carefully defining behavior for mismatched obstimes, missing distances, and missing locations (warnings vs exceptions). Verification is non-trivial because it needs new regression tests that reproduce the satellite/topocentric-parallax confusion cases and ensure no regressions for existing geocentric and astrometric workflows.", "time_breakdown": {"understanding_and_investigation": 150, "implementation": 180, "testing_and_verification": 150}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "4-6", "testing_complexity": "complex", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 480,\n  \"justification\": \"This change touches Astropy's coordinate transformation graph in a domain-sensitive area (ITRS/AltAz/HADec behavior with observer location, distance handling, and obstime semantics), so an engineer will need significant time to understand current transforms and the source of the reported inaccuracies. Implementation requires adding or modifying frame transforms (and likely their finite-difference differentials behavior), plus carefully defining behavior for mismatched obstimes, missing distances, and missing locations (warnings vs exceptions). Verification is non-trivial because it needs new regression tests that reproduce the satellite/topocentric-parallax confusion cases and ensure no regressions for existing geocentric and astrometric workflows.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 150,\n    \"implementation\": 180,\n    \"testing_and_verification\": 150\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:44:32.499794"}
{"instance_id": "astropy__astropy-7606", "repo": "astropy/astropy", "estimated_minutes": 105.0, "justification": "The issue is clearly reproducible and localized to the equality implementation for UnrecognizedUnit, which currently attempts to coerce the RHS via Unit(other) and fails on None. Fixing it likely involves adjusting __eq__ (and possibly __ne__) to handle None and/or catch TypeError from Unit() conversion, returning False (or NotImplemented) instead of raising. Time is mainly spent ensuring the change matches Astropy\u2019s comparison conventions and adding regression tests to avoid altering equality semantics for other types.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 20, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 105,\n  \"justification\": \"The issue is clearly reproducible and localized to the equality implementation for UnrecognizedUnit, which currently attempts to coerce the RHS via Unit(other) and fails on None. Fixing it likely involves adjusting __eq__ (and possibly __ne__) to handle None and/or catch TypeError from Unit() conversion, returning False (or NotImplemented) instead of raising. Time is mainly spent ensuring the change matches Astropy\u2019s comparison conventions and adding regression tests to avoid altering equality semantics for other types.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 20,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:32.702693"}
{"instance_id": "astropy__astropy-8872", "repo": "astropy/astropy", "estimated_minutes": 150.0, "justification": "The issue is well-reproduced and points directly to the relevant logic in astropy/units/quantity.py where dtype coercion is decided, so investigation is bounded but still requires understanding historical intent (gh-1776) and current casting rules. The code change is likely small (adjusting the can_cast/inexact-type logic to include float16 and avoid unintended upcasting), but care is needed to avoid regressions for scalar/array inputs and other numpy scalar types. Writing targeted regression tests and running the unit test suite for units/quantity behavior will take a non-trivial amount of time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 35, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-reproduced and points directly to the relevant logic in astropy/units/quantity.py where dtype coercion is decided, so investigation is bounded but still requires understanding historical intent (gh-1776) and current casting rules. The code change is likely small (adjusting the can_cast/inexact-type logic to include float16 and avoid unintended upcasting), but care is needed to avoid regressions for scalar/array inputs and other numpy scalar types. Writing targeted regression tests and running the unit test suite for units/quantity behavior will take a non-trivial amount of time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 35,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:33.358905"}
{"instance_id": "astropy__astropy-14369", "repo": "astropy/astropy", "estimated_minutes": 210.0, "justification": "The issue is clearly reproducible and localized to the CDS unit parser (likely astropy/units/format/cds.py), but fixing it requires understanding the existing CDS grammar/tokenization and how it handles repeated division operators. Implementing the correct associativity/precedence for multiple slashes without breaking other CDS-specific unit features will take moderate investigation and careful changes. Proper regression tests must be added for multiple-slash composite units (and possibly a few related edge cases) and the full test suite should be run to ensure no parsing regressions in other unit formats or the ASCII CDS table reader.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"The issue is clearly reproducible and localized to the CDS unit parser (likely astropy/units/format/cds.py), but fixing it requires understanding the existing CDS grammar/tokenization and how it handles repeated division operators. Implementing the correct associativity/precedence for multiple slashes without breaking other CDS-specific unit features will take moderate investigation and careful changes. Proper regression tests must be added for multiple-slash composite units (and possibly a few related edge cases) and the full test suite should be run to ensure no parsing regressions in other unit formats or the ASCII CDS table reader.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:33.378873"}
{"instance_id": "django__django-10097", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires understanding Django's current URLValidator regex and how it parses optional userinfo, then adjusting it to disallow unescaped \":\", \"@\", and \"/\" within the username/password portion without breaking valid percent-encoded cases. The change is localized but regex-heavy and prone to subtle regressions, so time is needed to evaluate edge cases and ensure compatibility with existing accepted URLs. Writing/adjusting tests (including text-fixture URL lists) and running the validators test suite will take a significant portion of the effort to prevent new false negatives/positives.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 50, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires understanding Django's current URLValidator regex and how it parses optional userinfo, then adjusting it to disallow unescaped \\\":\\\", \\\"@\\\", and \\\"/\\\" within the username/password portion without breaking valid percent-encoded cases. The change is localized but regex-heavy and prone to subtle regressions, so time is needed to evaluate edge cases and ensure compatibility with existing accepted URLs. Writing/adjusting tests (including text-fixture URL lists) and running the validators test suite will take a significant portion of the effort to prevent new false negatives/positives.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 50,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:33.414180"}
{"instance_id": "django__django-10880", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped (a missing space in generated SQL when combining Aggregate(distinct=True) with a conditional Case/When), but it requires tracing how Aggregate SQL is rendered after the referenced DISTINCT-handling change. The fix is likely small (adjusting SQL template/concatenation in aggregate compilation), yet Django\u2019s ORM SQL generation has multiple code paths and backend considerations that require careful verification. Adding a regression test and running the relevant ORM test suite across backends (or at least ensuring backend-agnostic assertions) contributes materially to the total time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped (a missing space in generated SQL when combining Aggregate(distinct=True) with a conditional Case/When), but it requires tracing how Aggregate SQL is rendered after the referenced DISTINCT-handling change. The fix is likely small (adjusting SQL template/concatenation in aggregate compilation), yet Django\u2019s ORM SQL generation has multiple code paths and backend considerations that require careful verification. Adding a regression test and running the relevant ORM test suite across backends (or at least ensuring backend-agnostic assertions) contributes materially to the total time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:35.543637"}
{"instance_id": "django__django-11119", "repo": "django/django", "estimated_minutes": 120.0, "justification": "This is a well-scoped behavioral bug in Django\u2019s template Engine.render_to_string() where the Engine\u2019s autoescape setting isn\u2019t propagated when constructing the Context. An experienced engineer will need to locate the relevant code path (likely in django/template/engine.py), confirm the mismatch against other rendering entry points, and implement a small change to pass the correct autoescape value. The bulk of time will be spent adding a focused regression test in the existing template test suite and running/verifying tests to ensure no unintended changes to default autoescaping behavior.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"This is a well-scoped behavioral bug in Django\u2019s template Engine.render_to_string() where the Engine\u2019s autoescape setting isn\u2019t propagated when constructing the Context. An experienced engineer will need to locate the relevant code path (likely in django/template/engine.py), confirm the mismatch against other rendering entry points, and implement a small change to pass the correct autoescape value. The bulk of time will be spent adding a focused regression test in the existing template test suite and running/verifying tests to ensure no unintended changes to default autoescaping behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:36.575682"}
{"instance_id": "astropy__astropy-8707", "repo": "astropy/astropy", "estimated_minutes": 150.0, "justification": "This change is fairly well-scoped (accepting `bytes` in addition to `str`), but it requires careful investigation of the existing FITS header/card parsing path to ensure the fix is consistent with current assumptions (ASCII handling, padding, block sizing) and error behavior. Implementing the type-handling is likely straightforward, but updating both `Header.fromstring` and `Card.fromstring` and ensuring they behave identically across Python versions will take some time. Writing/adjusting tests to cover `bytes` inputs (and potentially mixed/invalid encodings) and running the relevant test suite to avoid regressions adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 45, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This change is fairly well-scoped (accepting `bytes` in addition to `str`), but it requires careful investigation of the existing FITS header/card parsing path to ensure the fix is consistent with current assumptions (ASCII handling, padding, block sizing) and error behavior. Implementing the type-handling is likely straightforward, but updating both `Header.fromstring` and `Card.fromstring` and ensuring they behave identically across Python versions will take some time. Writing/adjusting tests to cover `bytes` inputs (and potentially mixed/invalid encodings) and running the relevant test suite to avoid regressions adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 45,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:36.878598"}
{"instance_id": "django__django-11179", "repo": "django/django", "estimated_minutes": 140.0, "justification": "The issue is well-scoped and points directly to django/db/models/deletion.py and specific line ranges, but the engineer still needs to confirm the regression cause and ensure the fix matches Django\u2019s deletion semantics (fast delete vs. collected deletes). Implementing the fix is likely small (setting PK to None in the single-object fast-delete path) but requires care to avoid inconsistencies with multi-object handling and any field_updates behavior. Writing a regression test and running the relevant test suite (model deletion behavior across DB backends/settings) will take the bulk of the time.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 25, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 140,\n  \"justification\": \"The issue is well-scoped and points directly to django/db/models/deletion.py and specific line ranges, but the engineer still needs to confirm the regression cause and ensure the fix matches Django\u2019s deletion semantics (fast delete vs. collected deletes). Implementing the fix is likely small (setting PK to None in the single-object fast-delete path) but requires care to avoid inconsistencies with multi-object handling and any field_updates behavior. Writing a regression test and running the relevant test suite (model deletion behavior across DB backends/settings) will take the bulk of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 25,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:37.355021"}
{"instance_id": "django__django-11133", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-defined with a clear reproduction case and a likely fix location (HttpResponseBase.make_bytes), but it requires verifying how Django currently normalizes response content across HttpResponse/StreamingHttpResponse and ensuring consistency with force_bytes behavior. An experienced engineer will need to inspect existing response/content conversion paths, implement a small but careful change (e.g., converting memoryview to bytes without breaking other buffer-protocol inputs), and add regression tests that match Django\u2019s test conventions. Running the relevant HTTP/response test suite and checking for edge cases (e.g., content iterables, bytearray, encoding interactions) adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-defined with a clear reproduction case and a likely fix location (HttpResponseBase.make_bytes), but it requires verifying how Django currently normalizes response content across HttpResponse/StreamingHttpResponse and ensuring consistency with force_bytes behavior. An experienced engineer will need to inspect existing response/content conversion paths, implement a small but careful change (e.g., converting memoryview to bytes without breaking other buffer-protocol inputs), and add regression tests that match Django\u2019s test conventions. Running the relevant HTTP/response test suite and checking for edge cases (e.g., content iterables, bytearray, encoding interactions) adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:37.498735"}
{"instance_id": "django__django-11099", "repo": "django/django", "estimated_minutes": 90.0, "justification": "The fix itself is small (updating the regex anchors in ASCIIUsernameValidator and UnicodeUsernameValidator), but it requires verifying how Django\u2019s validators are constructed and ensuring the change doesn\u2019t affect any existing edge cases or deconstruction/serialization behavior. Adding regression tests is necessary to prove usernames ending with a trailing newline are rejected while all previously valid usernames remain valid. Running the relevant auth and validator test suites and checking for any downstream failures accounts for a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 15, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The fix itself is small (updating the regex anchors in ASCIIUsernameValidator and UnicodeUsernameValidator), but it requires verifying how Django\u2019s validators are constructed and ensuring the change doesn\u2019t affect any existing edge cases or deconstruction/serialization behavior. Adding regression tests is necessary to prove usernames ending with a trailing newline are rejected while all previously valid usernames remain valid. Running the relevant auth and validator test suites and checking for any downstream failures accounts for a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 15,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:38.029545"}
{"instance_id": "django__django-10914", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Changing the default FILE_UPLOAD_PERMISSIONS impacts core upload/storage behavior and requires careful review of how uploaded files are written across different upload handlers (memory vs temporary file) to ensure consistent permissions. Beyond a small code change, the work includes updating multiple documentation locations, adding a breaking change note for the correct release series, and adjusting/adding tests that currently assume OS-dependent defaults. Running and validating the relevant test modules (and ensuring cross-platform assumptions are correct) adds meaningful time.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 55, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "4-6", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Changing the default FILE_UPLOAD_PERMISSIONS impacts core upload/storage behavior and requires careful review of how uploaded files are written across different upload handlers (memory vs temporary file) to ensure consistent permissions. Beyond a small code change, the work includes updating multiple documentation locations, adding a breaking change note for the correct release series, and adjusting/adding tests that currently assume OS-dependent defaults. Running and validating the relevant test modules (and ensuring cross-platform assumptions are correct) adds meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 55,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:38.252852"}
{"instance_id": "django__django-10554", "repo": "django/django", "estimated_minutes": 270.0, "justification": "This issue involves a subtle QuerySet/Query mutation bug in Django's ORM around UNION queries and ordering, where evaluating a derived queryset appears to mutate the original query state and later produces invalid SQL (notably on PostgreSQL). Fixing it will require tracing cloning/copy semantics across QuerySet chaining and set-operator query compilation to ensure ORDER BY changes don\u2019t leak between related querysets. Given the risk of regressions in a core ORM feature and the need for robust multi-scenario regression tests (potentially backend-specific), a ~4.5 hour estimate is appropriate.", "time_breakdown": {"understanding_and_investigation": 120, "implementation": 70, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "4-6", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 270,\n  \"justification\": \"This issue involves a subtle QuerySet/Query mutation bug in Django's ORM around UNION queries and ordering, where evaluating a derived queryset appears to mutate the original query state and later produces invalid SQL (notably on PostgreSQL). Fixing it will require tracing cloning/copy semantics across QuerySet chaining and set-operator query compilation to ensure ORDER BY changes don\u2019t leak between related querysets. Given the risk of regressions in a core ORM feature and the need for robust multi-scenario regression tests (potentially backend-specific), a ~4.5 hour estimate is appropriate.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 120,\n    \"implementation\": 70,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:44:38.569964"}
{"instance_id": "django__django-10973", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The change is relatively contained (PostgreSQL backend client invocation) but requires careful review of existing client command construction and how Django currently handles passwords to avoid regressions across platforms. Updating to subprocess.run with a tailored environment (setting PGPASSWORD) is straightforward, but Django\u2019s conventions and backward-compatibility expectations add investigation overhead. Proper tests will likely need to mock subprocess execution and assert environment/arguments handling without leaking the password, which is moderately time-consuming.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 45, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The change is relatively contained (PostgreSQL backend client invocation) but requires careful review of existing client command construction and how Django currently handles passwords to avoid regressions across platforms. Updating to subprocess.run with a tailored environment (setting PGPASSWORD) is straightforward, but Django\u2019s conventions and backward-compatibility expectations add investigation overhead. Proper tests will likely need to mock subprocess execution and assert environment/arguments handling without leaking the password, which is moderately time-consuming.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 45,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:39.096488"}
{"instance_id": "django__django-11087", "repo": "django/django", "estimated_minutes": 270.0, "justification": "This change requires understanding Django\u2019s deletion collector and how QuerySet.delete() traverses related objects, then adjusting its queryset construction so it selects only the fields needed to build the deletion graph (e.g., PKs and referenced FK/to_field columns). The implementation touches core ORM deletion behavior and must preserve edge cases like non-PK foreign keys and disabling the optimization when delete-signal listeners are present. Verifying correctness requires adding targeted ORM tests (likely asserting executed SQL/selected columns) and running the relevant test suite across multiple database backends, which is time-consuming even for an experienced contributor.", "time_breakdown": {"understanding_and_investigation": 100, "implementation": 80, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 270,\n  \"justification\": \"This change requires understanding Django\u2019s deletion collector and how QuerySet.delete() traverses related objects, then adjusting its queryset construction so it selects only the fields needed to build the deletion graph (e.g., PKs and referenced FK/to_field columns). The implementation touches core ORM deletion behavior and must preserve edge cases like non-PK foreign keys and disabling the optimization when delete-signal listeners are present. Verifying correctness requires adding targeted ORM tests (likely asserting executed SQL/selected columns) and running the relevant test suite across multiple database backends, which is time-consuming even for an experienced contributor.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 100,\n    \"implementation\": 80,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:44:39.983603"}
{"instance_id": "django__django-11163", "repo": "django/django", "estimated_minutes": 90.0, "justification": "The fix is conceptually simple (treat an empty list of requested fields as \"request nothing\" rather than \"no filter\"), but it requires confirming current behavior, updating the conditional logic in the correct helper, and ensuring no callers/tests rely on the old semantics. Django\u2019s contribution standards mean adding a focused regression test and running the relevant test suite, which typically dominates the time compared to the one-line code change. Some additional time is needed to check edge cases (fields=None vs fields=[] vs fields set/tuple) and verify this doesn\u2019t affect form/model serialization behavior elsewhere.", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 10, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The fix is conceptually simple (treat an empty list of requested fields as \\\"request nothing\\\" rather than \\\"no filter\\\"), but it requires confirming current behavior, updating the conditional logic in the correct helper, and ensuring no callers/tests rely on the old semantics. Django\u2019s contribution standards mean adding a focused regression test and running the relevant test suite, which typically dominates the time compared to the one-line code change. Some additional time is needed to check edge cases (fields=None vs fields=[] vs fields set/tuple) and verify this doesn\u2019t affect form/model serialization behavior elsewhere.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 10,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:40.527099"}
{"instance_id": "django__django-11095", "repo": "django/django", "estimated_minutes": 240.0, "justification": "This change requires understanding Django admin\u2019s current inline construction flow (notably ModelAdmin.get_inline_instances()) and introducing a new hook without breaking existing custom ModelAdmin overrides. Implementation is fairly contained (likely centered in django/contrib/admin/options.py) but needs careful API design and backward-compatible behavior. The bulk of time will be spent adding robust tests that exercise request- and object-dependent inline selection and ensuring no regressions across existing admin inline behaviors, plus updating documentation/release notes per Django contribution standards.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 70, "testing_and_verification": 110}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"This change requires understanding Django admin\u2019s current inline construction flow (notably ModelAdmin.get_inline_instances()) and introducing a new hook without breaking existing custom ModelAdmin overrides. Implementation is fairly contained (likely centered in django/contrib/admin/options.py) but needs careful API design and backward-compatible behavior. The bulk of time will be spent adding robust tests that exercise request- and object-dependent inline selection and ensuring no regressions across existing admin inline behaviors, plus updating documentation/release notes per Django contribution standards.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 70,\n    \"testing_and_verification\": 110\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:44:40.813588"}
{"instance_id": "django__django-11141", "repo": "django/django", "estimated_minutes": 195.0, "justification": "The issue is conceptually clear (an outdated __file__ guard blocks namespace packages), but fixing it safely requires tracing where the check occurs and confirming all migration discovery paths now rely on __path__/pkgutil rather than filesystem assumptions. The main effort will be adding a robust regression test that constructs an app with a migrations namespace package (no __init__.py) and verifies migrate/loader behavior across different import and path setups. Implementation is likely a small change (removing/relaxing the __file__ requirement), but test setup and verification against Django\u2019s migration framework will take substantial time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 35, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 195,\n  \"justification\": \"The issue is conceptually clear (an outdated __file__ guard blocks namespace packages), but fixing it safely requires tracing where the check occurs and confirming all migration discovery paths now rely on __path__/pkgutil rather than filesystem assumptions. The main effort will be adding a robust regression test that constructs an app with a migrations namespace package (no __init__.py) and verifies migrate/loader behavior across different import and path setups. Implementation is likely a small change (removing/relaxing the __file__ requirement), but test setup and verification against Django\u2019s migration framework will take substantial time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 35,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:41.290616"}
{"instance_id": "django__django-11206", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible but requires investigating Django\u2019s existing number formatting logic (including the hardcoded cutoff introduced by the referenced commit) to ensure a change doesn\u2019t regress other formatting behaviors. The fix will likely be localized to the number formatting utility but needs careful handling of Decimal edge cases (very small magnitudes, sign handling, rounding, and interaction with decimal_pos). Adding targeted regression tests and running the relevant Django test modules to confirm no unintended output changes will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 45, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible but requires investigating Django\u2019s existing number formatting logic (including the hardcoded cutoff introduced by the referenced commit) to ensure a change doesn\u2019t regress other formatting behaviors. The fix will likely be localized to the number formatting utility but needs careful handling of Decimal edge cases (very small magnitudes, sign handling, rounding, and interaction with decimal_pos). Adding targeted regression tests and running the relevant Django test modules to confirm no unintended output changes will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 45,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:41.919950"}
{"instance_id": "django__django-11149", "repo": "django/django", "estimated_minutes": 270.0, "justification": "This is a permission regression in Django admin where auto-created ManyToMany through-model inlines remain editable for users with only view permissions. Fixing it requires tracing how InlineModelAdmin computes add/change/delete capabilities (including how view-permission support added in 2.1 affects formsets and template context), then ensuring the inline is rendered read-only and cannot POST modifications without change-related permissions. A proper solution also needs regression tests covering both UI rendering and POST behavior for M2M through inlines, which typically takes meaningful time in Django\u2019s admin test suite.", "time_breakdown": {"understanding_and_investigation": 105, "implementation": 60, "testing_and_verification": 105}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 270,\n  \"justification\": \"This is a permission regression in Django admin where auto-created ManyToMany through-model inlines remain editable for users with only view permissions. Fixing it requires tracing how InlineModelAdmin computes add/change/delete capabilities (including how view-permission support added in 2.1 affects formsets and template context), then ensuring the inline is rendered read-only and cannot POST modifications without change-related permissions. A proper solution also needs regression tests covering both UI rendering and POST behavior for M2M through inlines, which typically takes meaningful time in Django\u2019s admin test suite.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 105,\n    \"implementation\": 60,\n    \"testing_and_verification\": 105\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:44:41.980393"}
{"instance_id": "django__django-11265", "repo": "django/django", "estimated_minutes": 300.0, "justification": "This issue involves Django ORM internals around how negated filters (exclude/split_exclude) are rewritten into subqueries and how FilteredRelation annotations are propagated into those rewritten queries. The bug is subtle because it can manifest both as a FieldError (missing annotation metadata on a cloned/subquery) and as semantically incorrect SQL (subquery not applying the FilteredRelation condition), requiring careful tracing through query construction and join/alias reuse. An experienced engineer will likely need to adjust core query-building logic and add regression tests that validate both results and the presence of the filtered condition, then run the relevant test suite to ensure no regressions in other exclude/join edge-cases.", "time_breakdown": {"understanding_and_investigation": 140, "implementation": 90, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 300,\n  \"justification\": \"This issue involves Django ORM internals around how negated filters (exclude/split_exclude) are rewritten into subqueries and how FilteredRelation annotations are propagated into those rewritten queries. The bug is subtle because it can manifest both as a FieldError (missing annotation metadata on a cloned/subquery) and as semantically incorrect SQL (subquery not applying the FilteredRelation condition), requiring careful tracing through query construction and join/alias reuse. An experienced engineer will likely need to adjust core query-building logic and add regression tests that validate both results and the presence of the filtered condition, then run the relevant test suite to ensure no regressions in other exclude/join edge-cases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 140,\n    \"implementation\": 90,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:44:42.079846"}
{"instance_id": "django__django-11477", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing this requires understanding Django's URL resolution and reversing internals (notably _reverse_with_prefix) and how translate_url()/set_language interact with resolve() and reverse(). The core change (dropping None-valued kwargs/args during reversing for optional groups) is conceptually straightforward, but it sits in highly-trafficked, compatibility-sensitive code and needs careful handling to avoid breaking existing URL reversing behavior. Writing targeted regression tests (including translate_url and set_language paths) and running Django's URL-related test suite on multiple Python versions will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 50, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing this requires understanding Django's URL resolution and reversing internals (notably _reverse_with_prefix) and how translate_url()/set_language interact with resolve() and reverse(). The core change (dropping None-valued kwargs/args during reversing for optional groups) is conceptually straightforward, but it sits in highly-trafficked, compatibility-sensitive code and needs careful handling to avoid breaking existing URL reversing behavior. Writing targeted regression tests (including translate_url and set_language paths) and running Django's URL-related test suite on multiple Python versions will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 50,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:43.757162"}
{"instance_id": "django__django-11299", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires tracing how CheckConstraint conditions (especially mixed OR/AND Q objects) are compiled into SQL and why some branches use fully-qualified column references (e.g., new__table.column) while others don\u2019t. The engineer will likely need to adjust expression compilation or schema-editor constraint rendering for specific backends (SQLite/Oracle) and ensure the fix doesn\u2019t regress other constraint SQL generation. Writing a regression test that asserts the generated SQL during SQLite\u2019s table-rebuild path (and validating behavior on Oracle\u2019s compiler) adds meaningful but manageable effort.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires tracing how CheckConstraint conditions (especially mixed OR/AND Q objects) are compiled into SQL and why some branches use fully-qualified column references (e.g., new__table.column) while others don\u2019t. The engineer will likely need to adjust expression compilation or schema-editor constraint rendering for specific backends (SQLite/Oracle) and ensure the fix doesn\u2019t regress other constraint SQL generation. Writing a regression test that asserts the generated SQL during SQLite\u2019s table-rebuild path (and validating behavior on Oracle\u2019s compiler) adds meaningful but manageable effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:45.002301"}
{"instance_id": "django__django-11239", "repo": "django/django", "estimated_minutes": 150.0, "justification": "This change is likely localized to Django\u2019s PostgreSQL dbshell/client invocation code, but it requires understanding how Django currently maps DATABASES[\"OPTIONS\"] SSL settings onto the psql command/environment (and how similar parameters like sslrootcert are handled). The implementation itself should be small (adding support for sslcert and sslkey), but Django\u2019s test suite will require updating/adding mocked dbshell invocation tests to assert the correct flags/env vars are passed without relying on an actual psql binary. Extra time is allocated for ensuring the new behavior matches PostgreSQL/libpq expectations and doesn\u2019t regress existing dbshell option handling.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This change is likely localized to Django\u2019s PostgreSQL dbshell/client invocation code, but it requires understanding how Django currently maps DATABASES[\\\"OPTIONS\\\"] SSL settings onto the psql command/environment (and how similar parameters like sslrootcert are handled). The implementation itself should be small (adding support for sslcert and sslkey), but Django\u2019s test suite will require updating/adding mocked dbshell invocation tests to assert the correct flags/env vars are passed without relying on an actual psql binary. Extra time is allocated for ensuring the new behavior matches PostgreSQL/libpq expectations and doesn\u2019t regress existing dbshell option handling.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:45.043946"}
{"instance_id": "django__django-11400", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The issue is well-scoped (two specific admin list filter classes and clear root causes), but requires careful investigation of Django admin filter internals and how choice ordering is derived from ModelAdmin vs. related model Meta.ordering. The code change itself is likely small (adjust ordering fallback and pass the ordering kwarg), but validating the behavior requires adding/adjusting admin test coverage to assert ordering in list filter choices across both RelatedFieldListFilter and RelatedOnlyFieldListFilter. Running the relevant Django test suite sections and ensuring no regressions in admin filtering behavior adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-scoped (two specific admin list filter classes and clear root causes), but requires careful investigation of Django admin filter internals and how choice ordering is derived from ModelAdmin vs. related model Meta.ordering. The code change itself is likely small (adjust ordering fallback and pass the ordering kwarg), but validating the behavior requires adding/adjusting admin test coverage to assert ordering in list filter choices across both RelatedFieldListFilter and RelatedOnlyFieldListFilter. Running the relevant Django test suite sections and ensuring no regressions in admin filtering behavior adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:45.424421"}
{"instance_id": "django__django-11728", "repo": "django/django", "estimated_minutes": 135.0, "justification": "The issue is clearly reproducible and the hints already point to the specific functions and a concrete patch approach, reducing investigation time. However, the engineer still needs to understand Django's admindocs regex simplification logic, apply analogous fixes to both named and unnamed group handling, and ensure edge cases (nested groups, end-of-string patterns, optional trailing slashes) are covered. Adding/adjusting unit tests in the existing admindocs test suite and running the relevant test matrix locally will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 35, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 135,\n  \"justification\": \"The issue is clearly reproducible and the hints already point to the specific functions and a concrete patch approach, reducing investigation time. However, the engineer still needs to understand Django's admindocs regex simplification logic, apply analogous fixes to both named and unnamed group handling, and ensure edge cases (nested groups, end-of-string patterns, optional trailing slashes) are covered. Adding/adjusting unit tests in the existing admindocs test suite and running the relevant test matrix locally will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 35,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:45.996115"}
{"instance_id": "django__django-11532", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped with a clear traceback, reproduction steps, and an essentially proposed fix (IDNA/punycode encoding for the cached DNS name used in Message-ID generation). However, the engineer still needs to confirm where DNS_NAME is sourced and cached, ensure the change doesn\u2019t affect other email header behavior, and implement a regression test that reliably simulates a non-ASCII hostname. Writing and validating the test in Django\u2019s mail test suite and running the relevant test subset to avoid regressions will likely dominate the effort.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 20, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped with a clear traceback, reproduction steps, and an essentially proposed fix (IDNA/punycode encoding for the cached DNS name used in Message-ID generation). However, the engineer still needs to confirm where DNS_NAME is sourced and cached, ensure the change doesn\u2019t affect other email header behavior, and implement a regression test that reliably simulates a non-ASCII hostname. Writing and validating the test in Django\u2019s mail test suite and running the relevant test subset to avoid regressions will likely dominate the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 20,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:47.051991"}
{"instance_id": "django__django-11333", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-scoped (normalize the `urlconf` argument inside `get_resolver` so `None` maps to `settings.ROOT_URLCONF` before hitting the `lru_cache`), but it requires careful investigation of Django\u2019s URLconf/thread-local behavior to avoid subtle behavioral changes. Implementing the change is likely small and localized, however adding a robust regression test (ensuring the same cached resolver is reused across pre-request and in-request usage) and running/verifying the relevant URL resolution test suite will take the bulk of the time.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 30, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped (normalize the `urlconf` argument inside `get_resolver` so `None` maps to `settings.ROOT_URLCONF` before hitting the `lru_cache`), but it requires careful investigation of Django\u2019s URLconf/thread-local behavior to avoid subtle behavioral changes. Implementing the change is likely small and localized, however adding a robust regression test (ensuring the same cached resolver is reused across pre-request and in-request usage) and running/verifying the relevant URL resolution test suite will take the bulk of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 30,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:47.178603"}
{"instance_id": "django__django-11490", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This issue is well-reproduced but involves Django ORM internals for combined/composed queries (e.g., UNION) and how select/values state is propagated across query clones and compiler generation. Fixing it likely requires understanding how CombinedQuery/QuerySet cloning interacts with values()/values_list() and ensuring the selected columns are rebuilt on each evaluation rather than leaking from a prior compiler/query state. A proper regression test must cover multiple evaluations with different values_list() projections (and potentially multiple backends), which adds non-trivial verification time.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 55, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This issue is well-reproduced but involves Django ORM internals for combined/composed queries (e.g., UNION) and how select/values state is propagated across query clones and compiler generation. Fixing it likely requires understanding how CombinedQuery/QuerySet cloning interacts with values()/values_list() and ensuring the selected columns are rebuilt on each evaluation rather than leaking from a prior compiler/query state. A proper regression test must cover multiple evaluations with different values_list() projections (and potentially multiple backends), which adds non-trivial verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 55,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:47.467304"}
{"instance_id": "django__django-11138", "repo": "django/django", "estimated_minutes": 270.0, "justification": "The issue is clearly reproducible and points to a specific problematic line in MySQL operations, but fixing it correctly requires understanding Django\u2019s cross-backend timezone conversion logic for lookups like __date when USE_TZ=True. The change likely needs to be applied consistently across multiple backends (MySQL, SQLite, Oracle) and must handle the optimization where no conversion is needed when the database TIME_ZONE matches the current application timezone. Writing robust regression tests is the most time-consuming part because timezone behavior is backend-specific, often depends on database features (e.g., MySQL timezone tables), and must be validated without introducing fragile environment assumptions.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 120}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 270,\n  \"justification\": \"The issue is clearly reproducible and points to a specific problematic line in MySQL operations, but fixing it correctly requires understanding Django\u2019s cross-backend timezone conversion logic for lookups like __date when USE_TZ=True. The change likely needs to be applied consistently across multiple backends (MySQL, SQLite, Oracle) and must handle the optimization where no conversion is needed when the database TIME_ZONE matches the current application timezone. Writing robust regression tests is the most time-consuming part because timezone behavior is backend-specific, often depends on database features (e.g., MySQL timezone tables), and must be validated without introducing fragile environment assumptions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 120\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:44:48.310416"}
{"instance_id": "django__django-11603", "repo": "django/django", "estimated_minutes": 150.0, "justification": "While the functional change is small (enabling DISTINCT support on Avg and Sum, and possibly Min/Max), an engineer still needs to inspect Django\u2019s aggregate base classes and recent behavior changes from the referenced issue to ensure the flag is applied in the correct place. The bulk of the time will go into adding/adjusting ORM tests to confirm SQL generation and runtime behavior across backends, and running the relevant test suite to avoid regressions. The work is straightforward but requires careful verification because aggregates are a core ORM feature with broad surface area.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"While the functional change is small (enabling DISTINCT support on Avg and Sum, and possibly Min/Max), an engineer still needs to inspect Django\u2019s aggregate base classes and recent behavior changes from the referenced issue to ensure the flag is applied in the correct place. The bulk of the time will go into adding/adjusting ORM tests to confirm SQL generation and runtime behavior across backends, and running the relevant test suite to avoid regressions. The work is straightforward but requires careful verification because aggregates are a core ORM feature with broad surface area.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:48.980927"}
{"instance_id": "django__django-11555", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the failure is localized (get_order_dir() assuming order-by items are strings), Django\u2019s ordering pipeline touches multiple ORM layers (model Meta.ordering normalization, expression handling, SQL compiler, and sometimes admin/queryset cloning). An experienced engineer will need time to reproduce the crash in the reported scenarios (multi-table inheritance during test DB setup and ordering expressions like Lower()), identify the exact ordering normalization point, and ensure the fix preserves existing semantics for string-based ordering and OrderBy/Expression objects. Proper regression coverage requires adding ORM-level tests that exercise both Meta.ordering with expressions and inheritance-related query compilation paths, then running the relevant test suites to verify no regressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the failure is localized (get_order_dir() assuming order-by items are strings), Django\u2019s ordering pipeline touches multiple ORM layers (model Meta.ordering normalization, expression handling, SQL compiler, and sometimes admin/queryset cloning). An experienced engineer will need time to reproduce the crash in the reported scenarios (multi-table inheritance during test DB setup and ordering expressions like Lower()), identify the exact ordering normalization point, and ensure the fix preserves existing semantics for string-based ordering and OrderBy/Expression objects. Proper regression coverage requires adding ORM-level tests that exercise both Meta.ordering with expressions and inheritance-related query compilation paths, then running the relevant test suites to verify no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:49.339526"}
{"instance_id": "astropy__astropy-14096", "repo": "astropy/astropy", "estimated_minutes": 180.0, "justification": "The issue involves Python attribute-resolution semantics interacting with SkyCoord\u2019s custom __getattr__ logic, so an engineer will need to reproduce the behavior, inspect sky_coordinate.py, and understand why the original AttributeError is being masked. The likely fix is localized (adjusting __getattr__ to detect and re-raise an underlying AttributeError whose name differs from the requested attribute), but it must be done carefully to avoid breaking SkyCoord\u2019s existing fallback attribute behavior. Adding regression tests for subclassed properties and ensuring existing SkyCoord attribute access paths remain intact will take a meaningful portion of the effort.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue involves Python attribute-resolution semantics interacting with SkyCoord\u2019s custom __getattr__ logic, so an engineer will need to reproduce the behavior, inspect sky_coordinate.py, and understand why the original AttributeError is being masked. The likely fix is localized (adjusting __getattr__ to detect and re-raise an underlying AttributeError whose name differs from the requested attribute), but it must be done carefully to avoid breaking SkyCoord\u2019s existing fallback attribute behavior. Adding regression tests for subclassed properties and ensuring existing SkyCoord attribute access paths remain intact will take a meaningful portion of the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:50.175268"}
{"instance_id": "django__django-11734", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This bug sits in Django ORM internals where aliasing and reference resolution for OuterRef interacts with negated predicates (exclude() and ~Q()), which can be subtle and requires careful tracing through SQL compiler/query construction. Although the reproduction and failing SQL are clear, fixing the incorrect model/alias chosen for OuterRef likely involves modifying query-building code paths for negation (e.g., how excludes are converted to subqueries/NOT IN and how references are resolved across query boundaries). Proper regression tests must cover multiple forms (exclude(), ~Q(), and Exists/Subquery usage) and verification should include running ORM query tests to avoid regressions in other subquery/OuterRef scenarios.", "time_breakdown": {"understanding_and_investigation": 100, "implementation": 60, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This bug sits in Django ORM internals where aliasing and reference resolution for OuterRef interacts with negated predicates (exclude() and ~Q()), which can be subtle and requires careful tracing through SQL compiler/query construction. Although the reproduction and failing SQL are clear, fixing the incorrect model/alias chosen for OuterRef likely involves modifying query-building code paths for negation (e.g., how excludes are converted to subqueries/NOT IN and how references are resolved across query boundaries). Proper regression tests must cover multiple forms (exclude(), ~Q(), and Exists/Subquery usage) and verification should include running ORM query tests to avoid regressions in other subquery/OuterRef scenarios.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 100,\n    \"implementation\": 60,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:52.228888"}
{"instance_id": "django__django-11551", "repo": "django/django", "estimated_minutes": 210.0, "justification": "The issue is well-described and points to a specific regression in the admin checks code path, but an engineer will still need time to confirm the exact failing control flow and ensure the fix doesn\u2019t reintroduce the original ticket\u2019s behavior. The code change is likely small (localized to the list_display validation logic), however crafting a robust regression test is non-trivial because it must simulate a model attribute/descriptor or field whose class-level access raises or behaves unexpectedly without relying on third-party packages. Verifying against Django\u2019s existing admin checks test suite and ensuring compatibility with the original ManyToMany and descriptor-returning-None cases adds additional time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 100}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"The issue is well-described and points to a specific regression in the admin checks code path, but an engineer will still need time to confirm the exact failing control flow and ensure the fix doesn\u2019t reintroduce the original ticket\u2019s behavior. The code change is likely small (localized to the list_display validation logic), however crafting a robust regression test is non-trivial because it must simulate a model attribute/descriptor or field whose class-level access raises or behaves unexpectedly without relying on third-party packages. Verifying against Django\u2019s existing admin checks test suite and ensuring compatibility with the original ManyToMany and descriptor-returning-None cases adds additional time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 100\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:52.731286"}
{"instance_id": "django__django-11749", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Fixing this requires understanding how Django's call_command() selectively forwards kwargs into argparse.parse_args() and why mutually exclusive required groups aren't considered when no individual option is marked required. The change is localized but subtle because it must correctly detect required mutually exclusive groups and only forward the relevant provided option(s) without altering behavior for other argument patterns. Adding a regression test is straightforward but requires navigating Django's management command test harness and ensuring cross-version argparse behavior is stable.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing this requires understanding how Django's call_command() selectively forwards kwargs into argparse.parse_args() and why mutually exclusive required groups aren't considered when no individual option is marked required. The change is localized but subtle because it must correctly detect required mutually exclusive groups and only forward the relevant provided option(s) without altering behavior for other argument patterns. Adding a regression test is straightforward but requires navigating Django's management command test harness and ensuring cross-version argparse behavior is stable.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:53.167054"}
{"instance_id": "django__django-11820", "repo": "django/django", "estimated_minutes": 150.0, "justification": "This is a well-scoped regression in Django\u2019s model validation checks: Meta.ordering should accept related-field lookups ending in \"__pk\", but the current check incorrectly flags them as nonexistent. Fixing it will require moderate investigation to locate the exact ordering-check logic introduced/changed in the referenced commit, then adjusting lookup/field-resolution to treat \"pk\" as a valid terminal for related paths. A regression test must be added in Django\u2019s checks/tests suite and the relevant model-check test subset (or full suite) run to ensure no unintended relaxation of validation rules.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This is a well-scoped regression in Django\u2019s model validation checks: Meta.ordering should accept related-field lookups ending in \\\"__pk\\\", but the current check incorrectly flags them as nonexistent. Fixing it will require moderate investigation to locate the exact ordering-check logic introduced/changed in the referenced commit, then adjusting lookup/field-resolution to treat \\\"pk\\\" as a valid terminal for related paths. A regression test must be added in Django\u2019s checks/tests suite and the relevant model-check test subset (or full suite) run to ensure no unintended relaxation of validation rules.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:53.338202"}
{"instance_id": "django__django-11433", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This change likely involves Django's ModelForm instance construction logic (e.g., in django/forms/models.py) where model field defaults are preserved when input data omits a field, which currently prevents values injected into cleaned_data (via clean() or clean_<field>()) from being applied. An experienced engineer will need to trace the save/_post_clean/construct_instance path, adjust the condition to respect explicitly-present cleaned_data keys even when the field wasn't in the submitted payload, and ensure the behavior remains unchanged for fields truly absent from cleaned_data. Writing regression tests for ModelForm + model defaults interactions and running the relevant form/model test suites will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This change likely involves Django's ModelForm instance construction logic (e.g., in django/forms/models.py) where model field defaults are preserved when input data omits a field, which currently prevents values injected into cleaned_data (via clean() or clean_<field>()) from being applied. An experienced engineer will need to trace the save/_post_clean/construct_instance path, adjust the condition to respect explicitly-present cleaned_data keys even when the field wasn't in the submitted payload, and ensure the behavior remains unchanged for fields truly absent from cleaned_data. Writing regression tests for ModelForm + model defaults interactions and running the relevant form/model test suites will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:53.547985"}
{"instance_id": "django__django-11740", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-reproduced and already points to the likely faulty location in the migration autodetector, but an engineer will still need to trace how dependencies are computed for AlterField operations and confirm no other alteration paths are affected. The actual fix is relatively small (ensuring dependencies are added when changing a non-relation field to a ForeignKey), but Django\u2019s migration framework is subtle and requires careful handling to avoid introducing incorrect ordering or circular dependency behavior. Writing a targeted regression test in the existing autodetector test suite and running the relevant migration tests across supported databases will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 35, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-reproduced and already points to the likely faulty location in the migration autodetector, but an engineer will still need to trace how dependencies are computed for AlterField operations and confirm no other alteration paths are affected. The actual fix is relatively small (ensuring dependencies are added when changing a non-relation field to a ForeignKey), but Django\u2019s migration framework is subtle and requires careful handling to avoid introducing incorrect ordering or circular dependency behavior. Writing a targeted regression test in the existing autodetector test suite and running the relevant migration tests across supported databases will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 35,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:55.562307"}
{"instance_id": "django__django-11815", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the code change is localized (Enum serialization in migrations), an engineer will need to confirm current serializer behavior and ensure the new representation remains import-stable and backwards compatible with Django\u2019s migration writer conventions. Writing a robust regression test requires understanding existing migration serialization tests and correctly handling lazy translation objects (Promises) to validate imports and ensure the serialized form uses the enum member name rather than the translated value. Additional time is needed to run the relevant test suites and check that no other serialization pathways (e.g., TextChoices/IntegerChoices or non-lazy enum values) regress.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the code change is localized (Enum serialization in migrations), an engineer will need to confirm current serializer behavior and ensure the new representation remains import-stable and backwards compatible with Django\u2019s migration writer conventions. Writing a robust regression test requires understanding existing migration serialization tests and correctly handling lazy translation objects (Promises) to validate imports and ensure the serialized form uses the enum member name rather than the translated value. Additional time is needed to run the relevant test suites and check that no other serialization pathways (e.g., TextChoices/IntegerChoices or non-lazy enum values) regress.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:56.419883"}
{"instance_id": "django__django-11848", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is localized (django.utils.http.parse_http_date) but requires careful interpretation of RFC behavior for two-digit years relative to the current year, which adds some investigation and edge-case reasoning. Implementing the fix is small, but making the tests deterministic (pinning \"current year\" via mocking/patching datetime in Django\u2019s preferred style) and validating boundary cases (exactly 50 years, UTC handling) will take significant time. Running and iterating on Django\u2019s test suite and ensuring no regressions in other HTTP-date formats adds additional overhead.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is localized (django.utils.http.parse_http_date) but requires careful interpretation of RFC behavior for two-digit years relative to the current year, which adds some investigation and edge-case reasoning. Implementing the fix is small, but making the tests deterministic (pinning \\\"current year\\\" via mocking/patching datetime in Django\u2019s preferred style) and validating boundary cases (exactly 50 years, UTC handling) will take significant time. Running and iterating on Django\u2019s test suite and ensuring no regressions in other HTTP-date formats adds additional overhead.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:56.460502"}
{"instance_id": "django__django-11880", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped (Field.__deepcopy__ shallow-copies error_messages), but requires confirming current deepcopy behavior across Field subclasses and form instantiation to avoid unintended side effects. The implementation is likely small (ensuring error_messages is deep-copied into the cloned field), but Django\u2019s form/field copying semantics are subtle enough to warrant careful review. Writing a regression test that demonstrates isolation between separate Form instances and running relevant test suites will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 20, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped (Field.__deepcopy__ shallow-copies error_messages), but requires confirming current deepcopy behavior across Field subclasses and form instantiation to avoid unintended side effects. The implementation is likely small (ensuring error_messages is deep-copied into the cloned field), but Django\u2019s form/field copying semantics are subtle enough to warrant careful review. Writing a regression test that demonstrates isolation between separate Form instances and running relevant test suites will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 20,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:56.520930"}
{"instance_id": "django__django-11276", "repo": "django/django", "estimated_minutes": 165.0, "justification": "Although the code change is conceptually small (delegate to Python's stdlib html.escape()), an engineer will need to carefully verify Django's existing escape() semantics around SafeData/SafeString handling, input types, and exact output, because many tests and possibly user code compare escaped output literally. The stdlib behavior difference for escaping single quotes (&#x27 vs &#39) is likely to break existing assertions, so time will be spent deciding whether to preserve backward-compatible output (e.g., post-process &#x27) or update expectations and document the change. Writing/adjusting unit tests and running Django's test suite for utils/template escaping behavior will take a significant portion of the effort to avoid regressions in template rendering and security-sensitive escaping.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 165,\n  \"justification\": \"Although the code change is conceptually small (delegate to Python's stdlib html.escape()), an engineer will need to carefully verify Django's existing escape() semantics around SafeData/SafeString handling, input types, and exact output, because many tests and possibly user code compare escaped output literally. The stdlib behavior difference for escaping single quotes (&#x27 vs &#39) is likely to break existing assertions, so time will be spent deciding whether to preserve backward-compatible output (e.g., post-process &#x27) or update expectations and document the change. Writing/adjusting unit tests and running Django's test suite for utils/template escaping behavior will take a significant portion of the effort to avoid regressions in template rendering and security-sensitive escaping.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:57.423174"}
{"instance_id": "django__django-11451", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the code change is small (an early return in ModelBackend.authenticate() when username or password is None), an experienced engineer will need to confirm the security/timing rationale and ensure the behavior is consistent with Django\u2019s authentication contract across multiple backends. The bulk of the time is in locating the right existing test patterns, adding a regression test that demonstrates the unnecessary query (likely via a chained backend scenario), and running/adjusting the auth test suite to avoid regressions. Django\u2019s conventions and backwards-compatibility expectations make even small auth changes require careful verification.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 20, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the code change is small (an early return in ModelBackend.authenticate() when username or password is None), an experienced engineer will need to confirm the security/timing rationale and ensure the behavior is consistent with Django\u2019s authentication contract across multiple backends. The bulk of the time is in locating the right existing test patterns, adding a regression test that demonstrates the unnecessary query (likely via a chained backend scenario), and running/adjusting the auth test suite to avoid regressions. Django\u2019s conventions and backwards-compatibility expectations make even small auth changes require careful verification.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 20,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:58.144565"}
{"instance_id": "django__django-12039", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the behavior is cosmetically wrong rather than functionally broken, fixing it requires understanding how Django builds index column SQL via ddl_references.Columns and how ordering/opclasses are represented (including the subtle case where \"ascending\" is encoded as an empty-string suffix). The code change itself is likely small (normalizing/ignoring empty suffixes or ensuring spacing rules), but it must be validated across multiple index definitions (asc/desc, with/without opclasses) and at least one backend (most likely PostgreSQL) with regression tests added. Time is primarily spent on investigation and writing/confirming backend-specific SQL generation tests to avoid future formatting regressions.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 35, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the behavior is cosmetically wrong rather than functionally broken, fixing it requires understanding how Django builds index column SQL via ddl_references.Columns and how ordering/opclasses are represented (including the subtle case where \\\"ascending\\\" is encoded as an empty-string suffix). The code change itself is likely small (normalizing/ignoring empty suffixes or ensuring spacing rules), but it must be validated across multiple index definitions (asc/desc, with/without opclasses) and at least one backend (most likely PostgreSQL) with regression tests added. Time is primarily spent on investigation and writing/confirming backend-specific SQL generation tests to avoid future formatting regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 35,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:58.777825"}
{"instance_id": "django__django-11211", "repo": "django/django", "estimated_minutes": 165.0, "justification": "Although the report is small, GenericForeignKey prefetching involves multiple moving parts (ContentType queries, grouping by model, and mapping fetched objects back onto instances). The likely root cause is a type mismatch when correlating prefetched objects (UUID primary keys as UUID objects) with stored generic foreign key IDs (often stored as strings), causing the mapping step to miss and leave the attribute as None. Fixing this requires careful normalization/casting of IDs in the prefetch logic and adding a targeted regression test to ensure UUID PKs work across supported databases.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 165,\n  \"justification\": \"Although the report is small, GenericForeignKey prefetching involves multiple moving parts (ContentType queries, grouping by model, and mapping fetched objects back onto instances). The likely root cause is a type mismatch when correlating prefetched objects (UUID primary keys as UUID objects) with stored generic foreign key IDs (often stored as strings), causing the mapping step to miss and leave the attribute as None. Fixing this requires careful normalization/casting of IDs in the prefetch logic and adding a targeted regression test to ensure UUID PKs work across supported databases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:44:59.583089"}
{"instance_id": "django__django-12193", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is clearly described and already localized to an interaction between SplitArrayField rendering and CheckboxInput.get_context() mutating the passed attrs dict, but an engineer will still need to trace how attrs are shared across subwidgets and confirm the exact mutation path. The fix is likely small (copying attrs per widget render or preventing in-place mutation) but must be done carefully to avoid changing widget behavior elsewhere. A proper regression test should be added for SplitArrayField(BooleanField) initial values to ensure only the intended checkboxes are checked, and the full relevant Django test suite subset should be run to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly described and already localized to an interaction between SplitArrayField rendering and CheckboxInput.get_context() mutating the passed attrs dict, but an engineer will still need to trace how attrs are shared across subwidgets and confirm the exact mutation path. The fix is likely small (copying attrs per widget render or preventing in-place mutation) but must be done carefully to avoid changing widget behavior elsewhere. A proper regression test should be added for SplitArrayField(BooleanField) initial values to ensure only the intended checkboxes are checked, and the full relevant Django test suite subset should be run to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:00.392176"}
{"instance_id": "django__django-11885", "repo": "django/django", "estimated_minutes": 300.0, "justification": "This change requires understanding Django's deletion.Collector fast-delete path, how it queues per-relation DELETE querysets, and where it can safely coalesce them without changing semantics. Implementing query combination involves non-trivial ORM internals work (merging filters into a single OR condition per target table) while preserving backend portability and respecting existing fast-delete constraints. Proper validation needs new regression tests that assert reduced query counts across relationship types (e.g., multiple FKs to same model, self-referential M2M) and that behavior remains correct across supported databases.", "time_breakdown": {"understanding_and_investigation": 120, "implementation": 110, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 300,\n  \"justification\": \"This change requires understanding Django's deletion.Collector fast-delete path, how it queues per-relation DELETE querysets, and where it can safely coalesce them without changing semantics. Implementing query combination involves non-trivial ORM internals work (merging filters into a single OR condition per target table) while preserving backend portability and respecting existing fast-delete constraints. Proper validation needs new regression tests that assert reduced query counts across relationship types (e.g., multiple FKs to same model, self-referential M2M) and that behavior remains correct across supported databases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 120,\n    \"implementation\": 110,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:45:00.666310"}
{"instance_id": "django__django-12155", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the underlying bug is small (indent calculation in admindocs docstring trimming), an engineer will need time to locate the exact call path where docstrings are processed and rendered through docutils and to reproduce the failure reliably across supported Python/docutils combinations. The fix is likely either switching to `inspect.cleandoc()` (preferred per PEP 257) or adjusting the existing algorithm to ignore the first line and handle empty/min() edge cases. Proper regression tests will require setting up an admindocs rendering scenario (or unit-testing the trimming function) and running Django\u2019s test suite to ensure no regressions in documentation rendering.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 35, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the underlying bug is small (indent calculation in admindocs docstring trimming), an engineer will need time to locate the exact call path where docstrings are processed and rendered through docutils and to reproduce the failure reliably across supported Python/docutils combinations. The fix is likely either switching to `inspect.cleandoc()` (preferred per PEP 257) or adjusting the existing algorithm to ignore the first line and handle empty/min() edge cases. Proper regression tests will require setting up an admindocs rendering scenario (or unit-testing the trimming function) and running Django\u2019s test suite to ensure no regressions in documentation rendering.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 35,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:00.957427"}
{"instance_id": "django__django-11292", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Implementing a global --skip-checks flag is conceptually straightforward because Django already supports a skip_checks stealth option that influences BaseCommand.execute() behavior, but it requires careful integration into the shared argument parser used by all management commands. The main work is identifying the correct place to add the option (without breaking command-specific arguments), ensuring it behaves correctly for commands that do and do not run system checks, and updating/adding tests to verify checks are actually skipped when requested. Running Django\u2019s test suite (or the relevant management-command/system-check subsets) and iterating on any argument-parsing edge cases accounts for a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Implementing a global --skip-checks flag is conceptually straightforward because Django already supports a skip_checks stealth option that influences BaseCommand.execute() behavior, but it requires careful integration into the shared argument parser used by all management commands. The main work is identifying the correct place to add the option (without breaking command-specific arguments), ensuring it behaves correctly for commands that do and do not run system checks, and updating/adding tests to verify checks are actually skipped when requested. Running Django\u2019s test suite (or the relevant management-command/system-check subsets) and iterating on any argument-parsing edge cases accounts for a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:00.959556"}
{"instance_id": "django__django-11790", "repo": "django/django", "estimated_minutes": 120.0, "justification": "This looks like a well-scoped regression in Django\u2019s auth form rendering where the form field\u2019s effective max_length is no longer being propagated to the widget, so the HTML \"maxlength\" attribute is missing. An experienced engineer will need some time to trace the change introduced by the referenced commit/PR, confirm how AuthenticationForm constructs its username field (and why CharField/widget_attrs isn\u2019t producing maxlength), and implement the smallest correct fix consistent with Django\u2019s form conventions. Adding a regression test and running the relevant auth/form test suite to ensure no behavioral changes elsewhere will take a substantial portion of the effort.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 25, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"This looks like a well-scoped regression in Django\u2019s auth form rendering where the form field\u2019s effective max_length is no longer being propagated to the widget, so the HTML \\\"maxlength\\\" attribute is missing. An experienced engineer will need some time to trace the change introduced by the referenced commit/PR, confirm how AuthenticationForm constructs its username field (and why CharField/widget_attrs isn\u2019t producing maxlength), and implement the smallest correct fix consistent with Django\u2019s form conventions. Adding a regression test and running the relevant auth/form test suite to ensure no behavioral changes elsewhere will take a substantial portion of the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 25,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:01.429593"}
{"instance_id": "django__django-11951", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The core code change is small (making bulk_create choose the minimum of the user-provided batch_size and the backend-compatible maximum), but it requires careful investigation of how bulk_create currently computes and uses batch sizes across backends. Writing a reliable regression test is the main time driver, since it needs to validate query batching behavior without depending on a specific database\u2019s hard limits (likely via mocking/patching connection.ops.bulk_batch_size and asserting the number of INSERT queries). Additional time is needed to run the relevant ORM test suite and ensure no regressions in bulk_insert behavior or edge cases.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 25, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The core code change is small (making bulk_create choose the minimum of the user-provided batch_size and the backend-compatible maximum), but it requires careful investigation of how bulk_create currently computes and uses batch sizes across backends. Writing a reliable regression test is the main time driver, since it needs to validate query batching behavior without depending on a specific database\u2019s hard limits (likely via mocking/patching connection.ops.bulk_batch_size and asserting the number of INSERT queries). Additional time is needed to run the relevant ORM test suite and ensure no regressions in bulk_insert behavior or edge cases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 25,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:01.747020"}
{"instance_id": "django__django-12209", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This issue is a behavioral regression in Django's model saving logic involving subtle state/PK-default interactions introduced by a specific commit, which requires careful investigation of Model.save()/_save_table and how pk_set and defaults are determined. The fix is likely small in code size but high in risk because it affects core ORM insert/update decision-making and also impacts fixture loading (loaddata) behavior via the raw save path. Proper resolution will require adding targeted regression tests (model save and serialization/fixtures) and running a meaningful portion of Django\u2019s test suite to ensure no regressions in ORM/serialization behavior.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 50, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This issue is a behavioral regression in Django's model saving logic involving subtle state/PK-default interactions introduced by a specific commit, which requires careful investigation of Model.save()/_save_table and how pk_set and defaults are determined. The fix is likely small in code size but high in risk because it affects core ORM insert/update decision-making and also impacts fixture loading (loaddata) behavior via the raw save path. Proper resolution will require adding targeted regression tests (model save and serialization/fixtures) and running a meaningful portion of Django\u2019s test suite to ensure no regressions in ORM/serialization behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 50,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:01.787538"}
{"instance_id": "django__django-12125", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing this requires understanding Django\u2019s migration serialization pipeline (serializer_factory, TypeSerializer, EnumSerializer) and why nested classes are mis-resolved to module-level names. The actual code change is likely localized (switching to __qualname__ and ensuring correct import/path generation), but it must be done carefully to avoid breaking existing serialization behavior for top-level types and edge cases. Writing regression tests for nested Enums/Choices and validating generated migration output across test suites adds significant time.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 60, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing this requires understanding Django\u2019s migration serialization pipeline (serializer_factory, TypeSerializer, EnumSerializer) and why nested classes are mis-resolved to module-level names. The actual code change is likely localized (switching to __qualname__ and ensuring correct import/path generation), but it must be done carefully to avoid breaking existing serialization behavior for top-level types and edge cases. Writing regression tests for nested Enums/Choices and validating generated migration output across test suites adds significant time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 60,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:01.945794"}
{"instance_id": "django__django-12262", "repo": "django/django", "estimated_minutes": 170.0, "justification": "The issue is clearly reproducible but requires understanding Django\u2019s template tag argument parsing/binding logic (used by both simple_tag and inclusion_tag) and how it interacts with Python keyword-only parameters and default values. The fix is likely localized to the helper that binds parsed template arguments to the inspected function signature, but care is needed to preserve existing behavior and error messages while correctly handling keyword-only defaults and duplicate keyword assignments. Writing regression tests for both simple and inclusion tags (covering keyword-only defaults, overrides, and duplicate keywords) and running the template-related test suite adds meaningful time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 45, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 170,\n  \"justification\": \"The issue is clearly reproducible but requires understanding Django\u2019s template tag argument parsing/binding logic (used by both simple_tag and inclusion_tag) and how it interacts with Python keyword-only parameters and default values. The fix is likely localized to the helper that binds parsed template arguments to the inspected function signature, but care is needed to preserve existing behavior and error messages while correctly handling keyword-only defaults and duplicate keyword assignments. Writing regression tests for both simple and inclusion tags (covering keyword-only defaults, overrides, and duplicate keywords) and running the template-related test suite adds meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 45,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:02.538895"}
{"instance_id": "django__django-12276", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and points to a specific method (`ClearableFileInput.use_required_attribute()`), but an engineer will still need to investigate how `required` attributes are determined across `Widget.render()`, bound fields, and `FileField`/`FileInput` interactions to avoid subtle regressions. The code change is likely small (moving/duplicating logic into `FileInput.use_required_attribute()` and ensuring subclasses behave correctly), but it requires careful consideration of edge cases like initial values, bound data, and clearing behavior. Writing/adjusting regression tests in Django's forms/widget test suite and running the relevant test subset will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and points to a specific method (`ClearableFileInput.use_required_attribute()`), but an engineer will still need to investigate how `required` attributes are determined across `Widget.render()`, bound fields, and `FileField`/`FileInput` interactions to avoid subtle regressions. The code change is likely small (moving/duplicating logic into `FileInput.use_required_attribute()` and ensuring subclasses behave correctly), but it requires careful consideration of edge cases like initial values, bound data, and clearing behavior. Writing/adjusting regression tests in Django's forms/widget test suite and running the relevant test subset will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:03.041333"}
{"instance_id": "django__django-12273", "repo": "django/django", "estimated_minutes": 300.0, "justification": "Fixing `self.pk = None` behavior for multi-table inheritance requires careful investigation of Django's model base internals (especially how parent links and PK assignment interact across inheritance chains and multiple inheritance). The issue has known edge cases (multiple parents) and prior attempted patches caused unrelated test failures, indicating subtle invariants that must be preserved. A correct fix will likely require changes in `django/db/models/base.py` plus targeted regression tests in Django's inheritance-related test suites and verification against broader regression coverage.", "time_breakdown": {"understanding_and_investigation": 120, "implementation": 90, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 300,\n  \"justification\": \"Fixing `self.pk = None` behavior for multi-table inheritance requires careful investigation of Django's model base internals (especially how parent links and PK assignment interact across inheritance chains and multiple inheritance). The issue has known edge cases (multiple parents) and prior attempted patches caused unrelated test failures, indicating subtle invariants that must be preserved. A correct fix will likely require changes in `django/db/models/base.py` plus targeted regression tests in Django's inheritance-related test suites and verification against broader regression coverage.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 120,\n    \"implementation\": 90,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:45:03.872521"}
{"instance_id": "django__django-12325", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This issue is a subtle ORM metaclass/model-construction bug in multi-table inheritance where the selection of the parent link OneToOneField can be confused by additional OneToOneFields to the same base model, and the behavior depends on field definition order. An experienced Django engineer will need time to reproduce, trace ModelBase parent link detection/validation, and ensure the fix preserves backward-compatible behavior across inheritance and relation resolution edge cases. Implementing the fix is likely localized but requires careful ordering/selection logic, and Django-quality regression tests are needed to cover multiple permutations (field order, primary_key vs not, explicit parent_link vs implicit).", "time_breakdown": {"understanding_and_investigation": 85, "implementation": 55, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This issue is a subtle ORM metaclass/model-construction bug in multi-table inheritance where the selection of the parent link OneToOneField can be confused by additional OneToOneFields to the same base model, and the behavior depends on field definition order. An experienced Django engineer will need time to reproduce, trace ModelBase parent link detection/validation, and ensure the fix preserves backward-compatible behavior across inheritance and relation resolution edge cases. Implementing the fix is likely localized but requires careful ordering/selection logic, and Django-quality regression tests are needed to cover multiple permutations (field order, primary_key vs not, explicit parent_link vs implicit).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 85,\n    \"implementation\": 55,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:05.607265"}
{"instance_id": "django__django-12143", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the code change is likely a small and straightforward fix (escaping the formset prefix when interpolating it into a regex), an experienced engineer will need time to understand how the admin changeform uses this pattern and how it could lead to dropped POSTed inline data. The bulk of the effort is creating a reliable regression test that exercises an inline/formset prefix containing regex metacharacters and demonstrates the prior failure mode, then verifying the admin workflow behaves correctly. Running and iterating on Django\u2019s admin test suite and ensuring no regressions across related code paths adds meaningful overhead.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 25, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the code change is likely a small and straightforward fix (escaping the formset prefix when interpolating it into a regex), an experienced engineer will need time to understand how the admin changeform uses this pattern and how it could lead to dropped POSTed inline data. The bulk of the effort is creating a reliable regression test that exercises an inline/formset prefix containing regex metacharacters and demonstrates the prior failure mode, then verifying the admin workflow behaves correctly. Running and iterating on Django\u2019s admin test suite and ensuring no regressions across related code paths adds meaningful overhead.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 25,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:05.646518"}
{"instance_id": "django__django-12304", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-defined but requires investigating how Django\u2019s template engine treats callables and how the new enumeration/Choices classes are implemented, to ensure the fix is applied at the correct level without side effects. The implementation itself is likely small (setting `do_not_call_in_templates = True` on the relevant enum/Choices base classes), but validating behavior across different enum variants and template contexts needs targeted regression tests. Running and verifying the appropriate Django test suites adds additional time due to repository conventions and breadth of coverage.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-defined but requires investigating how Django\u2019s template engine treats callables and how the new enumeration/Choices classes are implemented, to ensure the fix is applied at the correct level without side effects. The implementation itself is likely small (setting `do_not_call_in_templates = True` on the relevant enum/Choices base classes), but validating behavior across different enum variants and template contexts needs targeted regression tests. Running and verifying the appropriate Django test suites adds additional time due to repository conventions and breadth of coverage.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:06.607578"}
{"instance_id": "django__django-13012", "repo": "django/django", "estimated_minutes": 75.0, "justification": "The issue is well-scoped and already includes a proposed patch that clearly explains the root cause (ExpressionWrapper inheriting the default grouping behavior instead of delegating to the wrapped expression). Implementing the fix is small, but time is still needed to confirm no unintended GROUP BY behavior changes and to follow Django\u2019s testing conventions. Writing and validating a regression test in the correct test module, plus running a targeted test suite, makes this more than a trivial one-liner.", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 10, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 75,\n  \"justification\": \"The issue is well-scoped and already includes a proposed patch that clearly explains the root cause (ExpressionWrapper inheriting the default grouping behavior instead of delegating to the wrapped expression). Implementing the fix is small, but time is still needed to confirm no unintended GROUP BY behavior changes and to follow Django\u2019s testing conventions. Writing and validating a regression test in the correct test module, plus running a targeted test suite, makes this more than a trivial one-liner.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 10,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:07.059876"}
{"instance_id": "django__django-12663", "repo": "django/django", "estimated_minutes": 135.0, "justification": "Although the underlying fix is small (adjusting Query.output_field to use Col.target rather than Col.field), confirming the regression and ensuring the change is safe requires non-trivial investigation of Django's ORM expression/lookup preparation path and nested Subquery output_field resolution. The engineer will need to reproduce the failure, understand how SimpleLazyObject is normally coerced for related-field lookups, implement the change, and add a focused regression test covering nested subquery annotations. Running the relevant ORM test suite subset and checking for unintended behavioral impact on other output_field consumers adds additional time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 20, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 135,\n  \"justification\": \"Although the underlying fix is small (adjusting Query.output_field to use Col.target rather than Col.field), confirming the regression and ensuring the change is safe requires non-trivial investigation of Django's ORM expression/lookup preparation path and nested Subquery output_field resolution. The engineer will need to reproduce the failure, understand how SimpleLazyObject is normally coerced for related-field lookups, implement the change, and add a focused regression test covering nested subquery annotations. Running the relevant ORM test suite subset and checking for unintended behavioral impact on other output_field consumers adds additional time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 20,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:07.290671"}
{"instance_id": "django__django-12308", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing readonly admin display for JSONField requires investigating how django.contrib.admin.utils.display_for_field currently formats values and identifying the correct, stable way to detect JSONField instances (including inheritance) without introducing coupling to contrib.postgres. The implementation itself is small but needs careful handling of edge cases like InvalidJSONInput and ensuring the output is valid JSON rather than a Python repr. Writing and running admin regression tests (likely involving ModelAdmin readonly_fields rendering) will take a significant portion of the time due to Django\u2019s test setup and the need to assert HTML-rendered output consistently across backends.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing readonly admin display for JSONField requires investigating how django.contrib.admin.utils.display_for_field currently formats values and identifying the correct, stable way to detect JSONField instances (including inheritance) without introducing coupling to contrib.postgres. The implementation itself is small but needs careful handling of edge cases like InvalidJSONInput and ensuring the output is valid JSON rather than a Python repr. Writing and running admin regression tests (likely involving ModelAdmin readonly_fields rendering) will take a significant portion of the time due to Django\u2019s test setup and the need to assert HTML-rendered output consistently across backends.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:07.537321"}
{"instance_id": "django__django-12050", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This issue is localized to the ORM query construction path (Query.resolve_lookup_value), but it requires careful investigation to confirm exactly where list-to-tuple coercion was introduced and how it impacts different lookup types (e.g., exact vs in). The code change itself is likely small (preserving the original iterable type when resolving nested expressions/values), but it must avoid regressions for other iterables and expression resolution. Writing a reliable regression test is moderately involved because Django core doesn\u2019t ship a PickledField, so the fix will likely require a small custom test field/model to demonstrate that list vs tuple identity affects exact matching.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 40, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This issue is localized to the ORM query construction path (Query.resolve_lookup_value), but it requires careful investigation to confirm exactly where list-to-tuple coercion was introduced and how it impacts different lookup types (e.g., exact vs in). The code change itself is likely small (preserving the original iterable type when resolving nested expressions/values), but it must avoid regressions for other iterables and expression resolution. Writing a reliable regression test is moderately involved because Django core doesn\u2019t ship a PickledField, so the fix will likely require a small custom test field/model to demonstrate that list vs tuple identity affects exact matching.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 40,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:08.862292"}
{"instance_id": "django__django-12741", "repo": "django/django", "estimated_minutes": 150.0, "justification": "This change requires updating a core backend API (DatabaseOperations.execute_sql_flush) and then finding and updating all internal call sites and any backend-specific overrides across Django\u2019s supported database backends. While the behavioral change is small, the work involves careful repository-wide investigation to ensure no lingering callers still pass the removed argument and that subclass signatures remain consistent. Verification will include running the relevant test suites (especially backend/flush-related tests) to ensure no regressions across database backends.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 60, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "4-6", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This change requires updating a core backend API (DatabaseOperations.execute_sql_flush) and then finding and updating all internal call sites and any backend-specific overrides across Django\u2019s supported database backends. While the behavioral change is small, the work involves careful repository-wide investigation to ensure no lingering callers still pass the removed argument and that subclass signatures remain consistent. Verification will include running the relevant test suites (especially backend/flush-related tests) to ensure no regressions across database backends.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 60,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:09.183410"}
{"instance_id": "django__django-12419", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This change is conceptually simple (set a more secure default for the Referrer-Policy header) but requires careful investigation of how SECURE_REFERRER_POLICY currently defaults (e.g., None vs. unset) and how SecurityMiddleware decides whether to emit the header. The engineer will likely need to update default settings, adjust/extend middleware tests to assert the new default behavior, and update documentation and release notes to clearly flag the backwards-incompatible behavior change. Verification includes running the relevant test suite sections and ensuring no unintended interaction with other security headers or settings overrides.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "4-6", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This change is conceptually simple (set a more secure default for the Referrer-Policy header) but requires careful investigation of how SECURE_REFERRER_POLICY currently defaults (e.g., None vs. unset) and how SecurityMiddleware decides whether to emit the header. The engineer will likely need to update default settings, adjust/extend middleware tests to assert the new default behavior, and update documentation and release notes to clearly flag the backwards-incompatible behavior change. Verification includes running the relevant test suite sections and ensuring no unintended interaction with other security headers or settings overrides.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:09.271226"}
{"instance_id": "django__django-12754", "repo": "django/django", "estimated_minutes": 330.0, "justification": "Fixing this requires understanding Django's migration autodetector ordering and dependency resolution, then adjusting operation dependencies so that field removals on a base model occur before creating subclasses that define conflicting fields. The change is subtle because it involves correctly modeling dependencies across inheritance hierarchies and ensuring ordering remains stable for multiple new subclasses sharing the moved field. Proper regression coverage will require adding/adjusting autodetector-focused tests to assert the produced operation ordering and to guard against duplicate or missing RemoveField operations.", "time_breakdown": {"understanding_and_investigation": 130, "implementation": 90, "testing_and_verification": 110}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 330,\n  \"justification\": \"Fixing this requires understanding Django's migration autodetector ordering and dependency resolution, then adjusting operation dependencies so that field removals on a base model occur before creating subclasses that define conflicting fields. The change is subtle because it involves correctly modeling dependencies across inheritance hierarchies and ensuring ordering remains stable for multiple new subclasses sharing the moved field. Proper regression coverage will require adding/adjusting autodetector-focused tests to assert the produced operation ordering and to guard against duplicate or missing RemoveField operations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 130,\n    \"implementation\": 90,\n    \"testing_and_verification\": 110\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:45:09.318282"}
{"instance_id": "django__django-12713", "repo": "django/django", "estimated_minutes": 150.0, "justification": "This issue likely involves Django admin\u2019s ModelAdmin.formfield_for_manytomany() not respecting a user-supplied \"widget\" kwarg because the method (or the defaults it applies) overwrites it, unlike formfield_for_foreignkey(). An engineer will need to trace the admin formfield generation flow (ModelAdmin -> formfield callbacks -> model field formfield()), identify where the widget is lost, and ensure consistent behavior with the foreign key path. The actual code change is probably small, but adding a robust regression test in Django\u2019s admin test suite and verifying no unintended widget-selection regressions will take significant time.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 35, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This issue likely involves Django admin\u2019s ModelAdmin.formfield_for_manytomany() not respecting a user-supplied \\\"widget\\\" kwarg because the method (or the defaults it applies) overwrites it, unlike formfield_for_foreignkey(). An engineer will need to trace the admin formfield generation flow (ModelAdmin -> formfield callbacks -> model field formfield()), identify where the widget is lost, and ensure consistent behavior with the foreign key path. The actual code change is probably small, but adding a robust regression test in Django\u2019s admin test suite and verifying no unintended widget-selection regressions will take significant time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 35,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:09.629312"}
{"instance_id": "django__django-13033", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Although the behavior is well-reproduced and a likely one-line fix is suggested, the engineer still needs to understand Django ORM ordering resolution and join generation to ensure the change doesn\u2019t alter semantics for other relation orderings. Implementing the fix is quick, but adding a regression test in Django\u2019s query/order_by test suite and validating SQL/output across supported databases (at least running the relevant subset locally) will take the bulk of the time. Some extra time is needed to confirm edge cases (order_by on FK vs FK_id, self-referential FK, default Meta.ordering interactions) and to run/interpret tests to avoid regressions.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 30, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the behavior is well-reproduced and a likely one-line fix is suggested, the engineer still needs to understand Django ORM ordering resolution and join generation to ensure the change doesn\u2019t alter semantics for other relation orderings. Implementing the fix is quick, but adding a regression test in Django\u2019s query/order_by test suite and validating SQL/output across supported databases (at least running the relevant subset locally) will take the bulk of the time. Some extra time is needed to confirm edge cases (order_by on FK vs FK_id, self-referential FK, default Meta.ordering interactions) and to run/interpret tests to avoid regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 30,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:10.176096"}
{"instance_id": "django__django-12965", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing this requires investigating why Django 3.1 started emitting a self-referential subquery for QuerySet.delete() (likely in the SQLDeleteCompiler/DeleteQuery logic added for cross-backend correctness) and determining when it is safe to fall back to a simple \"DELETE FROM table\". The implementation will need conditional SQL generation that preserves correctness for complex querysets (joins, slicing, distinct, or backend limitations) while avoiding the subquery for the simple single-table case. Proper regression tests are needed to assert generated SQL (and/or behavior) across backends, and to ensure no regressions for multi-table/complex deletes.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing this requires investigating why Django 3.1 started emitting a self-referential subquery for QuerySet.delete() (likely in the SQLDeleteCompiler/DeleteQuery logic added for cross-backend correctness) and determining when it is safe to fall back to a simple \\\"DELETE FROM table\\\". The implementation will need conditional SQL generation that preserves correctness for complex querysets (joins, slicing, distinct, or backend limitations) while avoiding the subquery for the simple single-table case. Proper regression tests are needed to assert generated SQL (and/or behavior) across backends, and to ensure no regressions for multi-table/complex deletes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:10.209774"}
{"instance_id": "django__django-13023", "repo": "django/django", "estimated_minutes": 90.0, "justification": "This is a well-scoped bug in a single field conversion method: DecimalField.to_python() should consistently raise ValidationError rather than leaking a TypeError when given an invalid type like dict. An experienced Django contributor will still need some time to confirm current behavior, identify the correct exception-handling pattern used by other fields, and ensure the fix matches Django\u2019s validation semantics. The bulk of the time will be spent writing a targeted regression test and running the relevant test suite portions to ensure no behavior regressions for other invalid inputs.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 20, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"This is a well-scoped bug in a single field conversion method: DecimalField.to_python() should consistently raise ValidationError rather than leaking a TypeError when given an invalid type like dict. An experienced Django contributor will still need some time to confirm current behavior, identify the correct exception-handling pattern used by other fields, and ensure the fix matches Django\u2019s validation semantics. The bulk of the time will be spent writing a targeted regression test and running the relevant test suite portions to ensure no behavior regressions for other invalid inputs.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 20,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:11.772524"}
{"instance_id": "django__django-11066", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Although the code change is likely a one-line fix (passing `using=db` to `save()`), an experienced engineer would still need time to trace how `RenameContentType._rename()` is invoked during `RenameModel` migrations and confirm the routing/connection-alias behavior. The main effort is creating a robust regression test that proves the write occurs on the schema editor\u2019s database alias (and does not accidentally write to `default`), which requires multi-database test setup and careful assertions about which connection executed the SQL. Additional time is needed to run Django\u2019s relevant migration/contenttypes test suites and ensure no regressions across supported multi-DB behaviors.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 15, "testing_and_verification": 135}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the code change is likely a one-line fix (passing `using=db` to `save()`), an experienced engineer would still need time to trace how `RenameContentType._rename()` is invoked during `RenameModel` migrations and confirm the routing/connection-alias behavior. The main effort is creating a robust regression test that proves the write occurs on the schema editor\u2019s database alias (and does not accidentally write to `default`), which requires multi-database test setup and careful assertions about which connection executed the SQL. Additional time is needed to run Django\u2019s relevant migration/contenttypes test suites and ensure no regressions across supported multi-DB behaviors.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 15,\n    \"testing_and_verification\": 135\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:12.117610"}
{"instance_id": "django__django-13028", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped with a strong hint pointing to the exact method (Query.check_filterable) and a minimal code change, but an experienced engineer will still need time to confirm the regression, ensure the condition only applies to Django expressions, and avoid breaking existing NotSupportedError behavior. Writing a targeted regression test in Django\u2019s ORM test suite and running relevant test modules (plus quick sanity checks) will dominate the effort due to Django\u2019s conventions and the need to verify no unintended query filtering regressions.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 15, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped with a strong hint pointing to the exact method (Query.check_filterable) and a minimal code change, but an experienced engineer will still need time to confirm the regression, ensure the condition only applies to Django expressions, and avoid breaking existing NotSupportedError behavior. Writing a targeted regression test in Django\u2019s ORM test suite and running relevant test modules (plus quick sanity checks) will dominate the effort due to Django\u2019s conventions and the need to verify no unintended query filtering regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 15,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:12.492673"}
{"instance_id": "django__django-13109", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the code change is likely small (switching ForeignKey.validate() from using the related model\u2019s _default_manager to _base_manager), it affects core model/ORM validation behavior and therefore requires careful investigation for backward-compatibility and edge cases. An experienced engineer will need time to trace how ForeignKey validation is triggered from Model.full_clean()/ModelForm validation, confirm the exact query path in related.py, and ensure the change doesn\u2019t unintentionally bypass intended constraints elsewhere. Writing a focused regression test (and running the relevant Django test suite subset) will take a significant portion of the work to ensure no regressions in related-field validation semantics.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the code change is likely small (switching ForeignKey.validate() from using the related model\u2019s _default_manager to _base_manager), it affects core model/ORM validation behavior and therefore requires careful investigation for backward-compatibility and edge cases. An experienced engineer will need time to trace how ForeignKey validation is triggered from Model.full_clean()/ModelForm validation, confirm the exact query path in related.py, and ensure the change doesn\u2019t unintentionally bypass intended constraints elsewhere. Writing a focused regression test (and running the relevant Django test suite subset) will take a significant portion of the work to ensure no regressions in related-field validation semantics.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:13.427410"}
{"instance_id": "django__django-12774", "repo": "django/django", "estimated_minutes": 120.0, "justification": "Fixing this requires understanding how QuerySet.in_bulk() currently determines whether a field is unique (likely via Field.unique/primary key checks) and extending that logic to also recognize \"total\" UniqueConstraint definitions on a single field. The code change itself should be small, but Django\u2019s ORM has subtle edge cases (e.g., conditional/partial unique constraints, multi-field constraints, expressions), so time is needed to ensure only appropriate constraints qualify. Writing and running regression tests across supported databases and ensuring no regressions in existing uniqueness validation is a significant portion of the work.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"Fixing this requires understanding how QuerySet.in_bulk() currently determines whether a field is unique (likely via Field.unique/primary key checks) and extending that logic to also recognize \\\"total\\\" UniqueConstraint definitions on a single field. The code change itself should be small, but Django\u2019s ORM has subtle edge cases (e.g., conditional/partial unique constraints, multi-field constraints, expressions), so time is needed to ensure only appropriate constraints qualify. Writing and running regression tests across supported databases and ensuring no regressions in existing uniqueness validation is a significant portion of the work.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:13.671656"}
{"instance_id": "django__django-13089", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the failure point is clear (cursor.fetchone() can return None when the culling query yields no rows), the engineer will need to confirm under which conditions the culling SQL returns an empty result across supported database backends and what the correct behavior should be. Implementing a defensive fix is likely small, but Django requires a regression test that reliably reproduces the edge case (e.g., small cache table sizes, specific cull_frequency behavior, or backend-specific SQL semantics). Additional time is needed to run the cache backend test suite and ensure no behavioral regressions for normal culling paths.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 30, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the failure point is clear (cursor.fetchone() can return None when the culling query yields no rows), the engineer will need to confirm under which conditions the culling SQL returns an empty result across supported database backends and what the correct behavior should be. Implementing a defensive fix is likely small, but Django requires a regression test that reliably reproduces the edge case (e.g., small cache table sizes, specific cull_frequency behavior, or backend-specific SQL semantics). Additional time is needed to run the cache backend test suite and ensure no behavioral regressions for normal culling paths.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 30,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:14.646536"}
{"instance_id": "django__django-12708", "repo": "django/django", "estimated_minutes": 240.0, "justification": "Although the crash is reproducible and points to a specific failure site (SchemaEditor._delete_composed_index()), the underlying cause involves Django\u2019s migration operations, constraint introspection, and composed-index naming/selection logic when unique and non-unique constraints overlap. An engineer will likely need to confirm whether the correct fix belongs in the schema editor (choosing the non-unique constraint deterministically) and/or the migration autodetector/optimizer (to avoid drop+recreate when moving declarations). Writing robust regression tests across backends and ensuring no unintended constraint deletions adds meaningful time.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 70, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Although the crash is reproducible and points to a specific failure site (SchemaEditor._delete_composed_index()), the underlying cause involves Django\u2019s migration operations, constraint introspection, and composed-index naming/selection logic when unique and non-unique constraints overlap. An engineer will likely need to confirm whether the correct fix belongs in the schema editor (choosing the non-unique constraint deterministically) and/or the migration autodetector/optimizer (to avoid drop+recreate when moving declarations). Writing robust regression tests across backends and ensuring no unintended constraint deletions adds meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 70,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:45:15.010881"}
{"instance_id": "django__django-11999", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires understanding how Django generates per-field get_FOO_display() methods during ModelBase construction and how the Django 2.2 regression changed attribute/add_to_class ordering. The likely fix is small (avoid clobbering an existing user-defined get_FOO_display() when contributing a field), but it must be done carefully to avoid breaking inheritance and field contribution semantics. Writing regression tests for both attribute orders and ensuring the fix works across supported Python/Django behaviors will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires understanding how Django generates per-field get_FOO_display() methods during ModelBase construction and how the Django 2.2 regression changed attribute/add_to_class ordering. The likely fix is small (avoid clobbering an existing user-defined get_FOO_display() when contributing a field), but it must be done carefully to avoid breaking inheritance and field contribution semantics. Writing regression tests for both attribute orders and ensuring the fix works across supported Python/Django behaviors will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:15.043770"}
{"instance_id": "django__django-13121", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The issue is reproducible and points to a failure in DurationField result conversion when a duration-only annotation expression is evaluated on SQLite/MySQL, implying a backend-specific mismatch between the database-returned type (often a string) and Django\u2019s expected numeric microseconds representation. Fixing it likely requires investigating how duration arithmetic expressions are compiled/cast per backend and adjusting either the expression output type/casting or the backend duration converter to accept the returned format. Because this touches ORM expressions and at least two database backends, the change must be validated with targeted regression tests and full backend test runs to avoid breaking existing duration/date arithmetic behavior.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 60, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is reproducible and points to a failure in DurationField result conversion when a duration-only annotation expression is evaluated on SQLite/MySQL, implying a backend-specific mismatch between the database-returned type (often a string) and Django\u2019s expected numeric microseconds representation. Fixing it likely requires investigating how duration arithmetic expressions are compiled/cast per backend and adjusting either the expression output type/casting or the backend duration converter to accept the returned format. Because this touches ORM expressions and at least two database backends, the change must be validated with targeted regression tests and full backend test runs to avoid breaking existing duration/date arithmetic behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 60,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:15.791714"}
{"instance_id": "django__django-13112", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the proposed code change is small and localized (adjusting how string-based related targets are lowercased during deconstruction), an engineer will still need time to confirm the regression source, understand the migration serialization/deconstruction pathway, and ensure no unintended behavior changes for existing migrations. Writing a robust regression test in Django\u2019s migrations/model field test suite and running the relevant test subsets (and possibly a broader suite) will dominate the effort. The issue is well-scoped with a known offending commit and a clear patch direction, keeping debugging difficulty moderate.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 30, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the proposed code change is small and localized (adjusting how string-based related targets are lowercased during deconstruction), an engineer will still need time to confirm the regression source, understand the migration serialization/deconstruction pathway, and ensure no unintended behavior changes for existing migrations. Writing a robust regression test in Django\u2019s migrations/model field test suite and running the relevant test subsets (and possibly a broader suite) will dominate the effort. The issue is well-scoped with a known offending commit and a clear patch direction, keeping debugging difficulty moderate.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 30,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:16.046389"}
{"instance_id": "django__django-12406", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Fixing this requires understanding how ModelForm builds a ModelChoiceField for ForeignKey fields and how/why an empty choice (\"---------\") is injected and then auto-selected by RadioSelect when the instance value is None. The code change is likely small (adjusting empty_label/choices behavior specifically for RadioSelect when the model field is required), but it touches Django\u2019s form-field generation conventions and must avoid regressions for Select widgets where a blank choice is intentionally used to prevent implicit selection. Writing a focused regression test (and running the relevant form/widget test suite) adds meaningful time due to Django\u2019s test patterns and ensuring cross-widget behavior remains correct.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing this requires understanding how ModelForm builds a ModelChoiceField for ForeignKey fields and how/why an empty choice (\\\"---------\\\") is injected and then auto-selected by RadioSelect when the instance value is None. The code change is likely small (adjusting empty_label/choices behavior specifically for RadioSelect when the model field is required), but it touches Django\u2019s form-field generation conventions and must avoid regressions for Select widgets where a blank choice is intentionally used to prevent implicit selection. Writing a focused regression test (and running the relevant form/widget test suite) adds meaningful time due to Django\u2019s test patterns and ensuring cross-widget behavior remains correct.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:17.322606"}
{"instance_id": "django__django-12858", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires investigating Django's model system check that validates Meta.ordering (models.E015) and understanding why it rejects lookup suffixes like \"__isnull\" even though QuerySet.order_by() successfully resolves them. The likely fix involves adjusting the ordering validation to use (or more closely mirror) the ORM's actual path/lookup resolution logic, which touches core model-checking code and must be done carefully to avoid allowing genuinely invalid orderings. A regression test must be added to ensure lookups (not just transforms) are accepted where the ORM supports them and that existing E015 behavior remains intact for truly invalid references.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires investigating Django's model system check that validates Meta.ordering (models.E015) and understanding why it rejects lookup suffixes like \\\"__isnull\\\" even though QuerySet.order_by() successfully resolves them. The likely fix involves adjusting the ordering validation to use (or more closely mirror) the ORM's actual path/lookup resolution logic, which touches core model-checking code and must be done carefully to avoid allowing genuinely invalid orderings. A regression test must be added to ensure lookups (not just transforms) are accepted where the ORM supports them and that existing E015 behavior remains intact for truly invalid references.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:18.361597"}
{"instance_id": "django__django-13128", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing this requires understanding how Django ORM infers (or fails to infer) output_field for combined temporal expressions, particularly when chaining DateTime subtraction with Duration addition. The change will likely involve adjusting expression type resolution (e.g., CombinedExpression/temporal subtraction handling) so the resulting type is inferred as a DurationField without requiring an ExpressionWrapper, while ensuring behavior remains consistent across database backends. Proper regression tests must be added to cover the exact failing pattern and confirm no regressions in other date/time arithmetic cases.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 60, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing this requires understanding how Django ORM infers (or fails to infer) output_field for combined temporal expressions, particularly when chaining DateTime subtraction with Duration addition. The change will likely involve adjusting expression type resolution (e.g., CombinedExpression/temporal subtraction handling) so the resulting type is inferred as a DurationField without requiring an ExpressionWrapper, while ensuring behavior remains consistent across database backends. Proper regression tests must be added to cover the exact failing pattern and confirm no regressions in other date/time arithmetic cases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 60,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:18.724871"}
{"instance_id": "django__django-13343", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Fixing this requires understanding how FileField stores the original `storage` argument versus how it resolves the runtime storage (callable vs instance), and locating where deconstruction currently forces evaluation. The implementation is likely a small change in `FileField.deconstruct()` (or related helper) to preserve the callable reference, but it must be done carefully to avoid breaking existing migration serialization behavior. A regression test should assert that `deconstruct()` returns the original callable (similar to `upload_to`) and that migration writing/serialization doesn\u2019t inline the evaluated storage, requiring running Django\u2019s model field and migration test suites.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 35, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing this requires understanding how FileField stores the original `storage` argument versus how it resolves the runtime storage (callable vs instance), and locating where deconstruction currently forces evaluation. The implementation is likely a small change in `FileField.deconstruct()` (or related helper) to preserve the callable reference, but it must be done carefully to avoid breaking existing migration serialization behavior. A regression test should assert that `deconstruct()` returns the original callable (similar to `upload_to`) and that migration writing/serialization doesn\u2019t inline the evaluated storage, requiring running Django\u2019s model field and migration test suites.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 35,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:18.735531"}
{"instance_id": "django__django-13212", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This change requires auditing Django\u2019s built-in validators to ensure they consistently include the input value in the raised ValidationError (typically via the params dict), without breaking existing params such as limit_value or other interpolation keys. Although the core code change is small, it touches many validator implementations and will likely require updating/adding tests to assert the new params behavior across multiple validator classes. Extra time is needed to confirm backwards compatibility (e.g., message overriding, i18n strings, existing %(...)s placeholders) and to run the relevant test suites to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "4-6", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This change requires auditing Django\u2019s built-in validators to ensure they consistently include the input value in the raised ValidationError (typically via the params dict), without breaking existing params such as limit_value or other interpolation keys. Although the core code change is small, it touches many validator implementations and will likely require updating/adding tests to assert the new params behavior across multiple validator classes. Extra time is needed to confirm backwards compatibility (e.g., message overriding, i18n strings, existing %(...)s placeholders) and to run the relevant test suites to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:18.968488"}
{"instance_id": "django__django-13344", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the underlying cause is relatively clear (several middlewares override __init__ without calling super().__init__(), preventing MiddlewareMixin\u2019s async bookkeeping), an engineer will still need time to trace the ASGI middleware execution path and confirm exactly which classes are affected. The fix is small but must be applied consistently across multiple middleware classes (SecurityMiddleware and cache-related middlewares) while maintaining backwards compatibility. Writing a robust regression test for ASGI middleware chaining and ensuring it fails pre-fix and passes post-fix will take a significant portion of the time, along with running the relevant Django test suite to avoid regressions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the underlying cause is relatively clear (several middlewares override __init__ without calling super().__init__(), preventing MiddlewareMixin\u2019s async bookkeeping), an engineer will still need time to trace the ASGI middleware execution path and confirm exactly which classes are affected. The fix is small but must be applied consistently across multiple middleware classes (SecurityMiddleware and cache-related middlewares) while maintaining backwards compatibility. Writing a robust regression test for ASGI middleware chaining and ensuring it fails pre-fix and passes post-fix will take a significant portion of the time, along with running the relevant Django test suite to avoid regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:19.308811"}
{"instance_id": "django__django-13195", "repo": "django/django", "estimated_minutes": 150.0, "justification": "This change requires investigating Django's current HttpResponseBase.delete_cookie() behavior, how it delegates to set_cookie(), and how SameSite is represented in Django\u2019s cookie machinery. The implementation is likely small (adding a samesite argument and ensuring it is emitted on the deletion Set-Cookie header), but it must be done in a backwards-compatible way and aligned with existing conventions and documentation. The bulk of time will be spent writing/adjusting tests to assert correct Set-Cookie output (including SameSite, Secure interactions, and defaults) and running the relevant test suite to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This change requires investigating Django's current HttpResponseBase.delete_cookie() behavior, how it delegates to set_cookie(), and how SameSite is represented in Django\u2019s cookie machinery. The implementation is likely small (adding a samesite argument and ensuring it is emitted on the deletion Set-Cookie header), but it must be done in a backwards-compatible way and aligned with existing conventions and documentation. The bulk of time will be spent writing/adjusting tests to assert correct Set-Cookie output (including SameSite, Secure interactions, and defaults) and running the relevant test suite to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:19.498536"}
{"instance_id": "django__django-13315", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing duplicate form choices caused by `limit_choices_to` with joins requires tracing how Django builds the queryset for `ForeignKey.formfield()`/`ModelChoiceField` and where duplicates are introduced. The prior naive fix of adding `.distinct()` was reverted due to backend/custom-field incompatibilities (e.g., PostgreSQL types that can\u2019t be compared for DISTINCT), so the engineer must design a safer de-duplication approach (often via PK-based grouping/annotation or Python-side de-duping) and ensure it doesn\u2019t reintroduce `MultipleObjectsReturned` when a duplicate is selected. Writing/adjusting regression tests and running them across relevant DB backends (at least SQLite plus verifying Postgres behavior) adds meaningful time due to setup and iteration.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 70, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing duplicate form choices caused by `limit_choices_to` with joins requires tracing how Django builds the queryset for `ForeignKey.formfield()`/`ModelChoiceField` and where duplicates are introduced. The prior naive fix of adding `.distinct()` was reverted due to backend/custom-field incompatibilities (e.g., PostgreSQL types that can\u2019t be compared for DISTINCT), so the engineer must design a safer de-duplication approach (often via PK-based grouping/annotation or Python-side de-duping) and ensure it doesn\u2019t reintroduce `MultipleObjectsReturned` when a duplicate is selected. Writing/adjusting regression tests and running them across relevant DB backends (at least SQLite plus verifying Postgres behavior) adds meaningful time due to setup and iteration.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 70,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:19.837173"}
{"instance_id": "django__django-13401", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires locating and understanding Django's current Field comparison semantics (__eq__/__hash__/__lt__) and where field equality is relied on (e.g., Meta options, model construction, ordering, and potentially migration/state comparisons). The implementation change is conceptually small but must be done carefully to avoid altering ordering behavior broadly, as the issue notes at least one ordering-sensitive test. Writing a targeted regression test plus running and iterating on affected test modules (and possibly a wider suite slice) is likely the most time-consuming part.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires locating and understanding Django's current Field comparison semantics (__eq__/__hash__/__lt__) and where field equality is relied on (e.g., Meta options, model construction, ordering, and potentially migration/state comparisons). The implementation change is conceptually small but must be done carefully to avoid altering ordering behavior broadly, as the issue notes at least one ordering-sensitive test. Writing a targeted regression test plus running and iterating on affected test modules (and possibly a wider suite slice) is likely the most time-consuming part.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:20.365246"}
{"instance_id": "django__django-13363", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The issue is well-scoped (TruncDate/TruncTime override as_sql and ignore the tzinfo provided by TimeZoneMixin), but it requires careful investigation of Django's datetime function compilation paths across database backends. The implementation is likely a small refactor to reuse the existing timezone handling helper/superclass logic, yet it must preserve existing SQL generation semantics. The bulk of the effort will be adding/adjusting tests to prove correct behavior for non-current timezones and ensuring the change doesn\u2019t regress backend-specific behavior.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-scoped (TruncDate/TruncTime override as_sql and ignore the tzinfo provided by TimeZoneMixin), but it requires careful investigation of Django's datetime function compilation paths across database backends. The implementation is likely a small refactor to reuse the existing timezone handling helper/superclass logic, yet it must preserve existing SQL generation semantics. The bulk of the effort will be adding/adjusting tests to prove correct behavior for non-current timezones and ensuring the change doesn\u2019t regress backend-specific behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:21.185542"}
{"instance_id": "django__django-13449", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing this requires understanding how SQLiteNumericMixin wraps DecimalField expressions with CAST() and how that interacts with Window/LAG SQL generation on SQLite, since the current CAST placement breaks window function syntax. The issue is reproducible with a clear SQL example, but the correct fix must be carefully scoped to avoid changing Decimal handling for non-window expressions and to preserve behavior across backends. Implementing the adjustment likely involves changes in expression/window compilation plus adding a focused regression test in Django's window function test suite and running the SQLite test matrix to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing this requires understanding how SQLiteNumericMixin wraps DecimalField expressions with CAST() and how that interacts with Window/LAG SQL generation on SQLite, since the current CAST placement breaks window function syntax. The issue is reproducible with a clear SQL example, but the correct fix must be carefully scoped to avoid changing Decimal handling for non-window expressions and to preserve behavior across backends. Implementing the adjustment likely involves changes in expression/window compilation plus adding a focused regression test in Django's window function test suite and running the SQLite test matrix to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:21.451437"}
{"instance_id": "django__django-13417", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This requires understanding how QuerySet.ordered is computed versus when SQLCompiler actually emits an ORDER BY, particularly for annotate()/GROUP BY queries where Meta.ordering is intentionally suppressed. The fix likely involves adjusting the ordered property logic (or the query state it inspects) to account for group_by/aggregation behavior introduced by the referenced change, plus adding a regression test that covers models with Meta.ordering. Time is driven by the need to trace query compilation paths, ensure the change matches Django\u2019s intended semantics, and run the relevant test suites to avoid regressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 45, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This requires understanding how QuerySet.ordered is computed versus when SQLCompiler actually emits an ORDER BY, particularly for annotate()/GROUP BY queries where Meta.ordering is intentionally suppressed. The fix likely involves adjusting the ordered property logic (or the query state it inspects) to account for group_by/aggregation behavior introduced by the referenced change, plus adding a regression test that covers models with Meta.ordering. Time is driven by the need to trace query compilation paths, ensure the change matches Django\u2019s intended semantics, and run the relevant test suites to avoid regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 45,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:22.468600"}
{"instance_id": "django__django-13279", "repo": "django/django", "estimated_minutes": 240.0, "justification": "The issue involves a subtle backwards-compatibility problem in Django\u2019s session encoding/signing format across the 3.0\u21923.1 transition, which requires careful investigation of how the session payload is serialized, signed, and versioned. Implementing a conditional \u201clegacy encode\u201d path tied to DEFAULT_HASHING_ALGORITHM == 'sha1' is relatively small in code size but risky in behavior, so it needs targeted tests proving cross-version readability and ensuring no regression for the default algorithm. Verifying the fix will also require running the relevant Django session test suite and ensuring both legacy and new formats decode correctly under the right settings.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"The issue involves a subtle backwards-compatibility problem in Django\u2019s session encoding/signing format across the 3.0\u21923.1 transition, which requires careful investigation of how the session payload is serialized, signed, and versioned. Implementing a conditional \u201clegacy encode\u201d path tied to DEFAULT_HASHING_ALGORITHM == 'sha1' is relatively small in code size but risky in behavior, so it needs targeted tests proving cross-version readability and ensuring no regression for the default algorithm. Verifying the fix will also require running the relevant Django session test suite and ensuring both legacy and new formats decode correctly under the right settings.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:45:22.696098"}
{"instance_id": "django__django-13158", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This issue is a subtle ORM edge case: QuerySet.none() is expected to produce an empty queryset, but when the queryset is a combined (union/intersection/difference) queryset it appears to lose the \u201cempty\u201d constraint and evaluates to the full combined result set. Fixing it likely requires understanding how Django represents combined queries internally (combinator queries) and ensuring the empty-query flag propagates correctly, then adding regression tests that reproduce the admin/form ManyToMany empty-submit behavior. The change is probably localized but needs careful verification across supported DB backends and existing queryset combination semantics.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This issue is a subtle ORM edge case: QuerySet.none() is expected to produce an empty queryset, but when the queryset is a combined (union/intersection/difference) queryset it appears to lose the \u201cempty\u201d constraint and evaluates to the full combined result set. Fixing it likely requires understanding how Django represents combined queries internally (combinator queries) and ensuring the empty-query flag propagates correctly, then adding regression tests that reproduce the admin/form ManyToMany empty-submit behavior. The change is probably localized but needs careful verification across supported DB backends and existing queryset combination semantics.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:23.046974"}
{"instance_id": "django__django-13410", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The code change itself is small and well-specified (fcntl.flock() returns None on success and raises OSError on failure), so implementation is straightforward. The main time cost is adding reliable regression tests that exercise non-blocking lock acquisition failure on POSIX, which typically requires a second process because fcntl locks are per-process and can be hard to test deterministically within a single process. Additional time is needed to find the right existing test location/patterns in Django\u2019s suite and to run/verify platform-conditional behavior without introducing flaky tests.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 15, "testing_and_verification": 95}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The code change itself is small and well-specified (fcntl.flock() returns None on success and raises OSError on failure), so implementation is straightforward. The main time cost is adding reliable regression tests that exercise non-blocking lock acquisition failure on POSIX, which typically requires a second process because fcntl locks are per-process and can be hard to test deterministically within a single process. Additional time is needed to find the right existing test location/patterns in Django\u2019s suite and to run/verify platform-conditional behavior without introducing flaky tests.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 15,\n    \"testing_and_verification\": 95\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:24.737646"}
{"instance_id": "django__django-13512", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped: Django's JSONField form/admin display uses json.dumps() defaults, which escape non-ASCII characters, and the fix is likely to pass ensure_ascii=False in the code path that prepares values for display. Even though the code change is small, an engineer will need to confirm it only affects rendering (not DB serialization), identify the correct hook (form field vs widget), and ensure consistency with existing encoder usage. Updating/adding regression tests for non-ASCII (e.g., Chinese) and running the relevant Django test suite will take a significant portion of the time due to project conventions and CI-style validation.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped: Django's JSONField form/admin display uses json.dumps() defaults, which escape non-ASCII characters, and the fix is likely to pass ensure_ascii=False in the code path that prepares values for display. Even though the code change is small, an engineer will need to confirm it only affects rendering (not DB serialization), identify the correct hook (form field vs widget), and ensure consistency with existing encoder usage. Updating/adding regression tests for non-ASCII (e.g., Chinese) and running the relevant Django test suite will take a significant portion of the time due to project conventions and CI-style validation.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:25.017305"}
{"instance_id": "django__django-13568", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Fixing auth.E003 requires investigating Django\u2019s auth system checks to see how it currently determines whether USERNAME_FIELD is unique, then extending that logic to treat an unconditional single-field UniqueConstraint as satisfying the requirement. The change is localized but needs careful handling of constraint edge cases (e.g., multi-field constraints, conditional/partial constraints, expressions) to avoid weakening the check incorrectly. Adding targeted regression tests in Django\u2019s auth check test suite and running relevant test modules accounts for a substantial portion of the effort.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 45, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing auth.E003 requires investigating Django\u2019s auth system checks to see how it currently determines whether USERNAME_FIELD is unique, then extending that logic to treat an unconditional single-field UniqueConstraint as satisfying the requirement. The change is localized but needs careful handling of constraint edge cases (e.g., multi-field constraints, conditional/partial constraints, expressions) to avoid weakening the check incorrectly. Adding targeted regression tests in Django\u2019s auth check test suite and running relevant test modules accounts for a substantial portion of the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 45,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:25.130548"}
{"instance_id": "django__django-13513", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The bug is well-scoped to Django\u2019s debug traceback rendering (django/views/debug.py) and has a clear root cause: the helper that walks exception causes ignores __suppress_context__. While the code change itself is small, a contributor must understand Django\u2019s traceback frame extraction and ensure behavior matches Python\u2019s exception display semantics. Most of the time will go into adding/adjusting regression tests that exercise the technical 500 debug page output and verifying no regressions in chained-exception rendering.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 15, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The bug is well-scoped to Django\u2019s debug traceback rendering (django/views/debug.py) and has a clear root cause: the helper that walks exception causes ignores __suppress_context__. While the code change itself is small, a contributor must understand Django\u2019s traceback frame extraction and ensure behavior matches Python\u2019s exception display semantics. Most of the time will go into adding/adjusting regression tests that exercise the technical 500 debug page output and verifying no regressions in chained-exception rendering.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 15,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:25.822168"}
{"instance_id": "django__django-13590", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-described and points directly at django.db.models.sql.query.Query.resolve_lookup_value, but an engineer will still need time to confirm the exact code path differences between 2.2 and 3.0 and reproduce the failure with a minimal ORM query. The fix is likely small (expanding an iterator when reconstructing the tuple to support namedtuple constructors), but it touches core queryset/lookup resolution logic and must preserve behavior for normal tuples and other iterable types. Writing a regression test for namedtuple values in a __range lookup and running Django\u2019s relevant test suite is a non-trivial portion of the work.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-described and points directly at django.db.models.sql.query.Query.resolve_lookup_value, but an engineer will still need time to confirm the exact code path differences between 2.2 and 3.0 and reproduce the failure with a minimal ORM query. The fix is likely small (expanding an iterator when reconstructing the tuple to support namedtuple constructors), but it touches core queryset/lookup resolution logic and must preserve behavior for normal tuples and other iterable types. Writing a regression test for namedtuple values in a __range lookup and running Django\u2019s relevant test suite is a non-trivial portion of the work.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:25.875332"}
{"instance_id": "django__django-13569", "repo": "django/django", "estimated_minutes": 240.0, "justification": "Although the reproduction is clear, the underlying behavior sits in Django ORM\u2019s SQL compiler and interacts with documented rules about how ORDER BY affects GROUP BY, so an engineer will need time to confirm intended semantics across backends. Implementing a safe change (e.g., excluding Random()/order-by expressions without column references while preserving raw SQL and edge cases) requires careful reasoning and likely a small refactor. A significant portion of the time will be spent writing/adjusting ORM tests and validating the behavior on multiple databases (SQLite/PostgreSQL/MySQL) to avoid regressions in grouping and ordering.", "time_breakdown": {"understanding_and_investigation": 105, "implementation": 55, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Although the reproduction is clear, the underlying behavior sits in Django ORM\u2019s SQL compiler and interacts with documented rules about how ORDER BY affects GROUP BY, so an engineer will need time to confirm intended semantics across backends. Implementing a safe change (e.g., excluding Random()/order-by expressions without column references while preserving raw SQL and edge cases) requires careful reasoning and likely a small refactor. A significant portion of the time will be spent writing/adjusting ORM tests and validating the behavior on multiple databases (SQLite/PostgreSQL/MySQL) to avoid regressions in grouping and ordering.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 105,\n    \"implementation\": 55,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:45:26.929931"}
{"instance_id": "django__django-13670", "repo": "django/django", "estimated_minutes": 90.0, "justification": "The issue is clearly reproducible and likely localized to the implementation of the \"y\" format character in django.utils.dateformat, but an engineer will still need to confirm current behavior across related format tokens and ensure consistency with Django\u2019s documented semantics. The code change itself should be small (e.g., ensuring a two-digit, zero-padded year modulo 100), but Django requires solid regression tests covering edge cases (years < 1000, < 100, < 10) and verification that no other date formatting behavior changes. Running the relevant unit tests and doing a quick broader sanity check accounts for a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 20, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clearly reproducible and likely localized to the implementation of the \\\"y\\\" format character in django.utils.dateformat, but an engineer will still need to confirm current behavior across related format tokens and ensure consistency with Django\u2019s documented semantics. The code change itself should be small (e.g., ensuring a two-digit, zero-padded year modulo 100), but Django requires solid regression tests covering edge cases (years < 1000, < 100, < 10) and verification that no other date formatting behavior changes. Running the relevant unit tests and doing a quick broader sanity check accounts for a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 20,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:27.225522"}
{"instance_id": "django__django-13807", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The root cause is clear and localized: SQLite's constraint-checking PRAGMA statements interpolate raw table names, which breaks when the name is a reserved keyword. Implementing the fix is small (quoting via connection.ops.quote_name()), but Django requires a proper regression test that reproduces the loaddata failure on SQLite and verifies no regressions. Most time will be spent identifying the best existing test location/pattern (fixtures/loaddata + SQLite-only behavior), creating/adjusting fixtures or models, and running the relevant test suite.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 25, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The root cause is clear and localized: SQLite's constraint-checking PRAGMA statements interpolate raw table names, which breaks when the name is a reserved keyword. Implementing the fix is small (quoting via connection.ops.quote_name()), but Django requires a proper regression test that reproduces the loaddata failure on SQLite and verifies no regressions. Most time will be spent identifying the best existing test location/pattern (fixtures/loaddata + SQLite-only behavior), creating/adjusting fixtures or models, and running the relevant test suite.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 25,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:28.791376"}
{"instance_id": "django__django-13786", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires understanding how migration squashing/optimization uses CreateModel.reduce() and how AlterModelOptions.state_forwards() interprets an empty options dict as \u201cunset relevant option keys\u201d. The code change is likely localized (adjusting CreateModel.reduce() to account for AlterModelOptions.ALTER_OPTION_KEYS and option removals), but getting the semantics right and avoiding regressions across various option combinations will take time. Writing a focused regression test that exercises the optimizer/squash path (not just state application) and running the relevant Django migration test suite adds a significant portion of the effort.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires understanding how migration squashing/optimization uses CreateModel.reduce() and how AlterModelOptions.state_forwards() interprets an empty options dict as \u201cunset relevant option keys\u201d. The code change is likely localized (adjusting CreateModel.reduce() to account for AlterModelOptions.ALTER_OPTION_KEYS and option removals), but getting the semantics right and avoiding regressions across various option combinations will take time. Writing a focused regression test that exercises the optimizer/squash path (not just state application) and running the relevant Django migration test suite adds a significant portion of the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:29.366650"}
{"instance_id": "django__django-13925", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This issue is a regression introduced during Django 3.2\u2019s DEFAULT_AUTO_FIELD work, where the model system check incorrectly flags models that inherit a manually defined primary key from an abstract/base parent. Fixing it requires tracing how Django determines whether a PK is \u201cauto-created\u201d (especially across model inheritance) and adjusting the check logic without breaking the intended new warning behavior. A regression test must be added to cover inherited custom PK fields and ensure the warning is only emitted when a PK is truly auto-created, followed by running the relevant test suite subset to guard against related regressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This issue is a regression introduced during Django 3.2\u2019s DEFAULT_AUTO_FIELD work, where the model system check incorrectly flags models that inherit a manually defined primary key from an abstract/base parent. Fixing it requires tracing how Django determines whether a PK is \u201cauto-created\u201d (especially across model inheritance) and adjusting the check logic without breaking the intended new warning behavior. A regression test must be added to cover inherited custom PK fields and ensure the warning is only emitted when a PK is truly auto-created, followed by running the relevant test suite subset to guard against related regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:31.474430"}
{"instance_id": "django__django-13741", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the core code change is small (setting `disabled=True` by default on `ReadOnlyPasswordHashField`), an engineer will need to verify how it interacts with `UserChangeForm`, the admin user edit form, and any code paths that currently rely on `clean_password()` to preserve the initial value. Proper tests should be added/updated to ensure tampered POSTed password-hash values are ignored and that existing behavior remains stable across supported configurations. Some documentation updates are likely needed because the docs currently instruct custom forms to implement `clean_password()`, and this guidance may need adjustment or clarification for `ReadOnlyPasswordHashField` usage.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the core code change is small (setting `disabled=True` by default on `ReadOnlyPasswordHashField`), an engineer will need to verify how it interacts with `UserChangeForm`, the admin user edit form, and any code paths that currently rely on `clean_password()` to preserve the initial value. Proper tests should be added/updated to ensure tampered POSTed password-hash values are ignored and that existing behavior remains stable across supported configurations. Some documentation updates are likely needed because the docs currently instruct custom forms to implement `clean_password()`, and this guidance may need adjustment or clarification for `ReadOnlyPasswordHashField` usage.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:31.775180"}
{"instance_id": "django__django-13794", "repo": "django/django", "estimated_minutes": 120.0, "justification": "This issue is fairly well-scoped (a specific template filter raises a TypeError when adding a lazy string), but it requires investigating Django\u2019s template filter implementation and its expected coercion/escaping behavior. The actual code change is likely small (coercing lazy strings/Promises to real strings before concatenation), but care is needed to avoid altering numeric-add behavior or SafeString/autoescape semantics. Adding and validating a regression test (and running the relevant Django template test suite) contributes a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"This issue is fairly well-scoped (a specific template filter raises a TypeError when adding a lazy string), but it requires investigating Django\u2019s template filter implementation and its expected coercion/escaping behavior. The actual code change is likely small (coercing lazy strings/Promises to real strings before concatenation), but care is needed to avoid altering numeric-add behavior or SafeString/autoescape semantics. Adding and validating a regression test (and running the relevant Django template test suite) contributes a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:32.782751"}
{"instance_id": "django__django-13551", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-scoped (password reset tokens should become invalid when the user\u2019s email changes) but requires careful integration with Django\u2019s generic user model APIs to avoid breaking custom user models. Implementing the fix is likely small (adjusting PasswordResetTokenGenerator._make_hash_value()), but adding a robust regression test and ensuring compatibility with different EMAIL_FIELD configurations and existing token behavior will take additional time. Verification typically involves running the relevant auth test suite and checking for unintended token invalidation changes.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped (password reset tokens should become invalid when the user\u2019s email changes) but requires careful integration with Django\u2019s generic user model APIs to avoid breaking custom user models. Implementing the fix is likely small (adjusting PasswordResetTokenGenerator._make_hash_value()), but adding a robust regression test and ensuring compatibility with different EMAIL_FIELD configurations and existing token behavior will take additional time. Verification typically involves running the relevant auth test suite and checking for unintended token invalidation changes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:32.822533"}
{"instance_id": "django__django-13820", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the code change in MigrationLoader.load_disk is likely small, the engineer will need to carefully verify Django\u2019s existing namespace-package detection logic and how it interacts with Python\u2019s import machinery. The main effort will be in crafting reliable tests that simulate a module/package with no __file__ but that is not a PEP-420 namespace package, and ensuring the loader still rejects true namespace packages. Running and iterating on Django\u2019s test suite (at least the migrations-related subset) and confirming no regressions will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the code change in MigrationLoader.load_disk is likely small, the engineer will need to carefully verify Django\u2019s existing namespace-package detection logic and how it interacts with Python\u2019s import machinery. The main effort will be in crafting reliable tests that simulate a module/package with no __file__ but that is not a PEP-420 namespace package, and ensuring the loader still rejects true namespace packages. Running and iterating on Django\u2019s test suite (at least the migrations-related subset) and confirming no regressions will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:34.273238"}
{"instance_id": "django__django-13810", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This issue sits in Django\u2019s request handler/middleware loading path where subtle sync/async adaptation logic can be accidentally altered when MiddlewareNotUsed is raised. An experienced engineer will need time to reproduce the behavior under ASGI, trace how the middleware chain is constructed, and confirm the exact poisoning mechanism described (handler overwritten after adapt_method_mode()). The fix is likely small but must be carefully placed to avoid changing middleware ordering/compatibility semantics, and it requires a focused regression test exercising ASGI + sync-only middleware + MiddlewareNotUsed interaction.", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 45, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This issue sits in Django\u2019s request handler/middleware loading path where subtle sync/async adaptation logic can be accidentally altered when MiddlewareNotUsed is raised. An experienced engineer will need time to reproduce the behavior under ASGI, trace how the middleware chain is constructed, and confirm the exact poisoning mechanism described (handler overwritten after adapt_method_mode()). The fix is likely small but must be carefully placed to avoid changing middleware ordering/compatibility semantics, and it requires a focused regression test exercising ASGI + sync-only middleware + MiddlewareNotUsed interaction.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 45,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:34.522420"}
{"instance_id": "django__django-13964", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue has a clear reproduction case and a strong hint pointing to a likely fix in Model._prepare_related_fields_for_save(), but confirming the behavior across field types (CharField PK, nullable/non-nullable, empty string vs None) requires targeted investigation in Django\u2019s model save mechanics. Implementing the change is likely small (one conditional) but needs careful validation to avoid changing semantics for legitimate empty values and to ensure no regressions for other relation/PK combinations. Writing a regression test that exercises deferred constraints inside an atomic transaction and verifying behavior across supported databases adds moderate test complexity and runtime.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 25, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue has a clear reproduction case and a strong hint pointing to a likely fix in Model._prepare_related_fields_for_save(), but confirming the behavior across field types (CharField PK, nullable/non-nullable, empty string vs None) requires targeted investigation in Django\u2019s model save mechanics. Implementing the change is likely small (one conditional) but needs careful validation to avoid changing semantics for legitimate empty values and to ensure no regressions for other relation/PK combinations. Writing a regression test that exercises deferred constraints inside an atomic transaction and verifying behavior across supported databases adds moderate test complexity and runtime.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 25,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:34.837969"}
{"instance_id": "django__django-13821", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Dropping support for SQLite < 3.9.0 requires identifying all existing version guards, compatibility code paths, and documentation claims across Django\u2019s SQLite backend. The implementation is typically straightforward (update minimum version checks and remove obsolete feature flags/workarounds), but it requires careful review to avoid regressions in schema/editor and feature detection. Testing will involve updating/adding assertions around version gating and running the relevant backend test suite, even though reproducing truly old SQLite in CI may not be feasible.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "4-6", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Dropping support for SQLite < 3.9.0 requires identifying all existing version guards, compatibility code paths, and documentation claims across Django\u2019s SQLite backend. The implementation is typically straightforward (update minimum version checks and remove obsolete feature flags/workarounds), but it requires careful review to avoid regressions in schema/editor and feature detection. Testing will involve updating/adding assertions around version gating and running the relevant backend test suite, even though reproducing truly old SQLite in CI may not be feasible.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:35.706045"}
{"instance_id": "django__django-13837", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-specified (replace the current \"python -m django\" detection logic with a __main__.__spec__.parent-based check), but it still requires reading Django's autoreload implementation to ensure the new detection integrates correctly with existing argument reconstruction. Implementing the change is relatively small, yet verifying correctness demands careful tests that simulate different interpreter entry modes (-m package, script path, directory/zip execution) without relying on __file__. Time is dominated by designing robust tests and running Django's test suite to ensure no regressions in autoreloader behavior across platforms/Python versions.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-specified (replace the current \\\"python -m django\\\" detection logic with a __main__.__spec__.parent-based check), but it still requires reading Django's autoreload implementation to ensure the new detection integrates correctly with existing argument reconstruction. Implementing the change is relatively small, yet verifying correctness demands careful tests that simulate different interpreter entry modes (-m package, script path, directory/zip execution) without relying on __file__. Time is dominated by designing robust tests and running Django's test suite to ensure no regressions in autoreloader behavior across platforms/Python versions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:36.101405"}
{"instance_id": "django__django-13933", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the functional change is small (ensuring ModelChoiceField supplies the invalid submitted value when raising ValidationError, similar to ChoiceField), it requires careful investigation to find the exact raise site and confirm behavior across ModelChoiceField and ModelMultipleChoiceField. The engineer will also need to adjust the error message parameters and possibly defaults in a backwards-compatible way, then add regression tests covering both default and customized error_messages. Running Django\u2019s relevant form/model field test suites and ensuring no message-format regressions makes the testing portion non-trivial.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the functional change is small (ensuring ModelChoiceField supplies the invalid submitted value when raising ValidationError, similar to ChoiceField), it requires careful investigation to find the exact raise site and confirm behavior across ModelChoiceField and ModelMultipleChoiceField. The engineer will also need to adjust the error message parameters and possibly defaults in a backwards-compatible way, then add regression tests covering both default and customized error_messages. Running Django\u2019s relevant form/model field test suites and ensuring no message-format regressions makes the testing portion non-trivial.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:38.193418"}
{"instance_id": "django__django-14140", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the crash has a clear reproduction and likely a small code change (adjusting Q.deconstruct() handling of single children), an engineer will need to understand Django's Q/Node serialization contract and ensure backward compatibility expectations around migrations and deconstruction. Implementing the fix is quick, but adding/adjusting regression tests around conditional expressions (e.g., Exists) and ensuring no regressions in existing expression/Q tests requires careful validation and full test runs for the affected areas. The time also includes investigating edge cases around single-child behavior and nested/empty Q objects mentioned in the discussion.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the crash has a clear reproduction and likely a small code change (adjusting Q.deconstruct() handling of single children), an engineer will need to understand Django's Q/Node serialization contract and ensure backward compatibility expectations around migrations and deconstruction. Implementing the fix is quick, but adding/adjusting regression tests around conditional expressions (e.g., Exists) and ensuring no regressions in existing expression/Q tests requires careful validation and full test runs for the affected areas. The time also includes investigating edge cases around single-child behavior and nested/empty Q objects mentioned in the discussion.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:38.947442"}
{"instance_id": "django__django-13658", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The code change itself is small (passing an explicit prog value when constructing the global CommandParser in ManagementUtility), but verifying the behavior requires understanding how Django\u2019s management entrypoints interact with argparse defaults and sys.argv. Because the issue reporter notes it was hard to reproduce, a reliable regression test will take time to design (likely involving patching sys.argv[0] to None while calling execute_from_command_line with a separate argv). Running and validating the relevant management-command test suite to ensure no regressions adds additional overhead.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 15, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The code change itself is small (passing an explicit prog value when constructing the global CommandParser in ManagementUtility), but verifying the behavior requires understanding how Django\u2019s management entrypoints interact with argparse defaults and sys.argv. Because the issue reporter notes it was hard to reproduce, a reliable regression test will take time to design (likely involving patching sys.argv[0] to None while calling execute_from_command_line with a separate argv). Running and validating the relevant management-command test suite to ensure no regressions adds additional overhead.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 15,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:39.118552"}
{"instance_id": "django__django-14053", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing duplicate yields in HashedFilesMixin.post_process() requires understanding Django\u2019s multi-pass hashing algorithm (introduced to resolve nested references) and identifying where intermediate results are incorrectly emitted to collectstatic. The change must preserve the correctness of multi-pass processing while ensuring only the final mapping for each original path is yielded once, which is subtle because passes may rewrite the same asset multiple times before stabilizing. A proper fix also needs regression tests around collectstatic/post_process behavior (including multi-pass scenarios) to ensure counts/output and subclass integrations aren\u2019t broken.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing duplicate yields in HashedFilesMixin.post_process() requires understanding Django\u2019s multi-pass hashing algorithm (introduced to resolve nested references) and identifying where intermediate results are incorrectly emitted to collectstatic. The change must preserve the correctness of multi-pass processing while ensuring only the final mapping for each original path is yielded once, which is subtle because passes may rewrite the same asset multiple times before stabilizing. A proper fix also needs regression tests around collectstatic/post_process behavior (including multi-pass scenarios) to ensure counts/output and subclass integrations aren\u2019t broken.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:39.166155"}
{"instance_id": "django__django-14007", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The issue is clear and reproducible but occurs in a relatively specialized ORM pathway: INSERT statements that use returning_fields/RETURNING and then assign returned values directly to model instances. Fixing it likely requires tracing how Django applies database converters (e.g., from_db_value) in normal query evaluation versus the insert-return path, then ensuring the same converter pipeline is applied consistently for both create() and bulk_create() on supporting backends. Proper regression coverage will require backend-feature-guarded tests and validation that the conversion occurs for primary keys and other returning fields without breaking existing insert/return behavior.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 50, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clear and reproducible but occurs in a relatively specialized ORM pathway: INSERT statements that use returning_fields/RETURNING and then assign returned values directly to model instances. Fixing it likely requires tracing how Django applies database converters (e.g., from_db_value) in normal query evaluation versus the insert-return path, then ensuring the same converter pipeline is applied consistently for both create() and bulk_create() on supporting backends. Proper regression coverage will require backend-feature-guarded tests and validation that the conversion occurs for primary keys and other returning fields without breaking existing insert/return behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 50,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:39.743214"}
{"instance_id": "django__django-14089", "repo": "django/django", "estimated_minutes": 90.0, "justification": "The change is conceptually straightforward (add an __reversed__() implementation to OrderedSet), but it requires locating the exact OrderedSet implementation, understanding its internal storage/invariants, and ensuring the new method matches Django\u2019s collection semantics. Proper coverage will involve adding or updating unit tests for reversed() behavior (including iteration order and mutation edge cases) and running the relevant test suite to confirm no regressions. The overall effort is modest but includes the usual Django contribution overhead (conventions, tests, and verification).", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 20, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The change is conceptually straightforward (add an __reversed__() implementation to OrderedSet), but it requires locating the exact OrderedSet implementation, understanding its internal storage/invariants, and ensuring the new method matches Django\u2019s collection semantics. Proper coverage will involve adding or updating unit tests for reversed() behavior (including iteration order and mutation edge cases) and running the relevant test suite to confirm no regressions. The overall effort is modest but includes the usual Django contribution overhead (conventions, tests, and verification).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 20,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:40.776015"}
{"instance_id": "django__django-13346", "repo": "django/django", "estimated_minutes": 300.0, "justification": "This issue is subtle because it only reproduces for JSON key transforms when an __in lookup has a single-element RHS list, and it varies by backend (MySQL/SQLite/Oracle vs PostgreSQL). An engineer will need to trace how Django prepares RHS values for In lookups on transformed JSON expressions and how each backend compiles the JSON extraction SQL and parameter types, then adjust lookup/transform behavior without regressing other JSON querying features. Proper coverage requires adding targeted regression tests (including numeric vs string cases and single vs multi-element lists) and running backend-specific test suites or at least reproducing via Django\u2019s test matrix for the affected databases.", "time_breakdown": {"understanding_and_investigation": 140, "implementation": 80, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 300,\n  \"justification\": \"This issue is subtle because it only reproduces for JSON key transforms when an __in lookup has a single-element RHS list, and it varies by backend (MySQL/SQLite/Oracle vs PostgreSQL). An engineer will need to trace how Django prepares RHS values for In lookups on transformed JSON expressions and how each backend compiles the JSON extraction SQL and parameter types, then adjust lookup/transform behavior without regressing other JSON querying features. Proper coverage requires adding targeted regression tests (including numeric vs string cases and single vs multi-element lists) and running backend-specific test suites or at least reproducing via Django\u2019s test matrix for the affected databases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 140,\n    \"implementation\": 80,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:45:40.788669"}
{"instance_id": "django__django-14122", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This issue requires understanding how Django\u2019s ORM builds SQL for aggregation queries, specifically how Meta.ordering currently leaks into GROUP BY generation even when ORDER BY is suppressed. Fixing it is likely localized to the query/SQL compiler path, but care is needed to avoid breaking other grouping behaviors (e.g., annotations, values(), distinct(), vendor-specific GROUP BY rules). A regression test must be added to demonstrate the incorrect aggregation caused by the extra GROUP BY columns and to ensure the fix works across supported database backends.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This issue requires understanding how Django\u2019s ORM builds SQL for aggregation queries, specifically how Meta.ordering currently leaks into GROUP BY generation even when ORDER BY is suppressed. Fixing it is likely localized to the query/SQL compiler path, but care is needed to avoid breaking other grouping behaviors (e.g., annotations, values(), distinct(), vendor-specific GROUP BY rules). A regression test must be added to demonstrate the incorrect aggregation caused by the extra GROUP BY columns and to ensure the fix works across supported database backends.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:41.090853"}
{"instance_id": "django__django-13516", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This issue likely stems from Django's management command output wrappers (e.g., OutputWrapper in django.core.management.base) not correctly delegating flush() or not honoring flush behavior when writing partial lines (such as migrate's progress output). An engineer will need to reproduce the behavior in a controlled environment, trace where stdout/stderr are wrapped, and confirm how flush is (or isn\u2019t) propagated to the underlying stream. The fix should be small, but adding a reliable regression test is moderately involved because it requires simulating a buffered stream and exercising management command output paths without relying on terminal line-buffering behavior.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 40, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This issue likely stems from Django's management command output wrappers (e.g., OutputWrapper in django.core.management.base) not correctly delegating flush() or not honoring flush behavior when writing partial lines (such as migrate's progress output). An engineer will need to reproduce the behavior in a controlled environment, trace where stdout/stderr are wrapped, and confirm how flush is (or isn\u2019t) propagated to the underlying stream. The fix should be small, but adding a reliable regression test is moderately involved because it requires simulating a buffered stream and exercising management command output paths without relying on terminal line-buffering behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 40,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:41.239869"}
{"instance_id": "django__django-14170", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires investigating Django's date extraction/lookups internals to understand why the YearLookup BETWEEN optimization is being applied to the \"__iso_year\" lookup and how that bypasses ExtractIsoYear semantics. The implementation is likely small (adjusting lookup registration or optimization conditions), but care is needed because ISO year boundaries differ from calendar years and the optimization can silently return wrong rows. Proper coverage involves updating/adding regression tests (including query generation assertions and behavioral tests around ISO-year boundary dates) and running the relevant database backend test suite to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires investigating Django's date extraction/lookups internals to understand why the YearLookup BETWEEN optimization is being applied to the \\\"__iso_year\\\" lookup and how that bypasses ExtractIsoYear semantics. The implementation is likely small (adjusting lookup registration or optimization conditions), but care is needed because ISO year boundaries differ from calendar years and the optimization can silently return wrong rows. Proper coverage involves updating/adding regression tests (including query generation assertions and behavioral tests around ISO-year boundary dates) and running the relevant database backend test suite to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:41.629256"}
{"instance_id": "django__django-14034", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Although the validation behavior is mostly working as designed for an optional MultiValueField, the issue highlights a real mismatch between MultiValueField/require_all_fields semantics and how HTML \"required\" attributes are applied to subwidgets. Fixing this in Django likely requires moderate investigation into BoundField.build_widget_attrs(), MultiWidget rendering, and how subfield required flags are propagated, plus careful alignment with documented behavior. Updating/adding regression tests is non-trivial because existing tests may assert current HTML output and will need adjustment to reflect per-subwidget required behavior without breaking other form/field combinations.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 60, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the validation behavior is mostly working as designed for an optional MultiValueField, the issue highlights a real mismatch between MultiValueField/require_all_fields semantics and how HTML \\\"required\\\" attributes are applied to subwidgets. Fixing this in Django likely requires moderate investigation into BoundField.build_widget_attrs(), MultiWidget rendering, and how subfield required flags are propagated, plus careful alignment with documented behavior. Updating/adding regression tests is non-trivial because existing tests may assert current HTML output and will need adjustment to reflect per-subwidget required behavior without breaking other form/field combinations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 60,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:42.467256"}
{"instance_id": "django__django-14311", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Fixing autoreload for \"python -m foo.bar.baz runserver\" requires understanding how Django\u2019s autoreloader reconstructs argv/child process invocation and how it detects -m execution via importlib/runpy semantics. The code change itself is likely small (adjusting module-spec parsing and __main__ handling), but verifying correct behavior across packages vs. modules and preventing corner cases requires targeted tests and careful validation. Writing reliable regression tests for subprocess/argv reconstruction in Django\u2019s test suite and running the relevant test matrix is a meaningful portion of the effort.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing autoreload for \\\"python -m foo.bar.baz runserver\\\" requires understanding how Django\u2019s autoreloader reconstructs argv/child process invocation and how it detects -m execution via importlib/runpy semantics. The code change itself is likely small (adjusting module-spec parsing and __main__ handling), but verifying correct behavior across packages vs. modules and preventing corner cases requires targeted tests and careful validation. Writing reliable regression tests for subprocess/argv reconstruction in Django\u2019s test suite and running the relevant test matrix is a meaningful portion of the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:42.888702"}
{"instance_id": "django__django-11964", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The issue is reproducible but requires understanding Django\u2019s model attribute assignment path: values set on a model instance are stored directly in __dict__ via the field descriptor, bypassing the usual to_python/from_db_value conversions that occur on database load. Fixing it cleanly likely involves adjusting how model field descriptors (or save/initialization paths) normalize enum members to their primitive .value, while ensuring no regressions for non-enum values and existing choice behavior. Implementing the fix and adding coverage for both TextChoices and IntegerChoices (creation, assignment, save, and retrieval) across Django\u2019s test suite conventions will take a few hours end-to-end.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 55, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is reproducible but requires understanding Django\u2019s model attribute assignment path: values set on a model instance are stored directly in __dict__ via the field descriptor, bypassing the usual to_python/from_db_value conversions that occur on database load. Fixing it cleanly likely involves adjusting how model field descriptors (or save/initialization paths) normalize enum members to their primitive .value, while ensuring no regressions for non-enum values and existing choice behavior. Implementing the fix and adding coverage for both TextChoices and IntegerChoices (creation, assignment, save, and retrieval) across Django\u2019s test suite conventions will take a few hours end-to-end.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 55,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:42.927096"}
{"instance_id": "django__django-13406", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Although the reproduction is clear, fixing it cleanly requires understanding Django's separation between QuerySet state (e.g., `_iterable_class`) and the underlying `Query` object that gets pickled. The likely fix is in `QuerySet.query`'s setter to re-derive the correct iterable behavior when a deserialized `Query` indicates a values-based select, plus potentially adjusting documentation for `values_list()` variants that cannot be fully inferred from the `Query` alone. Writing a regression test around pickled `Query` reassignment and running Django's relevant test suite adds non-trivial time.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 50, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the reproduction is clear, fixing it cleanly requires understanding Django's separation between QuerySet state (e.g., `_iterable_class`) and the underlying `Query` object that gets pickled. The likely fix is in `QuerySet.query`'s setter to re-derive the correct iterable behavior when a deserialized `Query` indicates a values-based select, plus potentially adjusting documentation for `values_list()` variants that cannot be fully inferred from the `Query` alone. Writing a regression test around pickled `Query` reassignment and running Django's relevant test suite adds non-trivial time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 50,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:44.852931"}
{"instance_id": "django__django-14315", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The bug report is fairly specific (PostgreSQL client env becomes an empty dict instead of None), but an engineer will still need to trace how DatabaseClient constructs the environment and how it is passed to subprocess in dbshell/runshell. The code change is likely small (adjusting env handling to return None or to merge with os.environ correctly), but Django requires a regression test that reliably asserts subprocess is called without overriding the parent environment. Writing a robust test (mocking subprocess invocation and verifying behavior across platforms) and running the relevant test suite accounts for a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 20, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The bug report is fairly specific (PostgreSQL client env becomes an empty dict instead of None), but an engineer will still need to trace how DatabaseClient constructs the environment and how it is passed to subprocess in dbshell/runshell. The code change is likely small (adjusting env handling to return None or to merge with os.environ correctly), but Django requires a regression test that reliably asserts subprocess is called without overriding the parent environment. Writing a robust test (mocking subprocess invocation and verifying behavior across platforms) and running the relevant test suite accounts for a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 20,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:45.958295"}
{"instance_id": "django__django-14349", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Fixing this requires investigating how Django's URLValidator currently relies on Python's URL splitting behavior and how bpo-43882 changes the inputs that reach Django (control characters stripped before validation). An experienced engineer will need to decide and implement the intended policy (most likely explicitly rejecting URLs containing CR/LF/TAB early), ensure behavior is consistent across Python versions, and update/extend tests to prevent regressions. The change is localized but touches security-adjacent URL parsing behavior, which increases care and verification time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing this requires investigating how Django's URLValidator currently relies on Python's URL splitting behavior and how bpo-43882 changes the inputs that reach Django (control characters stripped before validation). An experienced engineer will need to decide and implement the intended policy (most likely explicitly rejecting URLs containing CR/LF/TAB early), ensure behavior is consistent across Python versions, and update/extend tests to prevent regressions. The change is localized but touches security-adjacent URL parsing behavior, which increases care and verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:46.229747"}
{"instance_id": "django__django-14500", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This issue involves Django's migration framework behavior around squashed migrations, specifically how MigrationExecutor records applied/unapplied state when unapplying while the replaced migration files still exist. Fixing it requires reproducing the scenario, tracing state management through the loader/executor and migration graph, and ensuring the fix handles both squashed and replaced migrations correctly. Writing a reliable regression test is non-trivial because it typically requires constructing a controlled migration set (including a squash with \"replaces\") and validating the state transitions across apply/unapply runs.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 70, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This issue involves Django's migration framework behavior around squashed migrations, specifically how MigrationExecutor records applied/unapplied state when unapplying while the replaced migration files still exist. Fixing it requires reproducing the scenario, tracing state management through the loader/executor and migration graph, and ensuring the fix handles both squashed and replaced migrations correctly. Writing a reliable regression test is non-trivial because it typically requires constructing a controlled migration set (including a squash with \\\"replaces\\\") and validating the state transitions across apply/unapply runs.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 70,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:46.331417"}
{"instance_id": "django__django-14238", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the issue has a clear reproduction and points to a likely fix location (AutoFieldMeta.__subclasscheck__), the engineer still needs to understand Django's custom AutoField metaclass behavior and why issubclass() fails for indirect subclasses. The code change is likely small, but it touches core model field/type-checking logic where correctness and compatibility matter. Writing a focused regression test (and ensuring it runs within Django's testing patterns around DEFAULT_AUTO_FIELD and app loading) will take a meaningful portion of the total time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the issue has a clear reproduction and points to a likely fix location (AutoFieldMeta.__subclasscheck__), the engineer still needs to understand Django's custom AutoField metaclass behavior and why issubclass() fails for indirect subclasses. The code change is likely small, but it touches core model field/type-checking logic where correctness and compatibility matter. Writing a focused regression test (and ensuring it runs within Django's testing patterns around DEFAULT_AUTO_FIELD and app loading) will take a meaningful portion of the total time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:46.857407"}
{"instance_id": "django__django-14373", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped (the DateFormat \"Y\" specifier should be zero-padded to 4 digits), but it still requires locating the exact implementation and ensuring it matches Django\u2019s formatting conventions without breaking other specifiers. The code change is likely small (formatting or padding logic), yet proper regression tests must be added for years < 1000 and validated against existing date formatting behavior. Running and verifying the relevant Django test suite (or targeted subsets) accounts for a significant portion of the total time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped (the DateFormat \\\"Y\\\" specifier should be zero-padded to 4 digits), but it still requires locating the exact implementation and ensuring it matches Django\u2019s formatting conventions without breaking other specifiers. The code change is likely small (formatting or padding logic), yet proper regression tests must be added for years < 1000 and validated against existing date formatting behavior. Running and verifying the relevant Django test suite (or targeted subsets) accounts for a significant portion of the total time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:47.021656"}
{"instance_id": "django__django-14493", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and points directly to the failing code path in ManifestStaticFilesStorage.post_process() where a local variable is conditionally assigned inside a loop that may not execute when max_post_process_passes=0. The actual code fix is likely small (e.g., initializing substitutions or handling the zero-pass case explicitly), but Django\u2019s staticfiles pipeline has non-trivial behavior and requires a regression test that exercises collectstatic/post_process end-to-end. Time is primarily driven by writing a robust test using Django\u2019s staticfiles test utilities and ensuring it doesn\u2019t introduce regressions in other storage/post-processing scenarios.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and points directly to the failing code path in ManifestStaticFilesStorage.post_process() where a local variable is conditionally assigned inside a loop that may not execute when max_post_process_passes=0. The actual code fix is likely small (e.g., initializing substitutions or handling the zero-pass case explicitly), but Django\u2019s staticfiles pipeline has non-trivial behavior and requires a regression test that exercises collectstatic/post_process end-to-end. Time is primarily driven by writing a robust test using Django\u2019s staticfiles test utilities and ensuring it doesn\u2019t introduce regressions in other storage/post-processing scenarios.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:47.289565"}
{"instance_id": "django__django-14376", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped (a specific kwargs mapping in the MySQL backend) but requires confirming Django\u2019s connection parameter construction and any compatibility logic around mysqlclient versions. The implementation is small (switching to \"database\"/\"password\" and possibly retaining backward compatibility in a safe way), but Django expects thorough tests, likely needing a mock-based assertion of the connect() kwargs. Verification involves running the MySQL backend test suite and ensuring no regressions across connection settings permutations.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped (a specific kwargs mapping in the MySQL backend) but requires confirming Django\u2019s connection parameter construction and any compatibility logic around mysqlclient versions. The implementation is small (switching to \\\"database\\\"/\\\"password\\\" and possibly retaining backward compatibility in a safe way), but Django expects thorough tests, likely needing a mock-based assertion of the connect() kwargs. Verification involves running the MySQL backend test suite and ensuring no regressions across connection settings permutations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:47.679875"}
{"instance_id": "django__django-14534", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the code change is small (adjusting BoundWidget.id_for_label to respect the already-computed widget attrs id), an engineer will need time to trace how subwidgets are produced for CheckboxSelectMultiple and confirm the intended contract across widget types. The bulk of the work is writing a regression test that reproduces the mismatch when auto_id is overridden, then running and interpreting Django\u2019s forms/widget test suite to ensure no behavioral regressions for other multi-widgets or label rendering paths.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 20, "testing_and_verification": 100}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the code change is small (adjusting BoundWidget.id_for_label to respect the already-computed widget attrs id), an engineer will need time to trace how subwidgets are produced for CheckboxSelectMultiple and confirm the intended contract across widget types. The bulk of the work is writing a regression test that reproduces the mismatch when auto_id is overridden, then running and interpreting Django\u2019s forms/widget test suite to ensure no behavioral regressions for other multi-widgets or label rendering paths.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 20,\n    \"testing_and_verification\": 100\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:48.042076"}
{"instance_id": "django__django-14539", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Fixing urlize() here likely involves understanding how Django tokenizes URLs vs. surrounding text and how it treats HTML-escaped sequences like \"&lt\" when determining link boundaries. The bug is subtle because it mixes URL parsing with punctuation trimming logic, so the engineer must ensure the fix doesn\u2019t regress other edge cases (entities, punctuation, querystrings) and aligns with existing behavior and related historical issues/PRs. Adding targeted regression tests and running the relevant Django test suite portion will take a meaningful share of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing urlize() here likely involves understanding how Django tokenizes URLs vs. surrounding text and how it treats HTML-escaped sequences like \\\"&lt\\\" when determining link boundaries. The bug is subtle because it mixes URL parsing with punctuation trimming logic, so the engineer must ensure the fix doesn\u2019t regress other edge cases (entities, punctuation, querystrings) and aligns with existing behavior and related historical issues/PRs. Adding targeted regression tests and running the relevant Django test suite portion will take a meaningful share of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:48.174077"}
{"instance_id": "django__django-13809", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Adding a new --skip-checks flag to runserver is conceptually straightforward, but in Django it requires understanding how BaseCommand wires system checks, how runserver triggers checks (often in inner_run and during autoreload), and ensuring the new option consistently bypasses checks in all runserver entry paths. The engineer will likely need to adjust argument parsing and the conditional execution of checks, then add targeted tests that avoid actually starting a long-running server process while still proving checks are skipped. The bulk of time goes into repository-specific investigation and writing reliable, non-flaky tests around a command that normally blocks and interacts with reloader/threading code.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Adding a new --skip-checks flag to runserver is conceptually straightforward, but in Django it requires understanding how BaseCommand wires system checks, how runserver triggers checks (often in inner_run and during autoreload), and ensuring the new option consistently bypasses checks in all runserver entry paths. The engineer will likely need to adjust argument parsing and the conditional execution of checks, then add targeted tests that avoid actually starting a long-running server process while still proving checks are skipped. The bulk of time goes into repository-specific investigation and writing reliable, non-flaky tests around a command that normally blocks and interacts with reloader/threading code.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:49.164815"}
{"instance_id": "django__django-14580", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue has clear reproduction steps and a strongly suspected root cause in the migration serialization layer, but confirming why the import list is incomplete requires reading how TypeSerializer interacts with MigrationWriter and import collection. The code change itself is small (adding the missing import for the models.Model special case), but Django requires a targeted regression test that generates a migration and asserts correct imports/bases output. Running and validating the relevant migration/autodetector test suite and ensuring no unintended import changes elsewhere adds significant verification time.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 25, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue has clear reproduction steps and a strongly suspected root cause in the migration serialization layer, but confirming why the import list is incomplete requires reading how TypeSerializer interacts with MigrationWriter and import collection. The code change itself is small (adding the missing import for the models.Model special case), but Django requires a targeted regression test that generates a migration and asserts correct imports/bases output. Running and validating the relevant migration/autodetector test suite and ensuring no unintended import changes elsewhere adds significant verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 25,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:49.766453"}
{"instance_id": "django__django-14351", "repo": "django/django", "estimated_minutes": 240.0, "justification": "This is an ORM regression involving how Django constructs subqueries for related-field `__in` lookups when combined via `Q(... ) | Q(...)`, causing the subquery to select multiple columns and fail on PostgreSQL. An experienced engineer will need to reproduce the issue in Django\u2019s test suite, identify where `Query`/lookup logic changes the subquery\u2019s select mask/default columns under OR-conditions, and implement a targeted fix without breaking other `__in` behaviors. Writing a robust regression test (likely PostgreSQL-specific or at least asserting the generated SQL shape) and running the relevant ORM test matrix adds substantial time, especially to avoid subtle query-planner and aliasing regressions.", "time_breakdown": {"understanding_and_investigation": 110, "implementation": 55, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 240,\n  \"justification\": \"This is an ORM regression involving how Django constructs subqueries for related-field `__in` lookups when combined via `Q(... ) | Q(...)`, causing the subquery to select multiple columns and fail on PostgreSQL. An experienced engineer will need to reproduce the issue in Django\u2019s test suite, identify where `Query`/lookup logic changes the subquery\u2019s select mask/default columns under OR-conditions, and implement a targeted fix without breaking other `__in` behaviors. Writing a robust regression test (likely PostgreSQL-specific or at least asserting the generated SQL shape) and running the relevant ORM test matrix adds substantial time, especially to avoid subtle query-planner and aliasing regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 110,\n    \"implementation\": 55,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:45:49.841809"}
{"instance_id": "django__django-14011", "repo": "django/django", "estimated_minutes": 240.0, "justification": "Although the proposed fix is small (overriding ThreadedWSGIServer.close_request() to call connections.close_all()), an engineer will need time to confirm the root cause across Django\u2019s LiveServerTestCase/ThreadedWSGIServer shutdown path and ensure the change won\u2019t regress other server behaviors (notably SQLite thread-sharing). The main time cost is creating a deterministic regression test for a previously race-condition-driven failure, likely requiring careful mocking/instrumentation to prove per-request threads close DB connections reliably. Additional time is needed to run the relevant Django test suites and validate behavior across supported database backends and threading modes.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 50, "testing_and_verification": 110}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Although the proposed fix is small (overriding ThreadedWSGIServer.close_request() to call connections.close_all()), an engineer will need time to confirm the root cause across Django\u2019s LiveServerTestCase/ThreadedWSGIServer shutdown path and ensure the change won\u2019t regress other server behaviors (notably SQLite thread-sharing). The main time cost is creating a deterministic regression test for a previously race-condition-driven failure, likely requiring careful mocking/instrumentation to prove per-request threads close DB connections reliably. Additional time is needed to run the relevant Django test suites and validate behavior across supported database backends and threading modes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 50,\n    \"testing_and_verification\": 110\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:45:50.217755"}
{"instance_id": "django__django-14155", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-scoped (improving ResolverMatch.__repr__ output for functools.partial), but it requires careful investigation to avoid breaking how Django actually calls views (partial must remain callable with its bound args). The likely fix involves unwrapping partial only for representation/view-name purposes (and possibly incorporating bound args/keywords into the repr), which requires updating existing resolver utilities and adding targeted regression tests. Writing and running Django\u2019s URL resolver test suite and ensuring no regressions in callable resolution behavior contributes meaningful time.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 40, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped (improving ResolverMatch.__repr__ output for functools.partial), but it requires careful investigation to avoid breaking how Django actually calls views (partial must remain callable with its bound args). The likely fix involves unwrapping partial only for representation/view-name purposes (and possibly incorporating bound args/keywords into the repr), which requires updating existing resolver utilities and adding targeted regression tests. Writing and running Django\u2019s URL resolver test suite and ensuring no regressions in callable resolution behavior contributes meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 40,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:51.196266"}
{"instance_id": "django__django-14434", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the issue description points to a likely root cause (a Table instance passed where a string is expected), locating the exact call path to _create_unique_sql and confirming how it impacts references_column will require moderate investigation across Django\u2019s schema/migration SQL generation code. The fix itself is likely small (normalizing/coercing the table argument to the expected string form), but Django requires high-confidence regression coverage, so adding a targeted test that asserts correct SQL/behavior across supported backends will take additional time. Running and validating the relevant backend-specific test suite portions adds non-trivial verification overhead.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the issue description points to a likely root cause (a Table instance passed where a string is expected), locating the exact call path to _create_unique_sql and confirming how it impacts references_column will require moderate investigation across Django\u2019s schema/migration SQL generation code. The fix itself is likely small (normalizing/coercing the table argument to the expected string form), but Django requires high-confidence regression coverage, so adding a targeted test that asserts correct SQL/behavior across supported backends will take additional time. Running and validating the relevant backend-specific test suite portions adds non-trivial verification overhead.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:51.848084"}
{"instance_id": "django__django-14631", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This change touches core Django form internals (BaseForm._clean_fields(), changed_data, and BoundField) and requires carefully aligning behavior for disabled fields, callable initial values, and data normalization without introducing subtle regressions. Implementing a BoundField-level \"did_change\"-style method is a small refactor but must preserve existing semantics across many field types and widgets. Updating and extending tests (including the datetime callable initial/disabled case) and running an appropriate subset of the forms test suite adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 75, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This change touches core Django form internals (BaseForm._clean_fields(), changed_data, and BoundField) and requires carefully aligning behavior for disabled fields, callable initial values, and data normalization without introducing subtle regressions. Implementing a BoundField-level \\\"did_change\\\"-style method is a small refactor but must preserve existing semantics across many field types and widgets. Updating and extending tests (including the datetime callable initial/disabled case) and running an appropriate subset of the forms test suite adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 75,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:52.528129"}
{"instance_id": "django__django-14855", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The underlying bug and fix are fairly clear (missing current_app in a reverse() call), but confirming the correct behavior across Django\u2019s admin URL resolution patterns and ensuring there are no side effects requires some code reading. The bulk of the effort will be in creating a reliable regression test that sets up a custom AdminSite, a model with a ForeignKey in readonly_fields, and asserts the generated link targets the custom admin prefix. Running and iterating on Django\u2019s admin test suite to ensure no regressions is also a meaningful portion of the work.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 30, "testing_and_verification": 100}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The underlying bug and fix are fairly clear (missing current_app in a reverse() call), but confirming the correct behavior across Django\u2019s admin URL resolution patterns and ensuring there are no side effects requires some code reading. The bulk of the effort will be in creating a reliable regression test that sets up a custom AdminSite, a model with a ForeignKey in readonly_fields, and asserts the generated link targets the custom admin prefix. Running and iterating on Django\u2019s admin test suite to ensure no regressions is also a meaningful portion of the work.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 30,\n    \"testing_and_verification\": 100\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:53.721559"}
{"instance_id": "django__django-14752", "repo": "django/django", "estimated_minutes": 150.0, "justification": "This change is conceptually small (extracting result serialization into an overridable method) but requires careful integration into Django\u2019s existing admin autocomplete flow to avoid behavioral regressions. An engineer will need to inspect how AutocompleteJsonView currently builds its response (including pagination, to_field handling, and permissions) and add a stable extension point without altering output. Writing/adjusting tests in Django\u2019s admin test suite to confirm both default behavior and a customization override will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This change is conceptually small (extracting result serialization into an overridable method) but requires careful integration into Django\u2019s existing admin autocomplete flow to avoid behavioral regressions. An engineer will need to inspect how AutocompleteJsonView currently builds its response (including pagination, to_field handling, and permissions) and add a stable extension point without altering output. Writing/adjusting tests in Django\u2019s admin test suite to confirm both default behavior and a customization override will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:54.480030"}
{"instance_id": "django__django-14915", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped with a clear proposed fix: make ModelChoiceIteratorValue hashable (e.g., by delegating to hash(self.value)). An engineer will still need to locate the class, confirm Django\u2019s equality semantics for this wrapper, and ensure hashing is consistent with __eq__ to avoid subtle regressions. The bulk of the time will be spent adding/adjusting regression tests around form choice rendering and verifying the change against Django\u2019s test suite.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped with a clear proposed fix: make ModelChoiceIteratorValue hashable (e.g., by delegating to hash(self.value)). An engineer will still need to locate the class, confirm Django\u2019s equality semantics for this wrapper, and ensure hashing is consistent with __eq__ to avoid subtle regressions. The bulk of the time will be spent adding/adjusting regression tests around form choice rendering and verifying the change against Django\u2019s test suite.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:55.312384"}
{"instance_id": "django__django-14672", "repo": "django/django", "estimated_minutes": 120.0, "justification": "Although the fix is likely a small change (adding a missing `make_hashable()` call when building `ManyToManyRel.identity`), an engineer will need time to trace where `identity` is constructed and confirm the exact hashing/comparison behavior across all `ForeignObjectRel` subclasses. A proper regression test requires creating a minimal model setup (including a proxy model and an M2M with `through_fields` provided as a list) and exercising Django\u2019s system checks to reproduce the original `TypeError`. Verifying the change doesn\u2019t affect other relation identity semantics or introduce subtle compatibility issues requires running an appropriate slice of Django\u2019s test suite.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 20, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"Although the fix is likely a small change (adding a missing `make_hashable()` call when building `ManyToManyRel.identity`), an engineer will need time to trace where `identity` is constructed and confirm the exact hashing/comparison behavior across all `ForeignObjectRel` subclasses. A proper regression test requires creating a minimal model setup (including a proxy model and an M2M with `through_fields` provided as a list) and exercising Django\u2019s system checks to reproduce the original `TypeError`. Verifying the change doesn\u2019t affect other relation identity semantics or introduce subtle compatibility issues requires running an appropriate slice of Django\u2019s test suite.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 20,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:55.479613"}
{"instance_id": "django__django-14404", "repo": "django/django", "estimated_minutes": 90.0, "justification": "The issue is well-scoped (redirect URL should use request.path rather than request.path_info to preserve FORCE_SCRIPT_NAME), but it still requires locating the specific catch_all_view implementation and confirming current behavior under different deployment prefixes. The code change itself is likely a small, localized adjustment, but Django\u2019s test suite conventions mean adding/adjusting a regression test and running relevant tests to ensure no redirect behavior regressions. Verifying correct behavior with FORCE_SCRIPT_NAME typically needs careful test setup around request construction and expected redirect locations.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 15, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is well-scoped (redirect URL should use request.path rather than request.path_info to preserve FORCE_SCRIPT_NAME), but it still requires locating the specific catch_all_view implementation and confirming current behavior under different deployment prefixes. The code change itself is likely a small, localized adjustment, but Django\u2019s test suite conventions mean adding/adjusting a regression test and running relevant tests to ensure no redirect behavior regressions. Verifying correct behavior with FORCE_SCRIPT_NAME typically needs careful test setup around request construction and expected redirect locations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 15,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:55.795563"}
{"instance_id": "django__django-15104", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped with a clear traceback, a precise suspected fix (using pop with a default), and a minimal reproduction, which reduces investigation time. However, Django migrations/autodetector behavior is sensitive and requires carefully placed tests to ensure the change doesn\u2019t mask real errors or alter rename-detection logic. An experienced engineer would likely need to locate the correct existing test module, add a regression test for the custom field deconstruction behavior, and run the relevant migrations and full test subsets to confirm no regressions.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 15, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped with a clear traceback, a precise suspected fix (using pop with a default), and a minimal reproduction, which reduces investigation time. However, Django migrations/autodetector behavior is sensitive and requires carefully placed tests to ensure the change doesn\u2019t mask real errors or alter rename-detection logic. An experienced engineer would likely need to locate the correct existing test module, add a regression test for the custom field deconstruction behavior, and run the relevant migrations and full test subsets to confirm no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 15,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:56.838780"}
{"instance_id": "django__django-13297", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This looks like a regression in how URL kwargs are passed through class-based views in Django 3.1, where they became wrapped in SimpleLazyObject (likely to support a deprecation path) and now leak into user code. Fixing it requires tracing where the wrapping occurs (commit referenced), adjusting the behavior so Python-level get_context_data() receives real values while still preserving any intended deprecation behavior for template context. A proper fix also needs a targeted regression test covering CBV kwargs usage with ORM filtering/get_object_or_404, plus running relevant generic view and ORM test suites to ensure no unintended side effects.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This looks like a regression in how URL kwargs are passed through class-based views in Django 3.1, where they became wrapped in SimpleLazyObject (likely to support a deprecation path) and now leak into user code. Fixing it requires tracing where the wrapping occurs (commit referenced), adjusting the behavior so Python-level get_context_data() receives real values while still preserving any intended deprecation behavior for template context. A proper fix also needs a targeted regression test covering CBV kwargs usage with ORM filtering/get_object_or_404, plus running relevant generic view and ORM test suites to ensure no unintended side effects.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:57.026635"}
{"instance_id": "django__django-14725", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This requires understanding how Django model formsets derive initial/extra forms from the management form and how tampering with INITIAL_FORMS/TOTAL_FORMS can cause unintended object creation. The fix likely involves adding an explicit \"edit-only\" capability (or enforcing that posted management-form counts cannot exceed the true initial form count for a queryset-backed formset), which touches core formset validation logic and needs careful consideration of backwards compatibility and edge cases. Implementing and validating this behavior will require targeted regression tests around POST tampering, plus running a relevant portion of Django\u2019s form/formset test suite to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 70, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This requires understanding how Django model formsets derive initial/extra forms from the management form and how tampering with INITIAL_FORMS/TOTAL_FORMS can cause unintended object creation. The fix likely involves adding an explicit \\\"edit-only\\\" capability (or enforcing that posted management-form counts cannot exceed the true initial form count for a queryset-backed formset), which touches core formset validation logic and needs careful consideration of backwards compatibility and edge cases. Implementing and validating this behavior will require targeted regression tests around POST tampering, plus running a relevant portion of Django\u2019s form/formset test suite to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 70,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:58.069286"}
{"instance_id": "django__django-15037", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing inspectdb to correctly generate ForeignKey(..., to_field=...) for constraints targeting non-primary-key unique fields requires understanding how Django introspection reports foreign key relationships and how inspectdb converts those into model fields. The change is likely localized but needs careful handling across backends (or at least ensuring no regressions on others) and requires adding a regression test that creates tables with a FK to a unique, non-PK column and verifies the generated model output. Test setup and verification will take a significant portion of time due to database-specific DDL and ensuring the introspection output is stable.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing inspectdb to correctly generate ForeignKey(..., to_field=...) for constraints targeting non-primary-key unique fields requires understanding how Django introspection reports foreign key relationships and how inspectdb converts those into model fields. The change is likely localized but needs careful handling across backends (or at least ensuring no regressions on others) and requires adding a regression test that creates tables with a FK to a unique, non-PK column and verifies the generated model output. Test setup and verification will take a significant portion of time due to database-specific DDL and ensuring the introspection output is stable.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:58.183837"}
{"instance_id": "django__django-15127", "repo": "django/django", "estimated_minutes": 150.0, "justification": "This issue requires investigating how django.contrib.messages.storage.base.LEVEL_TAGS is constructed and why it remains stale under @override_settings(MESSAGE_TAGS=...). The likely fix is small (adding a setting_changed receiver or reusing an existing override_settings hook to rebuild LEVEL_TAGS), but it must be done carefully to avoid global-state leakage across tests and to match Django\u2019s established patterns. Writing a focused regression test and running the relevant messages test suite adds meaningful time, especially to ensure no cross-test interference or regressions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 35, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This issue requires investigating how django.contrib.messages.storage.base.LEVEL_TAGS is constructed and why it remains stale under @override_settings(MESSAGE_TAGS=...). The likely fix is small (adding a setting_changed receiver or reusing an existing override_settings hook to rebuild LEVEL_TAGS), but it must be done carefully to avoid global-state leakage across tests and to match Django\u2019s established patterns. Writing a focused regression test and running the relevant messages test suite adds meaningful time, especially to ensure no cross-test interference or regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 35,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:59.089228"}
{"instance_id": "django__django-14765", "repo": "django/django", "estimated_minutes": 90.0, "justification": "Although the code change itself is small (changing coercion/checking logic in ProjectState.__init__()), an engineer will need to confirm all internal call sites now pass a set, and ensure no remaining code paths rely on passing other iterables. Because this is in the migrations state machinery, it requires careful review of usages and running the migrations-related test suite to avoid subtle regressions. Adding or adjusting a targeted test (or updating callers if any still pass non-sets) is likely needed to make the change safe and reviewable.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 20, "testing_and_verification": 30}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"Although the code change itself is small (changing coercion/checking logic in ProjectState.__init__()), an engineer will need to confirm all internal call sites now pass a set, and ensure no remaining code paths rely on passing other iterables. Because this is in the migrations state machinery, it requires careful review of usages and running the migrations-related test suite to avoid subtle regressions. Adding or adjusting a targeted test (or updating callers if any still pass non-sets) is likely needed to make the change safe and reviewable.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 20,\n    \"testing_and_verification\": 30\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:59.391111"}
{"instance_id": "django__django-15103", "repo": "django/django", "estimated_minutes": 120.0, "justification": "This change is conceptually small (making the json_script element_id optional), but in Django it likely touches both the underlying helper and the template filter/tag interface where argument parsing is stricter. An engineer will need to confirm current behavior across Python API usage and template usage, update rendering to omit the id attribute cleanly, and ensure backwards compatibility. Adding/adjusting tests for both code paths (direct call and template rendering) and running the relevant Django test suite adds a non-trivial amount of time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 35, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"This change is conceptually small (making the json_script element_id optional), but in Django it likely touches both the underlying helper and the template filter/tag interface where argument parsing is stricter. An engineer will need to confirm current behavior across Python API usage and template usage, update rendering to omit the id attribute cleanly, and ensure backwards compatibility. Adding/adjusting tests for both code paths (direct call and template rendering) and running the relevant Django test suite adds a non-trivial amount of time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 35,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:45:59.419692"}
{"instance_id": "django__django-14559", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Although the code change is conceptually small (accumulating and returning the integer row counts from the per-batch QuerySet.update() calls), the engineer will need time to confirm intended semantics (e.g., how duplicates across batches should be counted) and ensure consistency across database backends. Django requires comprehensive, backend-agnostic tests, so adding/adjusting tests for bulk_update() return values and running the relevant test suite will dominate the effort. Some additional time is needed to check documentation/release notes expectations and ensure no regressions in existing bulk_update behavior.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the code change is conceptually small (accumulating and returning the integer row counts from the per-batch QuerySet.update() calls), the engineer will need time to confirm intended semantics (e.g., how duplicates across batches should be counted) and ensure consistency across database backends. Django requires comprehensive, backend-agnostic tests, so adding/adjusting tests for bulk_update() return values and running the relevant test suite will dominate the effort. Some additional time is needed to check documentation/release notes expectations and ensure no regressions in existing bulk_update behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:00.162171"}
{"instance_id": "django__django-15128", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing this requires understanding Django ORM query aliasing internals (Query.combine(), change_aliases(), bump_prefix()) and how alias_prefix collisions arise specifically for commutative QuerySet OR operations. The implementation likely involves a careful adjustment to alias bumping behavior to avoid change_map key/value intersections without breaking alias-merge invariants, which is easy to regress. Proper regression tests must be added and a meaningful subset of the Django test suite (ORM + any affected admin/queryset/subquery tests) should be run to ensure no aliasing-related failures.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing this requires understanding Django ORM query aliasing internals (Query.combine(), change_aliases(), bump_prefix()) and how alias_prefix collisions arise specifically for commutative QuerySet OR operations. The implementation likely involves a careful adjustment to alias bumping behavior to avoid change_map key/value intersections without breaking alias-merge invariants, which is easy to regress. Proper regression tests must be added and a meaningful subset of the Django test suite (ORM + any affected admin/queryset/subquery tests) should be run to ensure no aliasing-related failures.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:01.302125"}
{"instance_id": "django__django-14771", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The issue requires understanding how Django\u2019s auto-reloader reconstructs the command line for the child process and why interpreter flags like CPython\u2019s -X options are lost (they don\u2019t appear in sys.argv). The fix will likely involve extending the argument reconstruction logic (e.g., in django/utils/autoreload.py) to incorporate sys._xoptions in a deterministic way while avoiding regressions across platforms and Python implementations. Proper coverage will require new/updated unit tests that simulate sys._xoptions and validate the spawned command arguments without relying on actually restarting processes on Windows.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue requires understanding how Django\u2019s auto-reloader reconstructs the command line for the child process and why interpreter flags like CPython\u2019s -X options are lost (they don\u2019t appear in sys.argv). The fix will likely involve extending the argument reconstruction logic (e.g., in django/utils/autoreload.py) to incorporate sys._xoptions in a deterministic way while avoiding regressions across platforms and Python implementations. Proper coverage will require new/updated unit tests that simulate sys._xoptions and validate the spawned command arguments without relying on actually restarting processes on Windows.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:01.559675"}
{"instance_id": "django__django-14608", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This change is conceptually small (adding a CSS class for FormSet-level non-form errors) but requires moderate investigation to locate the exact code path where BaseFormSet constructs its ErrorList for non_form_errors and to ensure consistency with how Form.non_field_errors adds the \"nonfield\" class. Proper coverage will require adding/adjusting tests around FormSet non_form_errors rendering/attributes and ensuring no regressions in existing error rendering behavior. Updating developer-facing documentation to mention the new \"nonform\" class adds additional (but limited) scope.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This change is conceptually small (adding a CSS class for FormSet-level non-form errors) but requires moderate investigation to locate the exact code path where BaseFormSet constructs its ErrorList for non_form_errors and to ensure consistency with how Form.non_field_errors adds the \\\"nonfield\\\" class. Proper coverage will require adding/adjusting tests around FormSet non_form_errors rendering/attributes and ensuring no regressions in existing error rendering behavior. Updating developer-facing documentation to mention the new \\\"nonform\\\" class adds additional (but limited) scope.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:01.726829"}
{"instance_id": "django__django-15098", "repo": "django/django", "estimated_minutes": 190.0, "justification": "Fixing this requires understanding how Django extracts language codes from URL paths (e.g., get_language_from_path and LocaleMiddleware) and how i18n_patterns builds/validates URL prefixes. Supporting BCP 47-style tags with both script and region (and mixed case like en-Latn-US) likely involves adjusting parsing/normalization logic while avoiding overly-permissive regex matching. The change should be accompanied by new regression tests covering multiple tags, case normalization, and ensuring no false positives in URL resolution, which adds non-trivial verification time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 190,\n  \"justification\": \"Fixing this requires understanding how Django extracts language codes from URL paths (e.g., get_language_from_path and LocaleMiddleware) and how i18n_patterns builds/validates URL prefixes. Supporting BCP 47-style tags with both script and region (and mixed case like en-Latn-US) likely involves adjusting parsing/normalization logic while avoiding overly-permissive regex matching. The change should be accompanied by new regression tests covering multiple tags, case normalization, and ensuring no false positives in URL resolution, which adds non-trivial verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:02.249073"}
{"instance_id": "django__django-14792", "repo": "django/django", "estimated_minutes": 240.0, "justification": "This issue is a cross-backend regression involving subtle time zone naming/offset normalization changes (notably around \"Etc/GMT\u00b1X\" semantics) introduced by a specific commit, so an engineer will need time to trace how tzinfo names flow from TimezoneMixin through backend-specific _prepare_tzname_delta() logic. The fix likely requires adjusting normalization either in django/utils/timezone.py or in multiple database backends (PostgreSQL and MySQL are both impacted) while preserving correct behavior for numeric offsets and named zones. Proper coverage will require adding/adjusting database-specific tests for Trunc()/Extract() SQL generation and verifying no regressions across supported Python tz implementations (pytz/zoneinfo).", "time_breakdown": {"understanding_and_investigation": 100, "implementation": 60, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 240,\n  \"justification\": \"This issue is a cross-backend regression involving subtle time zone naming/offset normalization changes (notably around \\\"Etc/GMT\u00b1X\\\" semantics) introduced by a specific commit, so an engineer will need time to trace how tzinfo names flow from TimezoneMixin through backend-specific _prepare_tzname_delta() logic. The fix likely requires adjusting normalization either in django/utils/timezone.py or in multiple database backends (PostgreSQL and MySQL are both impacted) while preserving correct behavior for numeric offsets and named zones. Proper coverage will require adding/adjusting database-specific tests for Trunc()/Extract() SQL generation and verifying no regressions across supported Python tz implementations (pytz/zoneinfo).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 100,\n    \"implementation\": 60,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:02.910271"}
{"instance_id": "django__django-15161", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This change requires investigating how Django expressions implement deconstruction/serialization and identifying which expression classes can safely switch to shorter import paths without breaking backwards compatibility in migrations. The implementation is likely a set of targeted updates to several expression classes\u2019 deconstruct() return values, plus ensuring migration serialization continues to work correctly. Proper coverage will require adding/updating tests around migration writer output (or expression deconstruction tests) and running the relevant migration and model test suites to confirm no regressions.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 55, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This change requires investigating how Django expressions implement deconstruction/serialization and identifying which expression classes can safely switch to shorter import paths without breaking backwards compatibility in migrations. The implementation is likely a set of targeted updates to several expression classes\u2019 deconstruct() return values, plus ensuring migration serialization continues to work correctly. Proper coverage will require adding/updating tests around migration writer output (or expression deconstruction tests) and running the relevant migration and model test suites to confirm no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 55,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:02.984086"}
{"instance_id": "django__django-15280", "repo": "django/django", "estimated_minutes": 300.0, "justification": "This issue is a subtle ORM interaction between deferred fields, instance caching, and nested prefetch_related() behavior, requiring careful investigation of how prefetched instances are attached back onto already-loaded origin instances. The fix likely involves modifying prefetch_one_level() logic in django/db/models/query.py to correctly handle cases where a relation is already cached but a nested prefetch provides a more-complete instance, without breaking existing caching/identity assumptions. Writing robust regression tests for both OneToOneField and ForeignKey variants and verifying no query regressions across the ORM test suite adds meaningful time.", "time_breakdown": {"understanding_and_investigation": 140, "implementation": 80, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 300,\n  \"justification\": \"This issue is a subtle ORM interaction between deferred fields, instance caching, and nested prefetch_related() behavior, requiring careful investigation of how prefetched instances are attached back onto already-loaded origin instances. The fix likely involves modifying prefetch_one_level() logic in django/db/models/query.py to correctly handle cases where a relation is already cached but a nested prefetch provides a more-complete instance, without breaking existing caching/identity assumptions. Writing robust regression tests for both OneToOneField and ForeignKey variants and verifying no query regressions across the ORM test suite adds meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 140,\n    \"implementation\": 80,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:04.840168"}
{"instance_id": "django__django-15380", "repo": "django/django", "estimated_minutes": 240.0, "justification": "Fixing this requires reproducing the crash, understanding how the migration autodetector tracks model renames vs. field renames, and identifying why the renamed model is still being looked up under the old key (triggering a KeyError). The regression reference suggests behavior changed recently, so the engineer will likely need to inspect the cited commit and related logic in the autodetector to restore correct state mapping when both renames happen in one step. A proper fix should include a regression test covering interactive rename prompts and ensuring the generated operations don\u2019t crash and are correct.", "time_breakdown": {"understanding_and_investigation": 100, "implementation": 60, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Fixing this requires reproducing the crash, understanding how the migration autodetector tracks model renames vs. field renames, and identifying why the renamed model is still being looked up under the old key (triggering a KeyError). The regression reference suggests behavior changed recently, so the engineer will likely need to inspect the cited commit and related logic in the autodetector to restore correct state mapping when both renames happen in one step. A proper fix should include a regression test covering interactive rename prompts and ensuring the generated operations don\u2019t crash and are correct.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 100,\n    \"implementation\": 60,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:05.640519"}
{"instance_id": "django__django-15315", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the reproduction is clear, the engineer will need to trace how Field.__hash__ was changed in #31750 and why assignment to a model class mutates the value used for hashing (likely via contributing attributes like model/name/creation_counter). The fix must preserve the hash/eq contract (especially after #31750\u2019s equality changes) while ensuring the hash remains stable across a field\u2019s lifecycle, which requires careful adjustment and review of related field identity semantics. Adding a regression test for the pre-assignment dict usage and running Django\u2019s model/field test suite to avoid subtle regressions adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the reproduction is clear, the engineer will need to trace how Field.__hash__ was changed in #31750 and why assignment to a model class mutates the value used for hashing (likely via contributing attributes like model/name/creation_counter). The fix must preserve the hash/eq contract (especially after #31750\u2019s equality changes) while ensuring the hash remains stable across a field\u2019s lifecycle, which requires careful adjustment and review of related field identity semantics. Adding a regression test for the pre-assignment dict usage and running Django\u2019s model/field test suite to avoid subtle regressions adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:06.529577"}
{"instance_id": "django__django-15382", "repo": "django/django", "estimated_minutes": 140.0, "justification": "The issue is fairly well-scoped with a clear reproduction and a suggested fix, but it involves Django's query compilation/optimization paths where EmptyResultSet handling can have subtle effects. An engineer will need to confirm how negated Exists interacts with queryset.none() during SQL generation and ensure the fix doesn't break other optimizations or database backends. Implementing the try/except is quick, but adding a robust regression test and running Django's relevant test suites (expressions/queryset-related) will take the bulk of the time.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 140,\n  \"justification\": \"The issue is fairly well-scoped with a clear reproduction and a suggested fix, but it involves Django's query compilation/optimization paths where EmptyResultSet handling can have subtle effects. An engineer will need to confirm how negated Exists interacts with queryset.none() during SQL generation and ensure the fix doesn't break other optimizations or database backends. Implementing the try/except is quick, but adding a robust regression test and running Django's relevant test suites (expressions/queryset-related) will take the bulk of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:06.670555"}
{"instance_id": "django__django-15268", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Implementing this optimization requires understanding Django's migration optimizer rules and how AlterUniqueTogether/AlterIndexTogether reductions are currently handled after the split introduced in #31503. The fix is likely localized to migration operation reduction/optimizer logic, but needs careful handling to ensure correctness (only collapsing truly redundant remove-then-add sequences with no intervening operations that rely on the empty state). Writing or adjusting targeted optimizer tests and running the relevant migration test suite will take a significant portion of the time due to Django's conventions and the need to avoid regressions in edge cases.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 55, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Implementing this optimization requires understanding Django's migration optimizer rules and how AlterUniqueTogether/AlterIndexTogether reductions are currently handled after the split introduced in #31503. The fix is likely localized to migration operation reduction/optimizer logic, but needs careful handling to ensure correctness (only collapsing truly redundant remove-then-add sequences with no intervening operations that rely on the empty state). Writing or adjusting targeted optimizer tests and running the relevant migration test suite will take a significant portion of the time due to Django's conventions and the need to avoid regressions in edge cases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 55,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:07.413926"}
{"instance_id": "django__django-15375", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and the likely root cause is localized to Aggregate.default\u2019s internal Coalesce wrapping, but confirming why the ORM generates an invalid outer SELECT requires some time reading query compilation/summary expression handling. The actual code change is small (marking the Coalesce wrapper as a summary expression and ensuring default state doesn\u2019t leak), but Django requires a proper regression test in the ORM aggregation test suite and verification across multiple backends. Running and iterating on the relevant test subsets (and potentially full ORM tests locally) typically dominates the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and the likely root cause is localized to Aggregate.default\u2019s internal Coalesce wrapping, but confirming why the ORM generates an invalid outer SELECT requires some time reading query compilation/summary expression handling. The actual code change is small (marking the Coalesce wrapper as a summary expression and ensuring default state doesn\u2019t leak), but Django requires a proper regression test in the ORM aggregation test suite and verification across multiple backends. Running and iterating on the relevant test subsets (and potentially full ORM tests locally) typically dominates the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:07.936864"}
{"instance_id": "django__django-15467", "repo": "django/django", "estimated_minutes": 150.0, "justification": "While the functional change is small (ensuring a caller-supplied empty_label isn\u2019t overwritten when radio_fields is used), an engineer will need to trace the admin formfield generation path to confirm exactly where kwargs is being clobbered and that the precedence change won\u2019t affect other widget/field types. The bulk of the time will go into adding a focused regression test in Django\u2019s admin test suite that reproduces the interaction between radio_fields and formfield_for_foreignkey(), and running/verifying the relevant admin tests to avoid regressions.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 25, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"While the functional change is small (ensuring a caller-supplied empty_label isn\u2019t overwritten when radio_fields is used), an engineer will need to trace the admin formfield generation path to confirm exactly where kwargs is being clobbered and that the precedence change won\u2019t affect other widget/field types. The bulk of the time will go into adding a focused regression test in Django\u2019s admin test suite that reproduces the interaction between radio_fields and formfield_for_foreignkey(), and running/verifying the relevant admin tests to avoid regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 25,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:07.966226"}
{"instance_id": "django__django-15525", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the underlying fix is small (ensuring the model instance used to compute natural_key() is bound to the target database), it requires understanding Django's serializer/deserializer flow and multi-database behavior to avoid regressions. Adding a regression test is non-trivial because it must exercise loaddata/Deserializer with natural keys across non-default databases and confirm the correct DB is used when resolving related objects. Time is also needed to run and validate Django's relevant test suites and ensure the change aligns with internal conventions (e.g., avoiding direct _state manipulation).", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the underlying fix is small (ensuring the model instance used to compute natural_key() is bound to the target database), it requires understanding Django's serializer/deserializer flow and multi-database behavior to avoid regressions. Adding a regression test is non-trivial because it must exercise loaddata/Deserializer with natural keys across non-default databases and confirm the correct DB is used when resolving related objects. Time is also needed to run and validate Django's relevant test suites and ensure the change aligns with internal conventions (e.g., avoiding direct _state manipulation).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:08.204949"}
{"instance_id": "django__django-15252", "repo": "django/django", "estimated_minutes": 240.0, "justification": "Fixing this requires understanding how Django's migration executor and MigrationRecorder interact across multiple database connections, and where router allow_migrate rules should be consulted to avoid creating/writing the migrations table on disallowed databases. The change is not isolated to a single method because skipping ensure_schema() must also prevent record_applied/record_unapplied and applied_migrations from issuing queries that assume the table exists, likely requiring coordinated behavior changes and/or an early exit/error when migrations are disallowed. Writing reliable regression tests will take significant time due to the need for multi-database configuration, custom routers, and assertions around table creation and migration recording behavior.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 70, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "4-6", "testing_complexity": "complex", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Fixing this requires understanding how Django's migration executor and MigrationRecorder interact across multiple database connections, and where router allow_migrate rules should be consulted to avoid creating/writing the migrations table on disallowed databases. The change is not isolated to a single method because skipping ensure_schema() must also prevent record_applied/record_unapplied and applied_migrations from issuing queries that assume the table exists, likely requiring coordinated behavior changes and/or an early exit/error when migrations are disallowed. Writing reliable regression tests will take significant time due to the need for multi-database configuration, custom routers, and assertions around table creation and migration recording behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 70,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:08.550618"}
{"instance_id": "django__django-15277", "repo": "django/django", "estimated_minutes": 110.0, "justification": "Although the code change is small (guarding CharField's MaxLengthValidator creation when max_length is None), an engineer will need to confirm all call sites where CharField is instantiated without max_length (notably Value._resolve_output_field) and ensure this doesn\u2019t alter expected behavior for real model fields that rely on system checks. Writing a focused regression test that fails on current behavior (TypeError during clean() or unexpected validators) and passes with the fix will take some time to place correctly within Django\u2019s test structure. Verification also includes running the relevant test modules and sanity-checking that system checks still flag missing max_length on user-defined CharFields.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 20, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 110,\n  \"justification\": \"Although the code change is small (guarding CharField's MaxLengthValidator creation when max_length is None), an engineer will need to confirm all call sites where CharField is instantiated without max_length (notably Value._resolve_output_field) and ensure this doesn\u2019t alter expected behavior for real model fields that rely on system checks. Writing a focused regression test that fails on current behavior (TypeError during clean() or unexpected validators) and passes with the fix will take some time to place correctly within Django\u2019s test structure. Verification also includes running the relevant test modules and sanity-checking that system checks still flag missing max_length on user-defined CharFields.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 20,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:08.558288"}
{"instance_id": "django__django-14017", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The issue is well-scoped and reproducible: Q.__and__/__or__ currently reject non-Q operands (raising TypeError), which breaks commutativity with conditional expressions like Exists() that can otherwise be embedded inside Q objects. An experienced engineer will need to inspect Django\u2019s operator overloading paths (Q._combine vs Combinable/Expression behavior) to implement a safe coercion path (e.g., wrapping conditional expressions in Q) without changing error behavior for truly invalid operands. Time is also driven by adding regression tests and running the relevant test suites to ensure no regressions in query construction semantics.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 45, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-scoped and reproducible: Q.__and__/__or__ currently reject non-Q operands (raising TypeError), which breaks commutativity with conditional expressions like Exists() that can otherwise be embedded inside Q objects. An experienced engineer will need to inspect Django\u2019s operator overloading paths (Q._combine vs Combinable/Expression behavior) to implement a safe coercion path (e.g., wrapping conditional expressions in Q) without changing error behavior for truly invalid operands. Time is also driven by adding regression tests and running the relevant test suites to ensure no regressions in query construction semantics.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 45,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:08.769194"}
{"instance_id": "django__django-15368", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-scoped with a clear reproduction and a likely single-location fix in QuerySet.bulk_update() where expressions are incorrectly treated as plain values. Even though the code change is small (switching to a resolve_expression-based check), the engineer will need to confirm how bulk_update compiles CASE/WHEN updates across backends and ensure no regressions for existing Expression handling. Adding a focused regression test and running Django\u2019s query/model test suite (or a targeted subset) will take the majority of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped with a clear reproduction and a likely single-location fix in QuerySet.bulk_update() where expressions are incorrectly treated as plain values. Even though the code change is small (switching to a resolve_expression-based check), the engineer will need to confirm how bulk_update compiles CASE/WHEN updates across backends and ensure no regressions for existing Expression handling. Adding a focused regression test and running Django\u2019s query/model test suite (or a targeted subset) will take the majority of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:09.008838"}
{"instance_id": "django__django-14787", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this likely requires understanding how Django's method_decorator() adapts a function decorator to methods and why it currently passes a functools.partial into the decorator, which breaks decorators using functools.wraps/update_wrapper due to missing attributes like __name__. The implementation is probably a targeted change (e.g., passing a bound method via __get__ / MethodType instead of partial) but must be carefully validated across method types and Python versions. Adding a focused regression test is straightforward, but verifying no regressions (e.g., behavior for class-based views, multiple decorators, and preservation of metadata) adds non-trivial test/verification time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this likely requires understanding how Django's method_decorator() adapts a function decorator to methods and why it currently passes a functools.partial into the decorator, which breaks decorators using functools.wraps/update_wrapper due to missing attributes like __name__. The implementation is probably a targeted change (e.g., passing a bound method via __get__ / MethodType instead of partial) but must be carefully validated across method types and Python versions. Adding a focused regression test is straightforward, but verifying no regressions (e.g., behavior for class-based views, multiple decorators, and preservation of metadata) adds non-trivial test/verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:09.480929"}
{"instance_id": "django__django-15563", "repo": "django/django", "estimated_minutes": 240.0, "justification": "Fixing this requires understanding Django ORM\u2019s multi-table inheritance (MTI) update path and how UpdateQuery/SQLUpdateCompiler determine which parent table rows to update. The hinted solution involves a small but non-trivial internal API change (from a list of related IDs to a per-model mapping), plus adjusting compiler pre-setup logic to select the correct parent-link values for updated fields. Because this touches query compilation and MTI behavior, careful regression testing across different inheritance/update combinations is needed to ensure no unintended updates or missed updates occur.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 80, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Fixing this requires understanding Django ORM\u2019s multi-table inheritance (MTI) update path and how UpdateQuery/SQLUpdateCompiler determine which parent table rows to update. The hinted solution involves a small but non-trivial internal API change (from a list of related IDs to a per-model mapping), plus adjusting compiler pre-setup logic to select the correct parent-link values for updated fields. Because this touches query compilation and MTI behavior, careful regression testing across different inheritance/update combinations is needed to ensure no unintended updates or missed updates occur.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 80,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:10.362137"}
{"instance_id": "django__django-15278", "repo": "django/django", "estimated_minutes": 240.0, "justification": "This looks like a backend-specific regression in SQLite schema editing where adding a OneToOneField (unique=True) is emitted as an inline UNIQUE column constraint during ALTER TABLE ... ADD COLUMN, which SQLite rejects. An engineer will need to trace the regression to the referenced commit, adjust SQLite's schema editor to emit the column without UNIQUE and create the unique constraint/index in a separate step, and ensure behavior matches other backends. Proper coverage requires adding a migration/schema test that reproduces the failure on SQLite and verifies the unique constraint is created without breaking other add-field cases.", "time_breakdown": {"understanding_and_investigation": 100, "implementation": 60, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"This looks like a backend-specific regression in SQLite schema editing where adding a OneToOneField (unique=True) is emitted as an inline UNIQUE column constraint during ALTER TABLE ... ADD COLUMN, which SQLite rejects. An engineer will need to trace the regression to the referenced commit, adjust SQLite's schema editor to emit the column without UNIQUE and create the unique constraint/index in a separate step, and ensure behavior matches other backends. Proper coverage requires adding a migration/schema test that reproduces the failure on SQLite and verifies the unique constraint is created without breaking other add-field cases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 100,\n    \"implementation\": 60,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:10.487775"}
{"instance_id": "django__django-15499", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This requires understanding Django\u2019s migration optimization rules and how operations are reduced/combined, then extending that logic to fold AlterModelManagers into a preceding CreateModel (similar to existing CreateModel+AlterModelOptions behavior). The change is localized but subtle because it must preserve semantics across different migration graphs and operation orderings, and it needs careful test coverage to avoid regressions in optimizer behavior. Writing focused optimizer tests and running the migration test suite will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This requires understanding Django\u2019s migration optimization rules and how operations are reduced/combined, then extending that logic to fold AlterModelManagers into a preceding CreateModel (similar to existing CreateModel+AlterModelOptions behavior). The change is localized but subtle because it must preserve semantics across different migration graphs and operation orderings, and it needs careful test coverage to avoid regressions in optimizer behavior. Writing focused optimizer tests and running the migration test suite will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:10.884478"}
{"instance_id": "django__django-15561", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-scoped (SQLite emits table-rebuild SQL for an AlterField that only changes non-DB attributes like choices), but requires understanding Django\u2019s migration/schema-editor decision path to ensure the fix is SQLite-specific and doesn\u2019t regress third-party fields that map choices to real DB-level types (e.g., EnumField). Implementation should be small (likely overriding or adjusting SQLite\u2019s _field_should_be_altered() logic), but a proper regression test is needed to assert that changing only choices produces no SQL on SQLite while other AlterField changes still behave correctly. Verifying involves running targeted migration/schema tests on SQLite and ensuring no cross-backend behavior changes.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped (SQLite emits table-rebuild SQL for an AlterField that only changes non-DB attributes like choices), but requires understanding Django\u2019s migration/schema-editor decision path to ensure the fix is SQLite-specific and doesn\u2019t regress third-party fields that map choices to real DB-level types (e.g., EnumField). Implementation should be small (likely overriding or adjusting SQLite\u2019s _field_should_be_altered() logic), but a proper regression test is needed to assert that changing only choices produces no SQL on SQLite while other AlterField changes still behave correctly. Verifying involves running targeted migration/schema tests on SQLite and ensuring no cross-backend behavior changes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:10.909441"}
{"instance_id": "django__django-15554", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This issue likely stems from Django ORM join-reuse logic incorrectly treating multiple FilteredRelation aliases that target the same relation path as identical, causing one filtered join to overwrite or be reused for the other. Fixing it requires investigating how filtered relations are registered and how joins are keyed/deduplicated inside the SQL query compiler, then adjusting that logic so distinct filtered aliases generate distinct joins. A regression test is straightforward to add (and hinted in the issue), but validating the fix requires running the relevant ORM and filtered-relation test suite to ensure no join explosion or unintended join reuse changes elsewhere.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 75, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This issue likely stems from Django ORM join-reuse logic incorrectly treating multiple FilteredRelation aliases that target the same relation path as identical, causing one filtered join to overwrite or be reused for the other. Fixing it requires investigating how filtered relations are registered and how joins are keyed/deduplicated inside the SQL query compiler, then adjusting that logic so distinct filtered aliases generate distinct joins. A regression test is straightforward to add (and hinted in the issue), but validating the fix requires running the relevant ORM and filtered-relation test suite to ensure no join explosion or unintended join reuse changes elsewhere.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 75,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:11.143288"}
{"instance_id": "django__django-15695", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing RenameIndex idempotency for unnamed (auto-generated) indexes requires understanding Django\u2019s migration state vs. database schema behavior and why backwards is currently a noop for unnamed old indexes. The engineer will need to reproduce the PostgreSQL failure, trace how index names are generated/restored (likely via SchemaEditor._create_index_name()), and implement a safe backwards/forwards behavior that avoids creating an already-existing relation. Writing and running targeted migration operation tests across backends (at least PostgreSQL-focused, with sanity on others) adds nontrivial verification time.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing RenameIndex idempotency for unnamed (auto-generated) indexes requires understanding Django\u2019s migration state vs. database schema behavior and why backwards is currently a noop for unnamed old indexes. The engineer will need to reproduce the PostgreSQL failure, trace how index names are generated/restored (likely via SchemaEditor._create_index_name()), and implement a safe backwards/forwards behavior that avoids creating an already-existing relation. Writing and running targeted migration operation tests across backends (at least PostgreSQL-focused, with sanity on others) adds nontrivial verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:11.428443"}
{"instance_id": "django__django-15569", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The functional change is small (mirroring the cache-clearing behavior already present in register_lookup()), but it requires understanding how lookup caching works in RegisterLookupMixin and how it impacts cross-test isolation. Updating/adding regression tests is necessary to reproduce the cache-retention failure and to adjust an existing schema test that becomes sensitive to the corrected behavior. A significant portion of time will be spent running and iterating on Django\u2019s test suite for the affected modules to ensure no regressions or order-dependent failures remain.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 20, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The functional change is small (mirroring the cache-clearing behavior already present in register_lookup()), but it requires understanding how lookup caching works in RegisterLookupMixin and how it impacts cross-test isolation. Updating/adding regression tests is necessary to reproduce the cache-retention failure and to adjust an existing schema test that becomes sensitive to the corrected behavior. A significant portion of time will be spent running and iterating on Django\u2019s test suite for the affected modules to ensure no regressions or order-dependent failures remain.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 20,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:11.497536"}
{"instance_id": "django__django-15732", "repo": "django/django", "estimated_minutes": 240.0, "justification": "Fixing this requires understanding how Django\u2019s schema editor discovers and drops unique constraints (especially on PostgreSQL) and why single-column unique_together conflicts with other uniqueness mechanisms (PK or unique=True). The implementation is likely localized to constraint discovery/drop logic but must carefully avoid regressions across backends and handle existing databases that may already have both constraints. Writing reliable regression tests will take significant time because it involves generating/altering migrations and asserting database-level constraints, typically requiring PostgreSQL-specific test coverage.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Fixing this requires understanding how Django\u2019s schema editor discovers and drops unique constraints (especially on PostgreSQL) and why single-column unique_together conflicts with other uniqueness mechanisms (PK or unique=True). The implementation is likely localized to constraint discovery/drop logic but must carefully avoid regressions across backends and handle existing databases that may already have both constraints. Writing reliable regression tests will take significant time because it involves generating/altering migrations and asserting database-level constraints, typically requiring PostgreSQL-specific test coverage.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:15.338842"}
{"instance_id": "django__django-15741", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is clearly described and includes a concrete failure mode (TypeError in get_format when a lazy string is passed), but the engineer will still need to trace the regression to the referenced change and confirm the expected behavior across template filters. The fix itself is likely small (coercing lazy objects to a real string before using them as attribute names / lookup keys), but Django requires a proper regression test in the template/filter test suite and verification that no locale/format resolution paths are broken. Running and iterating on targeted tests plus ensuring compatibility across supported Python/Django utilities adds non-trivial time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 25, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly described and includes a concrete failure mode (TypeError in get_format when a lazy string is passed), but the engineer will still need to trace the regression to the referenced change and confirm the expected behavior across template filters. The fix itself is likely small (coercing lazy objects to a real string before using them as attribute names / lookup keys), but Django requires a proper regression test in the template/filter test suite and verification that no locale/format resolution paths are broken. Running and iterating on targeted tests plus ensuring compatibility across supported Python/Django utilities adds non-trivial time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 25,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:15.390956"}
{"instance_id": "django__django-15022", "repo": "django/django", "estimated_minutes": 330.0, "justification": "Fixing admin multi-word search join explosion requires investigating how ModelAdmin.get_search_results() builds per-term filters and how the ORM aliases joins when AND-ing Q objects across related lookups. A robust fix likely needs changing the query construction strategy (e.g., using subqueries/pk__in intersections or another approach that avoids multiplying JOIN aliases per search term) while preserving correct semantics for multi-term searches across related objects. Writing regression tests is non-trivial because they must assert query shape (JOIN count/aliasing) in a backend-tolerant way and ensure correctness across various search_fields, including related fields and distinct handling.", "time_breakdown": {"understanding_and_investigation": 140, "implementation": 90, "testing_and_verification": 100}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 330,\n  \"justification\": \"Fixing admin multi-word search join explosion requires investigating how ModelAdmin.get_search_results() builds per-term filters and how the ORM aliases joins when AND-ing Q objects across related lookups. A robust fix likely needs changing the query construction strategy (e.g., using subqueries/pk__in intersections or another approach that avoids multiplying JOIN aliases per search term) while preserving correct semantics for multi-term searches across related objects. Writing regression tests is non-trivial because they must assert query shape (JOIN count/aliasing) in a backend-tolerant way and ensure correctness across various search_fields, including related fields and distinct handling.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 140,\n    \"implementation\": 90,\n    \"testing_and_verification\": 100\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:15.555610"}
{"instance_id": "django__django-15503", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing this requires understanding how JSONField lookups are compiled on SQLite/MySQL/Oracle and why numeric-looking keys (e.g., \"1111\") are being treated as array indexes in JSON path generation. The change will likely involve adjusting or extending the JSON path compilation logic (or lookup compilation) for has_key/has_keys/has_any_keys without breaking existing behavior for true array indexing in other lookups. Proper regression tests must be added and validated across the affected backends\u2019 query-generation paths to ensure no regressions in JSON transforms and key lookups.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 60, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing this requires understanding how JSONField lookups are compiled on SQLite/MySQL/Oracle and why numeric-looking keys (e.g., \\\"1111\\\") are being treated as array indexes in JSON path generation. The change will likely involve adjusting or extending the JSON path compilation logic (or lookup compilation) for has_key/has_keys/has_any_keys without breaking existing behavior for true array indexing in other lookups. Proper regression tests must be added and validated across the affected backends\u2019 query-generation paths to ensure no regressions in JSON transforms and key lookups.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 60,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:15.697996"}
{"instance_id": "django__django-15863", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-defined with a minimal reproducible example and a clear suspected root cause (Decimal values being coerced through float), so investigation is bounded but still requires reading Django\u2019s existing floatformat implementation and its historical behavior. The fix likely involves adjusting numeric handling to preserve Decimal precision without regressing float/int behavior and ensuring consistent formatting across edge cases. Writing and running targeted template filter tests (including rounding, trailing zeros, and negative precisions) and verifying no regressions across supported Python/Django behaviors will take a substantial portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-defined with a minimal reproducible example and a clear suspected root cause (Decimal values being coerced through float), so investigation is bounded but still requires reading Django\u2019s existing floatformat implementation and its historical behavior. The fix likely involves adjusting numeric handling to preserve Decimal precision without regressing float/int behavior and ensuring consistent formatting across edge cases. Writing and running targeted template filter tests (including rounding, trailing zeros, and negative precisions) and verifying no regressions across supported Python/Django behaviors will take a substantial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:15.723256"}
{"instance_id": "django__django-15851", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-scoped (argument ordering for PostgreSQL\u2019s psql invocation) but requires locating where Django constructs dbshell command arguments and ensuring the change is PostgreSQL-specific without impacting other backends. Implementing the fix is likely a small change to argument construction, but Django\u2019s management command and database client code paths require careful review. Writing/adjusting tests will take a significant portion of the time because dbshell typically involves subprocess invocation and backend-specific command building that must be asserted via mocking rather than executing psql.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped (argument ordering for PostgreSQL\u2019s psql invocation) but requires locating where Django constructs dbshell command arguments and ensuring the change is PostgreSQL-specific without impacting other backends. Implementing the fix is likely a small change to argument construction, but Django\u2019s management command and database client code paths require careful review. Writing/adjusting tests will take a significant portion of the time because dbshell typically involves subprocess invocation and backend-specific command building that must be asserted via mocking rather than executing psql.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:16.505169"}
{"instance_id": "django__django-15814", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-reported with a clear reproducer and an identified suspect location, but an engineer still needs to understand Django\u2019s QuerySet select_related()/only() internals and confirm the correct fix point (ensuring concrete model metadata is used without breaking other proxy behaviors). Implementing the fix is likely small, but requires careful placement to avoid unintended side effects in related object population and deferred field loading. A regression test must be added to Django\u2019s proxy model test suite and the relevant ORM/proxy tests should be run to ensure no regressions across multiple query patterns.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-reported with a clear reproducer and an identified suspect location, but an engineer still needs to understand Django\u2019s QuerySet select_related()/only() internals and confirm the correct fix point (ensuring concrete model metadata is used without breaking other proxy behaviors). Implementing the fix is likely small, but requires careful placement to avoid unintended side effects in related object population and deferred field loading. A regression test must be added to Django\u2019s proxy model test suite and the relevant ORM/proxy tests should be run to ensure no regressions across multiple query patterns.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:16.810545"}
{"instance_id": "django__django-15731", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and already points to a specific location in django/db/models/manager.py where wrapper metadata is not fully preserved, so investigation is moderate rather than extensive. The code change itself is small (switching to functools.wraps and ensuring the wrapper preserves __wrapped__/signature-related metadata), but Django requires adding a regression test and verifying behavior across manager/queryset delegation paths. Running and validating the relevant Django test suite portions and ensuring no unintended side effects on method delegation makes testing and verification the dominant time component.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and already points to a specific location in django/db/models/manager.py where wrapper metadata is not fully preserved, so investigation is moderate rather than extensive. The code change itself is small (switching to functools.wraps and ensuring the wrapper preserves __wrapped__/signature-related metadata), but Django requires adding a regression test and verifying behavior across manager/queryset delegation paths. Running and validating the relevant Django test suite portions and ensuring no unintended side effects on method delegation makes testing and verification the dominant time component.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:17.958637"}
{"instance_id": "django__django-15572", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The regression is well-described and likely localized to how template directories are normalized and then consumed by django/template/autoreload.py, but confirming the exact control flow (settings -> Engine -> autoreload directory list -> template_changed()) will take some investigation. The fix itself is probably small (e.g., filtering out empty/invalid DIRS entries before normalization or before matching), but Django\u2019s expectations around path handling and cross-platform behavior require care. Writing a reliable regression test is the most time-consuming part, since it must simulate the problematic DIRS=[''] configuration and assert autoreload behavior without introducing flaky filesystem-watcher dependencies.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The regression is well-described and likely localized to how template directories are normalized and then consumed by django/template/autoreload.py, but confirming the exact control flow (settings -> Engine -> autoreload directory list -> template_changed()) will take some investigation. The fix itself is probably small (e.g., filtering out empty/invalid DIRS entries before normalization or before matching), but Django\u2019s expectations around path handling and cross-platform behavior require care. Writing a reliable regression test is the most time-consuming part, since it must simulate the problematic DIRS=[''] configuration and assert autoreload behavior without introducing flaky filesystem-watcher dependencies.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:18.391328"}
{"instance_id": "django__django-15629", "repo": "django/django", "estimated_minutes": 300.0, "justification": "Fixing db_collation propagation for foreign key columns in Django requires understanding how related fields derive database parameters, how migrations detect/serialize field changes, and how schema editors generate ALTER TABLE SQL (especially for MySQL). A correct fix likely touches both field parameter plumbing (so FK columns inherit the target field collation and changes to it) and the MySQL schema editor\u2019s column/constraint alteration logic. Writing reliable regression tests is non-trivial because it must assert generated SQL (or run schema changes) under MySQL-specific behavior and ensure no unintended effects on other backends.", "time_breakdown": {"understanding_and_investigation": 105, "implementation": 95, "testing_and_verification": 100}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "4-6", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 300,\n  \"justification\": \"Fixing db_collation propagation for foreign key columns in Django requires understanding how related fields derive database parameters, how migrations detect/serialize field changes, and how schema editors generate ALTER TABLE SQL (especially for MySQL). A correct fix likely touches both field parameter plumbing (so FK columns inherit the target field collation and changes to it) and the MySQL schema editor\u2019s column/constraint alteration logic. Writing reliable regression tests is non-trivial because it must assert generated SQL (or run schema changes) under MySQL-specific behavior and ensure no unintended effects on other backends.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 105,\n    \"implementation\": 95,\n    \"testing_and_verification\": 100\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:18.393413"}
{"instance_id": "django__django-16082", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue requires investigating Django's expression type resolution for the modulo (MOD/%%) operator and why it diverges from other numeric operators when operands are mixed (e.g., DecimalField + IntegerField). The fix is likely localized to expression output_field inference logic but must be implemented carefully to preserve existing behavior (including the known NULL modulo test) and to ensure consistent cross-database behavior. Adding targeted regression tests for mixed numeric types and running the relevant test suite adds meaningful but manageable overhead.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue requires investigating Django's expression type resolution for the modulo (MOD/%%) operator and why it diverges from other numeric operators when operands are mixed (e.g., DecimalField + IntegerField). The fix is likely localized to expression output_field inference logic but must be implemented carefully to preserve existing behavior (including the known NULL modulo test) and to ensure consistent cross-database behavior. Adding targeted regression tests for mixed numeric types and running the relevant test suite adds meaningful but manageable overhead.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:18.426596"}
{"instance_id": "django__django-15987", "repo": "django/django", "estimated_minutes": 120.0, "justification": "This issue is narrowly scoped (duplicate detection in loaddata when FIXTURE_DIRS contains Path objects) but requires understanding how Django normalizes fixture directories and where the duplicate check occurs. The fix is likely a small change (normalizing entries via os.fspath()/Path and consistent path normalization before de-duplication), but Django\u2019s management command and settings interactions require careful handling to avoid altering behavior across platforms. Writing a regression test is non-trivial because it involves configuring FIXTURE_DIRS with Path instances and asserting the duplicate warning/error behavior, then running the relevant Django test suite subset.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"This issue is narrowly scoped (duplicate detection in loaddata when FIXTURE_DIRS contains Path objects) but requires understanding how Django normalizes fixture directories and where the duplicate check occurs. The fix is likely a small change (normalizing entries via os.fspath()/Path and consistent path normalization before de-duplication), but Django\u2019s management command and settings interactions require careful handling to avoid altering behavior across platforms. Writing a regression test is non-trivial because it involves configuring FIXTURE_DIRS with Path instances and asserting the duplicate warning/error behavior, then running the relevant Django test suite subset.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:18.758117"}
{"instance_id": "django__django-15916", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This change requires investigating how Django\u2019s ModelForm construction pipeline handles formfield_callback in modelform_factory, including how kwargs override (or unintentionally clear) attributes coming from the provided base form and its Meta. The fix is likely localized to django/forms/models.py but must be implemented carefully to preserve existing behavior when an explicit callback is passed while enabling fallback to the base form\u2019s Meta option when None is provided. Adding regression tests is non-trivial because it must assert the callback application through the factory-generated form and ensure no regressions across related factories (e.g., inlineformset_factory/model formsets).", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This change requires investigating how Django\u2019s ModelForm construction pipeline handles formfield_callback in modelform_factory, including how kwargs override (or unintentionally clear) attributes coming from the provided base form and its Meta. The fix is likely localized to django/forms/models.py but must be implemented carefully to preserve existing behavior when an explicit callback is passed while enabling fallback to the base form\u2019s Meta option when None is provided. Adding regression tests is non-trivial because it must assert the callback application through the factory-generated form and ensure no regressions across related factories (e.g., inlineformset_factory/model formsets).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:19.263201"}
{"instance_id": "django__django-16032", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the bug is reproducible with a small test, it involves subtle ORM internals around how Query/QuerySet decide whether a subquery has explicit selected fields, and how annotation masking interacts with alias(). The fix likely requires changing core Query state (replacing a computed property with a persisted flag), ensuring it clones correctly, and updating related lookup behavior (e.g., RelatedIn) to use set_values() to preserve the intended semantics. Writing a regression test and running the relevant Django ORM test modules to ensure no regressions typically brings the total to around three hours.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 55, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the bug is reproducible with a small test, it involves subtle ORM internals around how Query/QuerySet decide whether a subquery has explicit selected fields, and how annotation masking interacts with alias(). The fix likely requires changing core Query state (replacing a computed property with a persisted flag), ensuring it clones correctly, and updating related lookup behavior (e.g., RelatedIn) to use set_values() to preserve the intended semantics. Writing a regression test and running the relevant Django ORM test modules to ensure no regressions typically brings the total to around three hours.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 55,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:19.303559"}
{"instance_id": "django__django-15973", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Reproducing and diagnosing this issue requires digging into Django's migration state rendering and schema editor logic to understand why a ManyToManyField's through model remains a string reference when creating tables. The fix will likely involve resolving the through model reference to an actual model class at the right phase of migration execution without breaking other migration/autodetector behaviors. A proper regression test needs to be added using Django's migrations test framework to cover cross-app through models and verify the migration plan/order works correctly across backends.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "4-6", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Reproducing and diagnosing this issue requires digging into Django's migration state rendering and schema editor logic to understand why a ManyToManyField's through model remains a string reference when creating tables. The fix will likely involve resolving the through model reference to an actual model class at the right phase of migration execution without breaking other migration/autodetector behaviors. A proper regression test needs to be added using Django's migrations test framework to cover cross-app through models and verify the migration plan/order works correctly across backends.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:19.955617"}
{"instance_id": "django__django-15930", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This issue is a well-scoped ORM SQL generation bug, but it sits at the intersection of Q-object negation, empty IN lookups, and conditional expression compilation (Case/When), which typically requires non-trivial investigation in Django's query/expression compiler. The engineer will likely need to trace how an empty `__in` becomes an `EmptyResultSet`/\"always false\" predicate and how negation should turn it into an \"always true\" predicate, then ensure the Case/When SQL compiler handles that case without emitting an empty WHEN condition. A proper fix should include a regression test and validation across supported backends, adding some time for running the relevant ORM test suites and ensuring no behavior regressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This issue is a well-scoped ORM SQL generation bug, but it sits at the intersection of Q-object negation, empty IN lookups, and conditional expression compilation (Case/When), which typically requires non-trivial investigation in Django's query/expression compiler. The engineer will likely need to trace how an empty `__in` becomes an `EmptyResultSet`/\\\"always false\\\" predicate and how negation should turn it into an \\\"always true\\\" predicate, then ensure the Case/When SQL compiler handles that case without emitting an empty WHEN condition. A proper fix should include a regression test and validation across supported backends, adding some time for running the relevant ORM test suites and ensuring no behavior regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:20.186824"}
{"instance_id": "django__django-15957", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Supporting sliced querysets in Prefetch() isn\u2019t a straightforward bug fix because Django\u2019s prefetch mechanism needs to add additional filtering (typically an IN (...) constraint) to the provided queryset, which is illegal once a slice/limit is applied. A realistic and likely-acceptable resolution is to detect sliced querysets early, raise a clear and intentional error (instead of an AssertionError), and document the limitation and recommended workarounds, which requires moderate ORM and prefetch internals familiarity. The estimate includes time to locate the prefetch filtering path, implement the guard/error, add regression tests, and update documentation while ensuring no broader prefetch regressions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 50, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Supporting sliced querysets in Prefetch() isn\u2019t a straightforward bug fix because Django\u2019s prefetch mechanism needs to add additional filtering (typically an IN (...) constraint) to the provided queryset, which is illegal once a slice/limit is applied. A realistic and likely-acceptable resolution is to detect sliced querysets early, raise a clear and intentional error (instead of an AssertionError), and document the limitation and recommended workarounds, which requires moderate ORM and prefetch internals familiarity. The estimate includes time to locate the prefetch filtering path, implement the guard/error, add regression tests, and update documentation while ensuring no broader prefetch regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 50,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:21.203042"}
{"instance_id": "django__django-16255", "repo": "django/django", "estimated_minutes": 90.0, "justification": "The issue is well-scoped and reproducible: an empty sitemap combined with a callable lastmod triggers a ValueError due to max() on an empty sequence. An experienced Django contributor will need a short investigation to confirm current sitemap behavior and locate existing related tests, then implement a small defensive change (likely using max(..., default=None)) and add regression coverage. Most of the time will be spent writing and validating tests within Django\u2019s existing sitemap test framework and running the relevant test suite to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 15, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is well-scoped and reproducible: an empty sitemap combined with a callable lastmod triggers a ValueError due to max() on an empty sequence. An experienced Django contributor will need a short investigation to confirm current sitemap behavior and locate existing related tests, then implement a small defensive change (likely using max(..., default=None)) and add regression coverage. Most of the time will be spent writing and validating tests within Django\u2019s existing sitemap test framework and running the relevant test suite to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 15,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:22.165935"}
{"instance_id": "django__django-16100", "repo": "django/django", "estimated_minutes": 195.0, "justification": "The change requires understanding Django admin\u2019s `changelist_view` list_editable POST handling, where and how the formset is saved, and ensuring that wrapping it in `transaction.atomic()` doesn\u2019t alter existing behavior (messages, redirects, action handling, etc.). Implementation is likely a localized change in the admin view, but care is needed to scope the transaction only around the mutating list_editable save path. Proper verification will require adding admin tests that demonstrate rollback on an injected failure (e.g., exception during save) and confirming no regressions across existing changelist behaviors.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 45, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 195,\n  \"justification\": \"The change requires understanding Django admin\u2019s `changelist_view` list_editable POST handling, where and how the formset is saved, and ensuring that wrapping it in `transaction.atomic()` doesn\u2019t alter existing behavior (messages, redirects, action handling, etc.). Implementation is likely a localized change in the admin view, but care is needed to scope the transaction only around the mutating list_editable save path. Proper verification will require adding admin tests that demonstrate rollback on an injected failure (e.g., exception during save) and confirming no regressions across existing changelist behaviors.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 45,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:22.491093"}
{"instance_id": "django__django-16116", "repo": "django/django", "estimated_minutes": 165.0, "justification": "This change requires understanding how the makemigrations management command currently implements --check, --dry-run, and migration writing, and why --check still results in files being created. The implementation is likely a small behavioral adjustment (e.g., making --check imply non-writing behavior or bypassing the writer) but must preserve exit codes and messaging semantics. The bulk of the time is in adding/adjusting regression tests to ensure no migration files are written under --check while still correctly detecting pending model changes, and then running Django\u2019s test suite for management command behavior to avoid regressions.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 45, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 165,\n  \"justification\": \"This change requires understanding how the makemigrations management command currently implements --check, --dry-run, and migration writing, and why --check still results in files being created. The implementation is likely a small behavioral adjustment (e.g., making --check imply non-writing behavior or bypassing the writer) but must preserve exit codes and messaging semantics. The bulk of the time is in adding/adjusting regression tests to ensure no migration files are written under --check while still correctly detecting pending model changes, and then running Django\u2019s test suite for management command behavior to avoid regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 45,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:22.699580"}
{"instance_id": "django__django-16145", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and likely confined to how `runserver` formats the \"Starting development server\" URL when the bind address is the shortcut `0`. An engineer will still need to trace where Django parses `addrport` and where it chooses the display URL versus the actual bind host, then implement a small normalization (e.g., rewriting `0` to `0.0.0.0` for display). The bulk of the time is in finding/adjusting the right code path and adding/maintaining a robust test that captures command output without introducing platform-specific assumptions.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and likely confined to how `runserver` formats the \\\"Starting development server\\\" URL when the bind address is the shortcut `0`. An engineer will still need to trace where Django parses `addrport` and where it chooses the display URL versus the actual bind host, then implement a small normalization (e.g., rewriting `0` to `0.0.0.0` for display). The bulk of the time is in finding/adjusting the right code path and adding/maintaining a robust test that captures command output without introducing platform-specific assumptions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:23.330807"}
{"instance_id": "django__django-16136", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and already points to the likely fix area (View.http_method_not_allowed()) and a known regression, reducing investigation time. However, Django\u2019s async/sync dispatch paths require careful handling to avoid returning a non-awaitable in an async context, and the engineer will need to match existing conventions (similar to options()). Writing a targeted regression test for async CBV dispatch and running the relevant test suites (including async-related tests) adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and already points to the likely fix area (View.http_method_not_allowed()) and a known regression, reducing investigation time. However, Django\u2019s async/sync dispatch paths require careful handling to avoid returning a non-awaitable in an async context, and the engineer will need to match existing conventions (similar to options()). Writing a targeted regression test for async CBV dispatch and running the relevant test suites (including async-related tests) adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:24.039942"}
{"instance_id": "django__django-16429", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is a clear regression with a reliable reproduction case and a likely root cause (constructing a naive \"pivot\" datetime while operating on aware datetimes when USE_TZ=True). Fixing it should be relatively localized to django/utils/timesince.py, but it requires careful handling to preserve existing behavior for naive datetimes and for different input combinations (aware/naive, supplied \"now\" or default). Adding a regression test and running the relevant Django test modules (and possibly a small subset of timezone-related tests) will take a meaningful portion of the effort.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is a clear regression with a reliable reproduction case and a likely root cause (constructing a naive \\\"pivot\\\" datetime while operating on aware datetimes when USE_TZ=True). Fixing it should be relatively localized to django/utils/timesince.py, but it requires careful handling to preserve existing behavior for naive datetimes and for different input combinations (aware/naive, supplied \\\"now\\\" or default). Adding a regression test and running the relevant Django test modules (and possibly a small subset of timezone-related tests) will take a meaningful portion of the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:24.603831"}
{"instance_id": "django__django-16315", "repo": "django/django", "estimated_minutes": 165.0, "justification": "The issue is well-scoped and already points to the likely root cause: ON CONFLICT SQL generation is using model field names instead of database column names when db_column is set. The fix is relatively small (likely adjusting arguments passed into on_conflict_suffix_sql and/or normalizing update_fields/unique_fields to Field objects), but it requires careful alignment with Django\u2019s SQL compiler conventions across backends. A proper regression test (likely PostgreSQL-specific) will take the majority of the time due to setting up a model with mixed-case db_column values, exercising bulk_create(update_conflicts=...), and validating the generated SQL/behavior.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 35, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 165,\n  \"justification\": \"The issue is well-scoped and already points to the likely root cause: ON CONFLICT SQL generation is using model field names instead of database column names when db_column is set. The fix is relatively small (likely adjusting arguments passed into on_conflict_suffix_sql and/or normalizing update_fields/unique_fields to Field objects), but it requires careful alignment with Django\u2019s SQL compiler conventions across backends. A proper regression test (likely PostgreSQL-specific) will take the majority of the time due to setting up a model with mixed-case db_column values, exercising bulk_create(update_conflicts=...), and validating the generated SQL/behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 35,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:25.157983"}
{"instance_id": "django__django-16485", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue has clear reproduction steps and points to a specific regression commit, but an engineer still needs to inspect floatformat()\u2019s Decimal/quantize logic to understand why a precision of 0 is being produced and triggering the Decimal context error. The fix is likely localized to the floatformat filter implementation, but it must preserve existing formatting behavior across multiple edge cases (zero, negative values, trailing zeros, input as str/float/Decimal). Writing focused regression tests and running Django\u2019s template filter test suite (and possibly broader template tests) will take a substantial portion of the time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 35, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue has clear reproduction steps and points to a specific regression commit, but an engineer still needs to inspect floatformat()\u2019s Decimal/quantize logic to understand why a precision of 0 is being produced and triggering the Decimal context error. The fix is likely localized to the floatformat filter implementation, but it must preserve existing formatting behavior across multiple edge cases (zero, negative values, trailing zeros, input as str/float/Decimal). Writing focused regression tests and running Django\u2019s template filter test suite (and possibly broader template tests) will take a substantial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 35,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:25.390966"}
{"instance_id": "django__django-16569", "repo": "django/django", "estimated_minutes": 90.0, "justification": "The issue is clearly reproducible and points directly to the failing comparison in django/forms/formsets.py, so investigation is relatively quick. However, even a small conditional fix in Django requires understanding existing formset semantics (especially around empty_form and deletion fields) and adding a regression test in the correct test module. Most of the time will be spent writing/placing the test properly and running the relevant Django test suite subset to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 15, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clearly reproducible and points directly to the failing comparison in django/forms/formsets.py, so investigation is relatively quick. However, even a small conditional fix in Django requires understanding existing formset semantics (especially around empty_form and deletion fields) and adding a regression test in the correct test module. Most of the time will be spent writing/placing the test properly and running the relevant Django test suite subset to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 15,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:25.965742"}
{"instance_id": "django__django-16333", "repo": "django/django", "estimated_minutes": 180.0, "justification": "The issue is well-defined: UserCreationForm.save(commit=True) diverges from ModelForm by not calling save_m2m(), so ManyToMany form data is dropped for custom User models. The code change itself is small, but Django\u2019s contrib.auth forms and swappable user model testing patterns require some investigation to implement the fix in a way consistent with existing save(commit=...) semantics. Most of the effort is in writing a reliable regression test using a custom user model with a ManyToManyField and ensuring it passes across Django\u2019s test suite conventions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-defined: UserCreationForm.save(commit=True) diverges from ModelForm by not calling save_m2m(), so ManyToMany form data is dropped for custom User models. The code change itself is small, but Django\u2019s contrib.auth forms and swappable user model testing patterns require some investigation to implement the fix in a way consistent with existing save(commit=...) semantics. Most of the effort is in writing a reliable regression test using a custom user model with a ManyToManyField and ensuring it passes across Django\u2019s test suite conventions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:26.033665"}
{"instance_id": "django__django-16454", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires investigating Django's custom argparse integration (CommandParser) and how subparsers are constructed so the extra error-formatting behavior is preserved. The implementation is likely localized (overriding/adjusting add_subparsers() to ensure created subparsers are also CommandParser instances and inherit the relevant kwargs), but care is needed to avoid altering argparse behavior for existing commands. Writing a regression test that exercises a management command with subparsers and asserts user-friendly error output (no traceback) will take meaningful time, along with running the management command test suite to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires investigating Django's custom argparse integration (CommandParser) and how subparsers are constructed so the extra error-formatting behavior is preserved. The implementation is likely localized (overriding/adjusting add_subparsers() to ensure created subparsers are also CommandParser instances and inherit the relevant kwargs), but care is needed to avoid altering argparse behavior for existing commands. Writing a regression test that exercises a management command with subparsers and asserts user-friendly error output (no traceback) will take meaningful time, along with running the management command test suite to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:26.074407"}
{"instance_id": "django__django-16263", "repo": "django/django", "estimated_minutes": 360.0, "justification": "This change requires non-trivial ORM/compiler work to determine which annotations are actually referenced by filters, other annotations, ordering, or grouping, and to safely drop the rest when generating COUNT/EXISTS queries. The relevant logic spans QuerySet.count()/exists(), Query aggregation/subquery construction, and SQL compiler behavior, making investigation and careful implementation necessary to avoid subtle regressions. Proper coverage needs multiple ORM tests to confirm unused annotations are stripped while referenced annotations (including through aliases and expressions) are preserved across different query shapes.", "time_breakdown": {"understanding_and_investigation": 150, "implementation": 120, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "4-6", "testing_complexity": "complex", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 360,\n  \"justification\": \"This change requires non-trivial ORM/compiler work to determine which annotations are actually referenced by filters, other annotations, ordering, or grouping, and to safely drop the rest when generating COUNT/EXISTS queries. The relevant logic spans QuerySet.count()/exists(), Query aggregation/subquery construction, and SQL compiler behavior, making investigation and careful implementation necessary to avoid subtle regressions. Proper coverage needs multiple ORM tests to confirm unused annotations are stripped while referenced annotations (including through aliases and expressions) are preserved across different query shapes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 150,\n    \"implementation\": 120,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:26.556707"}
{"instance_id": "django__django-16493", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-scoped (FileField.deconstruct behavior) and the hint strongly suggests the correct fix, but an engineer still needs to trace how callable storages are stored/evaluated (e.g., _storage_callable vs. self.storage) and ensure the change doesn\u2019t break existing deconstruction semantics. A regression test is required to prove that callable storages are preserved even when the callable returns default_storage, ideally in the migration/deconstruction test suite. Running Django\u2019s relevant test modules and verifying no migration serialization regressions adds meaningful time despite the likely small code change.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 35, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped (FileField.deconstruct behavior) and the hint strongly suggests the correct fix, but an engineer still needs to trace how callable storages are stored/evaluated (e.g., _storage_callable vs. self.storage) and ensure the change doesn\u2019t break existing deconstruction semantics. A regression test is required to prove that callable storages are preserved even when the callable returns default_storage, ideally in the migration/deconstruction test suite. Running Django\u2019s relevant test modules and verifying no migration serialization regressions adds meaningful time despite the likely small code change.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 35,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:26.905589"}
{"instance_id": "django__django-16560", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This change is conceptually straightforward (add a new BaseConstraint option and pass it into the ValidationError as its code), but Django constraints are tied into migrations via deconstruction and have established patterns that must be followed for backward compatibility. The engineer will need to locate all constraint subclasses/paths that call BaseConstraint.validate, ensure the new parameter is correctly stored, deconstructed, and represented, and update or add targeted tests verifying the ValidationError.code behavior. Running and iterating on Django\u2019s test suite for model constraints and migration serialization typically adds meaningful verification time even for small feature additions.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 60, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This change is conceptually straightforward (add a new BaseConstraint option and pass it into the ValidationError as its code), but Django constraints are tied into migrations via deconstruction and have established patterns that must be followed for backward compatibility. The engineer will need to locate all constraint subclasses/paths that call BaseConstraint.validate, ensure the new parameter is correctly stored, deconstructed, and represented, and update or add targeted tests verifying the ValidationError.code behavior. Running and iterating on Django\u2019s test suite for model constraints and migration serialization typically adds meaningful verification time even for small feature additions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 60,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:28.548653"}
{"instance_id": "django__django-16502", "repo": "django/django", "estimated_minutes": 270.0, "justification": "Fixing this requires understanding how Django\u2019s development server (runserver/WSGIServer) handles WSGI responses for HEAD requests and why the post-#26052 behavior no longer strips the body. The change will likely involve modifying the dev server\u2019s request/response handling (potentially adapting/overriding wsgiref behavior) to ensure the body iterator is consumed/discarded correctly while preserving headers such as Content-Length/ETag semantics. Proper regression tests will need to exercise the actual runserver HTTP stack (not just the test client), which adds setup and verification time across different response types and edge cases (e.g., streaming).", "time_breakdown": {"understanding_and_investigation": 105, "implementation": 60, "testing_and_verification": 105}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 270,\n  \"justification\": \"Fixing this requires understanding how Django\u2019s development server (runserver/WSGIServer) handles WSGI responses for HEAD requests and why the post-#26052 behavior no longer strips the body. The change will likely involve modifying the dev server\u2019s request/response handling (potentially adapting/overriding wsgiref behavior) to ensure the body iterator is consumed/discarded correctly while preserving headers such as Content-Length/ETag semantics. Proper regression tests will need to exercise the actual runserver HTTP stack (not just the test client), which adds setup and verification time across different response types and edge cases (e.g., streaming).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 105,\n    \"implementation\": 60,\n    \"testing_and_verification\": 105\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:29.190369"}
{"instance_id": "django__django-16139", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the fix is conceptually small (the password-change link should not assume the UserAdmin is accessed via the user\u2019s primary key), implementing it correctly in Django requires understanding how admin URL patterns, object lookup, and the `_to_field` mechanism interact. The engineer will likely need to adjust link generation to reliably target the password-change admin view using the actual primary key (or properly reversed URL), and ensure it behaves correctly when the change view is reached via a non-PK field. Most of the time will go into creating a solid regression test that reproduces navigation through an admin relation using `to_field`, and verifying the link resolves and does not regress other admin behaviors.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the fix is conceptually small (the password-change link should not assume the UserAdmin is accessed via the user\u2019s primary key), implementing it correctly in Django requires understanding how admin URL patterns, object lookup, and the `_to_field` mechanism interact. The engineer will likely need to adjust link generation to reliably target the password-change admin view using the actual primary key (or properly reversed URL), and ensure it behaves correctly when the change view is reached via a non-PK field. Most of the time will go into creating a solid regression test that reproduces navigation through an admin relation using `to_field`, and verifying the link resolves and does not regress other admin behaviors.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:29.330340"}
{"instance_id": "django__django-16661", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Although the issue is well reproduced with a concrete failing test, the root cause involves subtle ORM/model-meta behavior (a ForeignKey/OneToOneField used as a primary key being mistaken for a concrete parent link) inside ModelAdmin.lookup_allowed(). An experienced engineer will need to trace the lookup normalization/parent-shortcut logic, confirm the regression introduced by the referenced bisection commit, and ensure the fix doesn\u2019t weaken admin lookup protections. Implementing the correct detection and adding/adjusting targeted regression tests should be doable within a few hours, but requires careful verification across related inheritance/parent-link scenarios.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 55, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the issue is well reproduced with a concrete failing test, the root cause involves subtle ORM/model-meta behavior (a ForeignKey/OneToOneField used as a primary key being mistaken for a concrete parent link) inside ModelAdmin.lookup_allowed(). An experienced engineer will need to trace the lookup normalization/parent-shortcut logic, confirm the regression introduced by the referenced bisection commit, and ensure the fix doesn\u2019t weaken admin lookup protections. Implementing the correct detection and adding/adjusting targeted regression tests should be doable within a few hours, but requires careful verification across related inheritance/parent-link scenarios.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 55,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:29.439420"}
{"instance_id": "django__django-16612", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The underlying bug is well-scoped and the fix is straightforward (switching the redirect target to preserve the query string), but Django\u2019s admin request/URL handling conventions require some investigation to ensure the change matches existing APPEND_SLASH behavior. A regression test must be added in the admin test suite to reproduce the failing redirect with a query string and assert the correct 301 Location header. Additional time is needed to run the relevant admin/tests and ensure no redirect-related regressions across similar code paths.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 15, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The underlying bug is well-scoped and the fix is straightforward (switching the redirect target to preserve the query string), but Django\u2019s admin request/URL handling conventions require some investigation to ensure the change matches existing APPEND_SLASH behavior. A regression test must be added in the admin test suite to reproduce the failing redirect with a query string and assert the correct 301 Location header. Additional time is needed to run the relevant admin/tests and ensure no redirect-related regressions across similar code paths.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 15,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:29.896558"}
{"instance_id": "django__django-16256", "repo": "django/django", "estimated_minutes": 270.0, "justification": "Fixing this requires understanding how Django\u2019s related managers are constructed in related_descriptors.py and why the accidentally-inherited async QuerySet methods bypass related-manager-specific behavior (e.g., injecting the instance for FK relations or handling M2M through defaults). The implementation is conceptually straightforward (add proper acreate()/aget_or_create()/aupdate_or_create() wrappers on the generated related manager classes), but it must be done for multiple relation directions and manager types without breaking existing sync behavior. Writing reliable regression tests for async related-manager methods across FK and M2M relations (including reverse/forward and through table behavior) and running Django\u2019s test suite adds significant time.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 95, "testing_and_verification": 100}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "expert", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 270,\n  \"justification\": \"Fixing this requires understanding how Django\u2019s related managers are constructed in related_descriptors.py and why the accidentally-inherited async QuerySet methods bypass related-manager-specific behavior (e.g., injecting the instance for FK relations or handling M2M through defaults). The implementation is conceptually straightforward (add proper acreate()/aget_or_create()/aupdate_or_create() wrappers on the generated related manager classes), but it must be done for multiple relation directions and manager types without breaking existing sync behavior. Writing reliable regression tests for async related-manager methods across FK and M2M relations (including reverse/forward and through table behavior) and running Django\u2019s test suite adds significant time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 95,\n    \"testing_and_verification\": 100\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:30.183677"}
{"instance_id": "django__django-16595", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue is well-scoped with a clear reproduction case: Django's migration optimizer currently lacks a reduction rule for successive AlterField operations on the same field. Implementing this requires understanding the existing reduction/optimization mechanics and ensuring the new rule is correct across ordering and \"same field\" comparisons. A regression test must be added in Django's migration optimizer test suite and verified by running relevant test subsets to ensure no unintended optimization changes.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped with a clear reproduction case: Django's migration optimizer currently lacks a reduction rule for successive AlterField operations on the same field. Implementing this requires understanding the existing reduction/optimization mechanics and ensuring the new rule is correct across ordering and \\\"same field\\\" comparisons. A regression test must be added in Django's migration optimizer test suite and verified by running relevant test subsets to ensure no unintended optimization changes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:30.215528"}
{"instance_id": "django__django-16527", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The code change itself is small (adding an `has_add_permission` check to the `show_save_as_new` context flag), but Django\u2019s admin behavior is tightly coupled to permissions and template rendering, so validating the correct behavior requires targeted admin view tests. An experienced engineer will need time to confirm current admin permission semantics for \u201cSave as new\u201d, locate the right existing test patterns/fixtures, and add assertions that the button is (not) rendered under different permission combinations. Running the relevant admin test suite and adjusting for any brittle template assertions adds additional verification time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 15, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The code change itself is small (adding an `has_add_permission` check to the `show_save_as_new` context flag), but Django\u2019s admin behavior is tightly coupled to permissions and template rendering, so validating the correct behavior requires targeted admin view tests. An experienced engineer will need time to confirm current admin permission semantics for \u201cSave as new\u201d, locate the right existing test patterns/fixtures, and add assertions that the button is (not) rendered under different permission combinations. Running the relevant admin test suite and adjusting for any brittle template assertions adds additional verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 15,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:30.909415"}
{"instance_id": "django__django-16662", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Fixing this requires locating where migration files assemble and sort imports (likely in the migrations writer), then adjusting the sort key so plain \"import X\" lines are emitted before \"from X import Y\" lines within the same section. While the behavioral change is small, Django\u2019s migration rendering has existing import deduping/grouping logic that needs careful modification to avoid regressions. Proper coverage will require adding or updating tests to assert exact rendered migration output and running the relevant migrations test suite to ensure no unintended ordering changes elsewhere.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 50, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing this requires locating where migration files assemble and sort imports (likely in the migrations writer), then adjusting the sort key so plain \\\"import X\\\" lines are emitted before \\\"from X import Y\\\" lines within the same section. While the behavioral change is small, Django\u2019s migration rendering has existing import deduping/grouping logic that needs careful modification to avoid regressions. Proper coverage will require adding or updating tests to assert exact rendered migration output and running the relevant migrations test suite to ensure no unintended ordering changes elsewhere.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 50,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:31.497735"}
{"instance_id": "django__django-16819", "repo": "django/django", "estimated_minutes": 210.0, "justification": "The issue is relatively vague (\"reduce AddIndex/RemoveIndex operations\") and requires investigating Django's migration optimizer rules to identify when AddIndex/RemoveIndex can be safely elided or combined with other operations. Implementing the change likely involves adjusting optimization/reduction logic in the migrations framework and carefully handling edge cases (index naming, constraints, conditional/functional indexes, and backend-specific behaviors). Proper coverage will require adding or updating optimizer tests to assert the minimized operation lists and running the migrations test suite to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 80, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"The issue is relatively vague (\\\"reduce AddIndex/RemoveIndex operations\\\") and requires investigating Django's migration optimizer rules to identify when AddIndex/RemoveIndex can be safely elided or combined with other operations. Implementing the change likely involves adjusting optimization/reduction logic in the migrations framework and carefully handling edge cases (index naming, constraints, conditional/functional indexes, and backend-specific behaviors). Proper coverage will require adding or updating optimizer tests to assert the minimized operation lists and running the migrations test suite to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 80,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:31.587323"}
{"instance_id": "django__django-16899", "repo": "django/django", "estimated_minutes": 120.0, "justification": "This change is fairly well-scoped: adjust the ModelAdmin system check for `readonly_fields` so the raised `Error` message includes the offending field name (not just the index), matching the style used by other admin option checks. An engineer will need moderate time to locate the relevant check code (likely in admin checks), confirm existing message patterns, and ensure the change doesn\u2019t alter error IDs or semantics. Updating/adding targeted tests and running the admin checks test suite will likely take comparable time to the implementation due to Django\u2019s strict assertion patterns and potential knock-on failures from message text changes.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"This change is fairly well-scoped: adjust the ModelAdmin system check for `readonly_fields` so the raised `Error` message includes the offending field name (not just the index), matching the style used by other admin option checks. An engineer will need moderate time to locate the relevant check code (likely in admin checks), confirm existing message patterns, and ensure the change doesn\u2019t alter error IDs or semantics. Updating/adding targeted tests and running the admin checks test suite will likely take comparable time to the implementation due to Django\u2019s strict assertion patterns and potential knock-on failures from message text changes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:33.193610"}
{"instance_id": "django__django-16950", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Although the issue has clear reproduction steps and a suspected culprit, confirming exactly where the parent object\u2019s non-PK UUID \"to_field\" value is being nulled during inline formset construction requires careful debugging through Django admin/formset internals. The fix is likely small (conditional logic around clearing a defaulted \"to_field\" on unsaved instances), but it touches subtle behavior in model/form interaction and must avoid regressions for normal PK defaults and existing inline workflows. Writing a reliable regression test for the admin add view with inlines and a ForeignKey(to_field=UUIDField) adds additional time due to Django\u2019s admin test patterns and setup requirements.", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 55, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the issue has clear reproduction steps and a suspected culprit, confirming exactly where the parent object\u2019s non-PK UUID \\\"to_field\\\" value is being nulled during inline formset construction requires careful debugging through Django admin/formset internals. The fix is likely small (conditional logic around clearing a defaulted \\\"to_field\\\" on unsaved instances), but it touches subtle behavior in model/form interaction and must avoid regressions for normal PK defaults and existing inline workflows. Writing a reliable regression test for the admin add view with inlines and a ForeignKey(to_field=UUIDField) adds additional time due to Django\u2019s admin test patterns and setup requirements.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 55,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:33.335897"}
{"instance_id": "django__django-16938", "repo": "django/django", "estimated_minutes": 150.0, "justification": "The issue has a clear reproduction case and a suspected regression point, but fixing it correctly requires understanding Django's serializer m2m iteration path and the interaction between default/related managers, select_related(), and only()/defer() behavior. The likely code change is small (adjusting or clearing select_related before applying only(\"pk\")), but care is needed to avoid regressing the performance optimization and to ensure consistent behavior across relation managers. Writing a regression test in Django's serialization test suite and running targeted test subsets will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue has a clear reproduction case and a suspected regression point, but fixing it correctly requires understanding Django's serializer m2m iteration path and the interaction between default/related managers, select_related(), and only()/defer() behavior. The likely code change is small (adjusting or clearing select_related before applying only(\\\"pk\\\")), but care is needed to avoid regressing the performance optimization and to ensure consistent behavior across relation managers. Writing a regression test in Django's serialization test suite and running targeted test subsets will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:33.717657"}
{"instance_id": "django__django-16801", "repo": "django/django", "estimated_minutes": 150.0, "justification": "Although the functional change is conceptually simple (only connect the ImageField post_init receiver when width_field/height_field are configured), an engineer will need time to confirm where and how ImageField registers its signal handler and ensure there are no edge cases (e.g., model inheritance, field cloning, app loading). Implementing the conditional registration should be quick, but writing robust tests that assert signal listener presence/absence without being brittle, and running Django\u2019s relevant test suite to avoid regressions, will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the functional change is conceptually simple (only connect the ImageField post_init receiver when width_field/height_field are configured), an engineer will need time to confirm where and how ImageField registers its signal handler and ensure there are no edge cases (e.g., model inheritance, field cloning, app loading). Implementing the conditional registration should be quick, but writing robust tests that assert signal listener presence/absence without being brittle, and running Django\u2019s relevant test suite to avoid regressions, will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:35.274175"}
{"instance_id": "django__django-16901", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires understanding how Django represents XOR in Q objects and how the ORM compiler produces SQL when the backend lacks native XOR support. The bug only manifests for chained XOR with more than two operands, so the engineer must locate and adjust the fallback logic to implement true parity semantics (odd-number-of-true) rather than \"exactly one\". The change should be accompanied by targeted ORM tests covering 2+ operands across backends (especially PostgreSQL) and verifying no regressions in existing boolean/where-clause compilation behavior.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires understanding how Django represents XOR in Q objects and how the ORM compiler produces SQL when the backend lacks native XOR support. The bug only manifests for chained XOR with more than two operands, so the engineer must locate and adjust the fallback logic to implement true parity semantics (odd-number-of-true) rather than \\\"exactly one\\\". The change should be accompanied by targeted ORM tests covering 2+ operands across backends (especially PostgreSQL) and verifying no regressions in existing boolean/where-clause compilation behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:36.041219"}
{"instance_id": "django__django-17087", "repo": "django/django", "estimated_minutes": 120.0, "justification": "The issue is well-scoped and already points to the likely fix in django/db/migrations/serializer.py (using __qualname__ instead of __name__ when serializing class-bound functions), but an engineer will still need to confirm the exact serialization path for classmethods and how migration writer imports are generated. Implementing the change is small, yet Django requires a regression test in the migrations writer/serializer suite, and verifying no regressions typically involves running a focused subset of migration serialization tests (and possibly a broader migrations test run). Overall effort is dominated by understanding existing serializer conventions and writing a precise test that fails on current behavior and passes with the fix.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 15, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped and already points to the likely fix in django/db/migrations/serializer.py (using __qualname__ instead of __name__ when serializing class-bound functions), but an engineer will still need to confirm the exact serialization path for classmethods and how migration writer imports are generated. Implementing the change is small, yet Django requires a regression test in the migrations writer/serializer suite, and verifying no regressions typically involves running a focused subset of migration serialization tests (and possibly a broader migrations test run). Overall effort is dominated by understanding existing serializer conventions and writing a precise test that fails on current behavior and passes with the fix.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 15,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:36.220186"}
{"instance_id": "matplotlib__matplotlib-14623", "repo": "matplotlib/matplotlib", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and the hints point to a specific prior regression and an upstream commit that contains the minimal fix, reducing open-ended debugging. However, the engineer still needs to understand how axis inversion is determined for log scales (likely in limit-setting / scale handling code), apply the extracted change cleanly, and ensure it aligns with Matplotlib\u2019s conventions. Adding a regression test for log-scale inversion and running the relevant test suite (including image/comparison behavior checks if applicable) will take a substantial portion of the time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and the hints point to a specific prior regression and an upstream commit that contains the minimal fix, reducing open-ended debugging. However, the engineer still needs to understand how axis inversion is determined for log scales (likely in limit-setting / scale handling code), apply the extracted change cleanly, and ensure it aligns with Matplotlib\u2019s conventions. Adding a regression test for log-scale inversion and running the relevant test suite (including image/comparison behavior checks if applicable) will take a substantial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:36.949942"}
{"instance_id": "matplotlib__matplotlib-13989", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible and already bisected to a specific commit, which reduces exploratory time, but fixing it likely requires understanding the interaction between Matplotlib's hist() bin selection (\"auto\"), the range= argument, and the density normalization path. The engineer will need to trace how bin edges are computed and potentially adjusted when density=True, ensuring that the requested range is preserved while not breaking other binning modes. A proper regression test should be added (covering both density=True/False and auto bins), and the fix should be validated against Matplotlib's plotting test suite to avoid subtle behavioral regressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible and already bisected to a specific commit, which reduces exploratory time, but fixing it likely requires understanding the interaction between Matplotlib's hist() bin selection (\\\"auto\\\"), the range= argument, and the density normalization path. The engineer will need to trace how bin edges are computed and potentially adjusted when density=True, ensuring that the requested range is preserved while not breaking other binning modes. A proper regression test should be added (covering both density=True/False and auto bins), and the fix should be validated against Matplotlib's plotting test suite to avoid subtle behavioral regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:37.067130"}
{"instance_id": "django__django-7530", "repo": "django/django", "estimated_minutes": 180.0, "justification": "Fixing this requires tracing how makemigrations performs router consistency checks and where it iterates over apps/models to call router.allow_migrate(). The behavioral change is conceptually small (ensure only an app\u2019s own models are paired with its app_label) but it touches migration autodetection/command plumbing and must be validated against router behavior. Writing a regression test is non-trivial because it needs a custom router and a project-like model setup that would fail under the current incorrect cross-product of (app_label, model).", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires tracing how makemigrations performs router consistency checks and where it iterates over apps/models to call router.allow_migrate(). The behavioral change is conceptually small (ensure only an app\u2019s own models are paired with its app_label) but it touches migration autodetection/command plumbing and must be validated against router behavior. Writing a regression test is non-trivial because it needs a custom router and a project-like model setup that would fail under the current incorrect cross-product of (app_label, model).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:37.200441"}
{"instance_id": "django__django-16631", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Fixing this requires understanding how Django derives and validates the session authentication hash (e.g., _auth_user_hash) and where SECRET_KEY_FALLBACKS is (and isn\u2019t) consulted during authentication/session validation. The change will likely touch the auth session verification path (e.g., AuthenticationMiddleware/auth.get_user) and/or AbstractBaseUser.get_session_auth_hash to validate against fallback-derived hashes, while preserving existing behavior and security properties. Proper regression tests must simulate key rotation with override_settings and verify that sessions remain valid with fallbacks but become invalid once fallbacks are removed.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 60, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Fixing this requires understanding how Django derives and validates the session authentication hash (e.g., _auth_user_hash) and where SECRET_KEY_FALLBACKS is (and isn\u2019t) consulted during authentication/session validation. The change will likely touch the auth session verification path (e.g., AuthenticationMiddleware/auth.get_user) and/or AbstractBaseUser.get_session_auth_hash to validate against fallback-derived hashes, while preserving existing behavior and security properties. Proper regression tests must simulate key rotation with override_settings and verify that sessions remain valid with fallbacks but become invalid once fallbacks are removed.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 60,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:37.424188"}
{"instance_id": "django__django-16877", "repo": "django/django", "estimated_minutes": 210.0, "justification": "Implementing a new built-in template filter in Django requires investigating existing filter patterns (especially `safeseq`, `escape`, `join`, and autoescape behavior) to ensure `escapeseq` interacts correctly with SafeData and doesn\u2019t double-escape. The implementation itself is fairly small but must match Django\u2019s established conventions (registration, handling of iterables vs. strings, and safety semantics). The bulk of time will be in writing comprehensive tests for autoescape-off scenarios and edge cases, plus updating documentation to include the new filter and its intended usage.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Implementing a new built-in template filter in Django requires investigating existing filter patterns (especially `safeseq`, `escape`, `join`, and autoescape behavior) to ensure `escapeseq` interacts correctly with SafeData and doesn\u2019t double-escape. The implementation itself is fairly small but must match Django\u2019s established conventions (registration, handling of iterables vs. strings, and safety semantics). The bulk of time will be in writing comprehensive tests for autoescape-off scenarios and edge cases, plus updating documentation to include the new filter and its intended usage.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:38.259023"}
{"instance_id": "django__django-9296", "repo": "django/django", "estimated_minutes": 120.0, "justification": "Implementing __iter__ on Django's Paginator is a small, well-scoped change, but it still requires confirming existing paginator semantics (page_range, page(), caching behavior, and empty datasets) and ensuring it matches Django's API expectations. The bulk of the time will be spent adding and running appropriate tests (including edge cases like empty querysets/lists and multiple pages) and verifying no unintended interactions with existing pagination behavior. A minor documentation or release-note touch may also be needed depending on Django's contribution conventions for new public API behavior.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 20, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"Implementing __iter__ on Django's Paginator is a small, well-scoped change, but it still requires confirming existing paginator semantics (page_range, page(), caching behavior, and empty datasets) and ensuring it matches Django's API expectations. The bulk of the time will be spent adding and running appropriate tests (including edge cases like empty querysets/lists and multiple pages) and verifying no unintended interactions with existing pagination behavior. A minor documentation or release-note touch may also be needed depending on Django's contribution conventions for new public API behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 20,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:39.540377"}
{"instance_id": "matplotlib__matplotlib-20676", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible but requires investigating Matplotlib\u2019s widget initialization path to find why creating an interactive SpanSelector triggers autoscaling and expands the x-limits to include 0. The fix is likely a small behavioral change (e.g., preventing the selector\u2019s artists from participating in autoscale or avoiding creating data-coordinate artists with default x=0), but it must be implemented carefully to avoid breaking other SpanSelector behaviors. Writing a regression test is moderately involved because widget code often touches drawing/artist setup and needs to be validated in a backend-agnostic way.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 50, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible but requires investigating Matplotlib\u2019s widget initialization path to find why creating an interactive SpanSelector triggers autoscaling and expands the x-limits to include 0. The fix is likely a small behavioral change (e.g., preventing the selector\u2019s artists from participating in autoscale or avoiding creating data-coordinate artists with default x=0), but it must be implemented carefully to avoid breaking other SpanSelector behaviors. Writing a regression test is moderately involved because widget code often touches drawing/artist setup and needs to be validated in a backend-agnostic way.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 50,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:39.955341"}
{"instance_id": "matplotlib__matplotlib-22719", "repo": "matplotlib/matplotlib", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and the likely fix is small and localized (guarding deprecation/warning logic on non-empty arrays in the categorical unit converter), but an engineer still needs to confirm the warning/error path and ensure the behavior aligns with Matplotlib\u2019s units/deprecation policy. The main time cost is adding robust regression tests that cover both the empty-input plotting path and unit conversion calls, and then running the relevant portions of Matplotlib\u2019s test suite to avoid regressions in categorical handling.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 25, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and the likely fix is small and localized (guarding deprecation/warning logic on non-empty arrays in the categorical unit converter), but an engineer still needs to confirm the warning/error path and ensure the behavior aligns with Matplotlib\u2019s units/deprecation policy. The main time cost is adding robust regression tests that cover both the empty-input plotting path and unit conversion calls, and then running the relevant portions of Matplotlib\u2019s test suite to avoid regressions in categorical handling.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 25,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:40.511930"}
{"instance_id": "matplotlib__matplotlib-20826", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "Although the repro is clear and a likely cause is identified (clearing tick keyword dictionaries drops visibility settings and rcParams are applied at an unexpected point), an engineer will still need to trace the clear/init/tick_params interactions across Axes/Axis to ensure the fix is correct and doesn\u2019t regress unrelated styling behavior. Implementing the fix will likely involve adjusting where/when tick rcParams or tick visibility state is applied/restored during Axes.clear (and possibly Axis.clear) while preserving shared-axis label-hiding semantics. Writing robust tests in Matplotlib for tick/ticklabel visibility (potentially including an image-comparison test) and running the relevant test suite portions will take a significant fraction of the time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the repro is clear and a likely cause is identified (clearing tick keyword dictionaries drops visibility settings and rcParams are applied at an unexpected point), an engineer will still need to trace the clear/init/tick_params interactions across Axes/Axis to ensure the fix is correct and doesn\u2019t regress unrelated styling behavior. Implementing the fix will likely involve adjusting where/when tick rcParams or tick visibility state is applied/restored during Axes.clear (and possibly Axis.clear) while preserving shared-axis label-hiding semantics. Writing robust tests in Matplotlib for tick/ticklabel visibility (potentially including an image-comparison test) and running the relevant test suite portions will take a significant fraction of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:40.515326"}
{"instance_id": "django__django-16642", "repo": "django/django", "estimated_minutes": 150.0, "justification": "An engineer will need to trace how FileResponse determines Content-Type (likely via Python's mimetypes.guess_type()) and confirm how Django currently handles the returned \"encoding\" for extensions like .br and .Z. The fix is probably localized (adjusting header inference so compressed-suffix encodings don\u2019t lead to misleading Content-Type, and/or setting Content-Encoding appropriately), but it requires careful alignment with Django\u2019s existing behavior and compatibility expectations. Writing regression tests for multiple extensions and verifying headers across platforms/Python versions adds meaningful time, as mimetypes behavior can vary depending on environment and mappings.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"An engineer will need to trace how FileResponse determines Content-Type (likely via Python's mimetypes.guess_type()) and confirm how Django currently handles the returned \\\"encoding\\\" for extensions like .br and .Z. The fix is probably localized (adjusting header inference so compressed-suffix encodings don\u2019t lead to misleading Content-Type, and/or setting Content-Encoding appropriately), but it requires careful alignment with Django\u2019s existing behavior and compatibility expectations. Writing regression tests for multiple extensions and verifying headers across platforms/Python versions adds meaningful time, as mimetypes behavior can vary depending on environment and mappings.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:41.958559"}
{"instance_id": "matplotlib__matplotlib-22871", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "Although the issue has a clear reproducer, fixing it requires understanding the nontrivial logic inside ConciseDateFormatter that selects tick-label formats and separately constructs the offset text, including edge cases when the visible range is <1 year and does not include January. The fix will likely involve adjusting the offset-generation heuristics (e.g., determining when the year must be included based on axis span and tick locations) and ensuring it doesn\u2019t regress other date-range scenarios. Adding robust tests for multiple date windows and verifying image/text output across backends adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 60, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the issue has a clear reproducer, fixing it requires understanding the nontrivial logic inside ConciseDateFormatter that selects tick-label formats and separately constructs the offset text, including edge cases when the visible range is <1 year and does not include January. The fix will likely involve adjusting the offset-generation heuristics (e.g., determining when the year must be included based on axis span and tick locations) and ensuring it doesn\u2019t regress other date-range scenarios. Adding robust tests for multiple date windows and verifying image/text output across backends adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 60,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:42.689782"}
{"instance_id": "django__django-17029", "repo": "django/django", "estimated_minutes": 90.0, "justification": "Although the proposed code change is likely a one-liner (calling cache_clear() on the lru_cache-wrapped method), an engineer will need to locate the exact implementation and call sites of get_swappable_settings_name and Apps.clear_cache() to ensure the fix is correct and consistent with Django\u2019s registry/cache semantics. The main time cost is designing a reliable regression test that asserts the cache is populated and then emptied by clear_cache(), without being flaky across different test configurations. Running and iterating on the relevant Django test modules to confirm no regressions (and that the change works across multiple Python versions/settings patterns) adds additional verification time.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 10, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"Although the proposed code change is likely a one-liner (calling cache_clear() on the lru_cache-wrapped method), an engineer will need to locate the exact implementation and call sites of get_swappable_settings_name and Apps.clear_cache() to ensure the fix is correct and consistent with Django\u2019s registry/cache semantics. The main time cost is designing a reliable regression test that asserts the cache is populated and then emptied by clear_cache(), without being flaky across different test configurations. Running and iterating on the relevant Django test modules to confirm no regressions (and that the change works across multiple Python versions/settings patterns) adds additional verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 10,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:43.023970"}
{"instance_id": "matplotlib__matplotlib-23412", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The issue is well-reproduced and already points to the likely root cause in patches.py where dash offset is effectively forced to 0, so the code change itself is small. However, confirming the intended behavior across backends, ensuring no regressions for existing patch linestyle handling, and adding a robust image/renderer-based test for dash offset on patch strokes will take the majority of the time. Matplotlib\u2019s testing conventions (often requiring baseline image comparisons or careful inspection of renderer state) add non-trivial overhead even for a one-line behavioral fix.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 25, "testing_and_verification": 105}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-reproduced and already points to the likely root cause in patches.py where dash offset is effectively forced to 0, so the code change itself is small. However, confirming the intended behavior across backends, ensuring no regressions for existing patch linestyle handling, and adding a robust image/renderer-based test for dash offset on patch strokes will take the majority of the time. Matplotlib\u2019s testing conventions (often requiring baseline image comparisons or careful inspection of renderer state) add non-trivial overhead even for a one-line behavioral fix.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 25,\n    \"testing_and_verification\": 105\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:43.391524"}
{"instance_id": "matplotlib__matplotlib-20859", "repo": "matplotlib/matplotlib", "estimated_minutes": 135.0, "justification": "The core failure is clear and reproducible: Legend rejects SubFigure as a valid parent, so the fix is likely a small change in legend parenting/type checks. However, the engineer will need to confirm the intended API semantics for SubFigure legends, ensure layout/tight-bbox interactions aren\u2019t inadvertently broken, and add a regression test in Matplotlib\u2019s fairly involved testing harness. Writing and validating a robust test (including rendering/saving paths) typically dominates the time over the one-line code change.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 135,\n  \"justification\": \"The core failure is clear and reproducible: Legend rejects SubFigure as a valid parent, so the fix is likely a small change in legend parenting/type checks. However, the engineer will need to confirm the intended API semantics for SubFigure legends, ensure layout/tight-bbox interactions aren\u2019t inadvertently broken, and add a regression test in Matplotlib\u2019s fairly involved testing harness. Writing and validating a robust test (including rendering/saving paths) typically dominates the time over the one-line code change.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:43.565761"}
{"instance_id": "matplotlib__matplotlib-24149", "repo": "matplotlib/matplotlib", "estimated_minutes": 150.0, "justification": "The issue has a clear reproducer and a likely root cause already identified in Axes._convert_dx calling cbook._safe_first_finite, which now raises StopIteration when all elements are NaN. The code change is small but must be done carefully to preserve behavior for unit-converted inputs and other iterable types, and to avoid reintroducing the original \u201cleading NaN\u201d bug fixed in 3.6.1. Writing a robust regression test in Matplotlib\u2019s test suite and running targeted tests (likely across multiple parameterizations) will take a substantial portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue has a clear reproducer and a likely root cause already identified in Axes._convert_dx calling cbook._safe_first_finite, which now raises StopIteration when all elements are NaN. The code change is small but must be done carefully to preserve behavior for unit-converted inputs and other iterable types, and to avoid reintroducing the original \u201cleading NaN\u201d bug fixed in 3.6.1. Writing a robust regression test in Matplotlib\u2019s test suite and running targeted tests (likely across multiple parameterizations) will take a substantial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:43.774806"}
{"instance_id": "matplotlib__matplotlib-22865", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible but likely requires understanding how Colorbar draws its segment boundaries versus how the extend patches (triangles/rectangles) are added, which is nontrivial Matplotlib internals. The fix will probably involve adjusting the edge-drawing logic to include boundaries at the start/end of the colorbar when extend='both' (and ensuring it works for horizontal/vertical orientations). Proper verification in Matplotlib typically requires adding or updating an image comparison test for colorbars, which adds meaningful time for test authoring and local baseline validation.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 45, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible but likely requires understanding how Colorbar draws its segment boundaries versus how the extend patches (triangles/rectangles) are added, which is nontrivial Matplotlib internals. The fix will probably involve adjusting the edge-drawing logic to include boundaries at the start/end of the colorbar when extend='both' (and ensuring it works for horizontal/vertical orientations). Proper verification in Matplotlib typically requires adding or updating an image comparison test for colorbars, which adds meaningful time for test authoring and local baseline validation.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 45,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:43.867316"}
{"instance_id": "matplotlib__matplotlib-24570", "repo": "matplotlib/matplotlib", "estimated_minutes": 210.0, "justification": "Although the underlying fix is likely a small change in the alignment mapping (e.g., swapping the handling of top/bottom in offsetbox alignment code), this touches user-visible behavior and requires careful consideration of backward compatibility and existing semantics. An engineer will need to confirm current behavior across HPacker/VPacker, identify the precise code path (_get_aligned_offsets and callers), and decide whether to treat this as a bugfix or implement a compatibility mechanism consistent with Matplotlib\u2019s deprecation policies. Writing robust tests for pixel/layout alignment and validating against existing offsetbox/legend layout tests adds meaningful time due to rendering/layout subtleties and cross-backend considerations.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the underlying fix is likely a small change in the alignment mapping (e.g., swapping the handling of top/bottom in offsetbox alignment code), this touches user-visible behavior and requires careful consideration of backward compatibility and existing semantics. An engineer will need to confirm current behavior across HPacker/VPacker, identify the precise code path (_get_aligned_offsets and callers), and decide whether to treat this as a bugfix or implement a compatibility mechanism consistent with Matplotlib\u2019s deprecation policies. Writing robust tests for pixel/layout alignment and validating against existing offsetbox/legend layout tests adds meaningful time due to rendering/layout subtleties and cross-backend considerations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:44.905216"}
{"instance_id": "matplotlib__matplotlib-21568", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "Although the user has a clear reproducer and a likely fix direction (adjusting how datetime tick labels are wrapped for TeX), an engineer will need to trace where the TeX-wrapping behavior changed between 3.3 and 3.4 and ensure the solution is consistent with Matplotlib\u2019s usetex/mathtext conventions. The implementation itself is likely a small change in the date formatter\u2019s TeX wrapper, but care is needed to correctly protect spaces and punctuation without breaking other tick label cases. Writing reliable tests is non-trivial because the issue is ultimately about rendered spacing, so tests will likely focus on generated TeX strings and/or add/adjust a usetex-based rendering/image test depending on existing infrastructure.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the user has a clear reproducer and a likely fix direction (adjusting how datetime tick labels are wrapped for TeX), an engineer will need to trace where the TeX-wrapping behavior changed between 3.3 and 3.4 and ensure the solution is consistent with Matplotlib\u2019s usetex/mathtext conventions. The implementation itself is likely a small change in the date formatter\u2019s TeX wrapper, but care is needed to correctly protect spaces and punctuation without breaking other tick label cases. Writing reliable tests is non-trivial because the issue is ultimately about rendered spacing, so tests will likely focus on generated TeX strings and/or add/adjust a usetex-based rendering/image test depending on existing infrastructure.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:45.371225"}
{"instance_id": "matplotlib__matplotlib-20488", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The failure is intermittent and likely driven by a dependency behavior change (NumPy 1.21 masked-array semantics), so a significant portion of time will be spent reproducing and isolating when/why LogNorm ends up with non-finite vmin/vmax. The probable fix is localized (handling fully-masked/degenerate arrays or autoscaling behavior in Normalize/LogNorm), but it must be done carefully to avoid changing normalization semantics for valid data. Proper regression coverage will require adjusting or extending tests around masked images + LogNorm and validating against multiple NumPy versions to ensure the flake is eliminated without introducing new failures.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The failure is intermittent and likely driven by a dependency behavior change (NumPy 1.21 masked-array semantics), so a significant portion of time will be spent reproducing and isolating when/why LogNorm ends up with non-finite vmin/vmax. The probable fix is localized (handling fully-masked/degenerate arrays or autoscaling behavior in Normalize/LogNorm), but it must be done carefully to avoid changing normalization semantics for valid data. Proper regression coverage will require adjusting or extending tests around masked images + LogNorm and validating against multiple NumPy versions to ensure the flake is eliminated without introducing new failures.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:46.406239"}
{"instance_id": "matplotlib__matplotlib-23476", "repo": "matplotlib/matplotlib", "estimated_minutes": 240.0, "justification": "Although the reproduction is clear, the root cause likely spans figure pickling/unpickling and backend-specific HiDPI handling (MacOSX/device pixel ratio), so an engineer will need time to trace where DPI is being scaled and then serialized. The fix is probably small (ensure the unscaled/original DPI is persisted or restored during __getstate__/__setstate__, or prevent backend scaling from being re-applied after unpickle), but it must be done carefully to avoid regressions for other HiDPI backends. Writing a robust regression test is non-trivial because the bug is backend/platform dependent and may require conditional testing or mocking of the device pixel ratio behavior.", "time_breakdown": {"understanding_and_investigation": 100, "implementation": 60, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Although the reproduction is clear, the root cause likely spans figure pickling/unpickling and backend-specific HiDPI handling (MacOSX/device pixel ratio), so an engineer will need time to trace where DPI is being scaled and then serialized. The fix is probably small (ensure the unscaled/original DPI is persisted or restored during __getstate__/__setstate__, or prevent backend scaling from being re-applied after unpickle), but it must be done carefully to avoid regressions for other HiDPI backends. Writing a robust regression test is non-trivial because the bug is backend/platform dependent and may require conditional testing or mocking of the device pixel ratio behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 100,\n    \"implementation\": 60,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:46.762451"}
{"instance_id": "django__django-17084", "repo": "django/django", "estimated_minutes": 180.0, "justification": "This appears to be a behavioral regression in Django 4.2\u2019s ORM SQL generation where an aggregate is compiled directly over an expression containing a window function, producing SQL like SUM(SUM(...) OVER (...)) which PostgreSQL rejects. Fixing it likely requires understanding how QuerySet.aggregate() decides whether to wrap the current query in a subquery and extending that logic to treat \"contains OVER clause\" similarly to existing \"contains aggregate\" handling. A proper fix also needs a PostgreSQL-specific regression test ensuring the ORM generates a subquery (or otherwise avoids nesting an aggregate over a window) and verifying results match expectations.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This appears to be a behavioral regression in Django 4.2\u2019s ORM SQL generation where an aggregate is compiled directly over an expression containing a window function, producing SQL like SUM(SUM(...) OVER (...)) which PostgreSQL rejects. Fixing it likely requires understanding how QuerySet.aggregate() decides whether to wrap the current query in a subquery and extending that logic to treat \\\"contains OVER clause\\\" similarly to existing \\\"contains aggregate\\\" handling. A proper fix also needs a PostgreSQL-specific regression test ensuring the ORM generates a subquery (or otherwise avoids nesting an aggregate over a window) and verifying results match expectations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:47.920243"}
{"instance_id": "matplotlib__matplotlib-24637", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The issue is well-scoped and reproducible, but requires understanding how AnnotationBbox composes multiple child artists and how the SVG backend assigns gids via renderer group handling. Implementing the fix is likely straightforward (wrapping AnnotationBbox.draw with renderer.open_group/close_group using the artist gid), but confirming the correct API usage and avoiding unintended effects across backends will take some investigation. Writing a robust SVG regression test (that doesn\u2019t rely on external image files and is stable across minor SVG output differences) and running the relevant test suite will be a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-scoped and reproducible, but requires understanding how AnnotationBbox composes multiple child artists and how the SVG backend assigns gids via renderer group handling. Implementing the fix is likely straightforward (wrapping AnnotationBbox.draw with renderer.open_group/close_group using the artist gid), but confirming the correct API usage and avoiding unintended effects across backends will take some investigation. Writing a robust SVG regression test (that doesn\u2019t rely on external image files and is stable across minor SVG output differences) and running the relevant test suite will be a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:48.769349"}
{"instance_id": "matplotlib__matplotlib-23314", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible, but fixing it likely requires tracing how mplot3d\u2019s Axes3D overrides the normal Axes draw pipeline and ensuring the visibility flag is respected (e.g., an early-return in a custom draw method). Matplotlib\u2019s rendering and artist-visibility behavior has a lot of subtle interactions (layout, tightbbox, and child artists), so some time will be spent confirming the fix doesn\u2019t break 3D rendering or layout. Proper regression coverage will likely require adding or adjusting mplot3d tests (potentially including an image-comparison test), and running the relevant test subsets to verify no regressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible, but fixing it likely requires tracing how mplot3d\u2019s Axes3D overrides the normal Axes draw pipeline and ensuring the visibility flag is respected (e.g., an early-return in a custom draw method). Matplotlib\u2019s rendering and artist-visibility behavior has a lot of subtle interactions (layout, tightbbox, and child artists), so some time will be spent confirming the fix doesn\u2019t break 3D rendering or layout. Proper regression coverage will likely require adding or adjusting mplot3d tests (potentially including an image-comparison test), and running the relevant test subsets to verify no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:49.735473"}
{"instance_id": "matplotlib__matplotlib-23299", "repo": "matplotlib/matplotlib", "estimated_minutes": 210.0, "justification": "Although the issue has a clear reproducer, the root cause likely involves subtle interactions between lazy backend resolution, rc_context state restoration (including the auto-backend sentinel), and pyplot's backend switching logic that can tear down existing figure managers. An experienced engineer will need time to trace where get_backend() triggers backend (re-)resolution and why that path closes figures, then implement a fix that avoids side effects while preserving expected backend-selection semantics. Writing a robust regression test is non-trivial because the failure depends on backend auto-resolution behavior and figure-manager lifecycle, which must be exercised in a headless CI-safe way.", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 60, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the issue has a clear reproducer, the root cause likely involves subtle interactions between lazy backend resolution, rc_context state restoration (including the auto-backend sentinel), and pyplot's backend switching logic that can tear down existing figure managers. An experienced engineer will need time to trace where get_backend() triggers backend (re-)resolution and why that path closes figures, then implement a fix that avoids side effects while preserving expected backend-selection semantics. Writing a robust regression test is non-trivial because the failure depends on backend auto-resolution behavior and figure-manager lifecycle, which must be exercised in a headless CI-safe way.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 60,\n    \"testing_and_verification\": 55\n    },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:50.160550"}
{"instance_id": "matplotlib__matplotlib-24970", "repo": "matplotlib/matplotlib", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and localized to the colormap indexing path in `matplotlib/colors.py`, but requires understanding how the lookup table reserves extra indices for over/under/bad and how different input dtypes (especially `uint8`) are handled. The fix is likely small (explicitly promoting/casting the index array to a dtype that can represent `N+2` without overflow) but must preserve existing behavior across masked arrays and multiple colormap types. Writing a regression test that reliably fails on NumPy 1.24+ (by treating the deprecation as an error or asserting no warning) and validating against the existing test suite adds non-trivial time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and localized to the colormap indexing path in `matplotlib/colors.py`, but requires understanding how the lookup table reserves extra indices for over/under/bad and how different input dtypes (especially `uint8`) are handled. The fix is likely small (explicitly promoting/casting the index array to a dtype that can represent `N+2` without overflow) but must preserve existing behavior across masked arrays and multiple colormap types. Writing a regression test that reliably fails on NumPy 1.24+ (by treating the deprecation as an error or asserting no warning) and validating against the existing test suite adds non-trivial time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:50.222253"}
{"instance_id": "matplotlib__matplotlib-25287", "repo": "matplotlib/matplotlib", "estimated_minutes": 150.0, "justification": "The bug is clearly reproducible and localized (offsetText color uses tick.color instead of tick.labelcolor), but the correct fix needs to match Matplotlib\u2019s existing precedence rules (rcParams defaults, 'inherit' behavior, and tick_params overrides). An engineer will need to inspect how tick/label colors are resolved on Axis objects and ensure offsetText updates consistently for both x and y axes. Writing a robust regression test (likely image- or property-based) and validating it across backends/CI expectations adds meaningful time beyond the small code change itself.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 45, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The bug is clearly reproducible and localized (offsetText color uses tick.color instead of tick.labelcolor), but the correct fix needs to match Matplotlib\u2019s existing precedence rules (rcParams defaults, 'inherit' behavior, and tick_params overrides). An engineer will need to inspect how tick/label colors are resolved on Axis objects and ensure offsetText updates consistently for both x and y axes. Writing a robust regression test (likely image- or property-based) and validating it across backends/CI expectations adds meaningful time beyond the small code change itself.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 45,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:50.976170"}
{"instance_id": "matplotlib__matplotlib-24627", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible but requires investigating Matplotlib\u2019s internal artist ownership lifecycle to determine why Axes.clear()/cla() (and likely Figure.clear()/clf()) do not mirror Artist.remove() behavior in unsetting references. The fix will likely involve updating the axes/figure clearing logic to properly \u201cde-parent\u201d all removed child artists across multiple artist types (lines, patches, images, collections, texts), which must be done carefully to avoid breaking invariants or callbacks. Proper regression tests are needed to cover both axes- and figure-level clearing and to ensure no regressions in artist reuse or rendering behavior.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 50, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible but requires investigating Matplotlib\u2019s internal artist ownership lifecycle to determine why Axes.clear()/cla() (and likely Figure.clear()/clf()) do not mirror Artist.remove() behavior in unsetting references. The fix will likely involve updating the axes/figure clearing logic to properly \u201cde-parent\u201d all removed child artists across multiple artist types (lines, patches, images, collections, texts), which must be done carefully to avoid breaking invariants or callbacks. Proper regression tests are needed to cover both axes- and figure-level clearing and to ensure no regressions in artist reuse or rendering behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 50,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:51.674205"}
{"instance_id": "matplotlib__matplotlib-24870", "repo": "matplotlib/matplotlib", "estimated_minutes": 210.0, "justification": "This enhancement requires understanding where Matplotlib computes default contour levels (likely in the QuadContourSet/contour module) and safely branching behavior only for true boolean inputs without affecting existing numeric arrays that happen to contain 0/1 values. The implementation is moderate because it must handle both contour() and contourf() defaults (including contourf\u2019s requirement for at least 2 levels) and integrate with existing argument/normalization logic. Writing robust tests is non-trivial in Matplotlib due to established testing patterns (often involving properties of the ContourSet and sometimes image-based comparisons) and the need to ensure no regressions across masked arrays and dtype edge cases.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 70, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This enhancement requires understanding where Matplotlib computes default contour levels (likely in the QuadContourSet/contour module) and safely branching behavior only for true boolean inputs without affecting existing numeric arrays that happen to contain 0/1 values. The implementation is moderate because it must handle both contour() and contourf() defaults (including contourf\u2019s requirement for at least 2 levels) and integrate with existing argument/normalization logic. Writing robust tests is non-trivial in Matplotlib due to established testing patterns (often involving properties of the ContourSet and sometimes image-based comparisons) and the need to ensure no regressions across masked arrays and dtype edge cases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 70,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:51.812481"}
{"instance_id": "django__django-16667", "repo": "django/django", "estimated_minutes": 110.0, "justification": "The issue is clearly reproducible and points directly to a specific code path (SelectDateWidget.value_from_datadict constructing a datetime.date from untrusted integers), so investigation is moderate rather than extensive. The fix is likely a small, targeted change (catching OverflowError alongside ValueError and returning a value that allows normal DateField validation to raise a ValidationError instead of crashing). Time is mainly driven by identifying the correct fallback behavior to preserve existing validation semantics and adding a regression test in Django\u2019s forms/widget test suite, then running relevant tests to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 110,\n  \"justification\": \"The issue is clearly reproducible and points directly to a specific code path (SelectDateWidget.value_from_datadict constructing a datetime.date from untrusted integers), so investigation is moderate rather than extensive. The fix is likely a small, targeted change (catching OverflowError alongside ValueError and returning a value that allows normal DateField validation to raise a ValidationError instead of crashing). Time is mainly driven by identifying the correct fallback behavior to preserve existing validation semantics and adding a regression test in Django\u2019s forms/widget test suite, then running relevant tests to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:52.186270"}
{"instance_id": "matplotlib__matplotlib-26208", "repo": "matplotlib/matplotlib", "estimated_minutes": 210.0, "justification": "The issue is reproducible but involves a subtle interaction between twinned axes, stackplot internals, and Matplotlib\u2019s unit/categorical conversion machinery that started behaving differently in 3.4.0+. An experienced engineer will likely need to trace where data limits are being updated during unit processing and why a shared-x twin causes ax1\u2019s dataLim to be overwritten with \u00b1inf. The fix should be localized but must be carefully integrated to avoid regressions across unit handling and shared-axis behaviors, requiring targeted tests and a focused test run.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"The issue is reproducible but involves a subtle interaction between twinned axes, stackplot internals, and Matplotlib\u2019s unit/categorical conversion machinery that started behaving differently in 3.4.0+. An experienced engineer will likely need to trace where data limits are being updated during unit processing and why a shared-x twin causes ax1\u2019s dataLim to be overwritten with \u00b1inf. The fix should be localized but must be carefully integrated to avoid regressions across unit handling and shared-axis behaviors, requiring targeted tests and a focused test run.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:53.056349"}
{"instance_id": "matplotlib__matplotlib-25479", "repo": "matplotlib/matplotlib", "estimated_minutes": 150.0, "justification": "The issue is well-reproduced but requires understanding the interaction between pyplot's `set_cmap`, rcParams (`image.cmap`), and the colormap registry where the registered key can differ from `cmap.name`. The code change is likely small (ensuring pyplot persists the user-provided registered name rather than the colormap object's internal name), but it touches a user-facing API and must be validated against the newer `colormaps.register` pathway and existing name-validation behavior. Writing a focused regression test and running the relevant Matplotlib test suite portion adds non-trivial time due to repository conventions and potential backend/rcParam interactions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-reproduced but requires understanding the interaction between pyplot's `set_cmap`, rcParams (`image.cmap`), and the colormap registry where the registered key can differ from `cmap.name`. The code change is likely small (ensuring pyplot persists the user-provided registered name rather than the colormap object's internal name), but it touches a user-facing API and must be validated against the newer `colormaps.register` pathway and existing name-validation behavior. Writing a focused regression test and running the relevant Matplotlib test suite portion adds non-trivial time due to repository conventions and potential backend/rcParam interactions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:53.583044"}
{"instance_id": "matplotlib__matplotlib-25960", "repo": "matplotlib/matplotlib", "estimated_minutes": 300.0, "justification": "Although the bug is easy to reproduce, fixing it likely requires understanding how SubFigure positioning is computed in non-constrained layout and why the passed wspace/hspace kwargs are currently ignored. The implementation will need to adjust Figure/SubFigure layout calculations (likely in figure.py and possibly gridspec interactions) while preserving existing expectations/tests about how subfigures relate to GridSpec spacing. Verification in Matplotlib typically involves adding/updating both behavioral tests and image-comparison baselines, which adds nontrivial iteration time to ensure the spacing works without regressions across layout modes.", "time_breakdown": {"understanding_and_investigation": 120, "implementation": 90, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 300,\n  \"justification\": \"Although the bug is easy to reproduce, fixing it likely requires understanding how SubFigure positioning is computed in non-constrained layout and why the passed wspace/hspace kwargs are currently ignored. The implementation will need to adjust Figure/SubFigure layout calculations (likely in figure.py and possibly gridspec interactions) while preserving existing expectations/tests about how subfigures relate to GridSpec spacing. Verification in Matplotlib typically involves adding/updating both behavioral tests and image-comparison baselines, which adds nontrivial iteration time to ensure the spacing works without regressions across layout modes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 120,\n    \"implementation\": 90,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:54.025953"}
{"instance_id": "matplotlib__matplotlib-25122", "repo": "matplotlib/matplotlib", "estimated_minutes": 150.0, "justification": "Although the code change is likely small (removing or altering an unnecessary `np.abs` in the window correction factor), an engineer will need time to confirm the correct normalization for `mode='psd'` with `scale_by_freq=False` and ensure behavior matches documented definitions and existing expectations. Writing a robust regression test is the main effort because tests should not rely on SciPy being installed, and the test must exercise a window with negative coefficients to catch the bug. Additional time is needed to run the relevant test suite subset and check for unintended changes in other modes (e.g., magnitude/spectrum vs density scaling).", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 20, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the code change is likely small (removing or altering an unnecessary `np.abs` in the window correction factor), an engineer will need time to confirm the correct normalization for `mode='psd'` with `scale_by_freq=False` and ensure behavior matches documented definitions and existing expectations. Writing a robust regression test is the main effort because tests should not rely on SciPy being installed, and the test must exercise a window with negative coefficients to catch the bug. Additional time is needed to run the relevant test suite subset and check for unintended changes in other modes (e.g., magnitude/spectrum vs density scaling).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 20,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:54.251102"}
{"instance_id": "matplotlib__matplotlib-25775", "repo": "matplotlib/matplotlib", "estimated_minutes": 360.0, "justification": "This change requires adding a new per-artist property to Text (and likely Annotation), threading it through the drawing pipeline, and ensuring renderers/backends (notably Agg and Cairo) consume the GraphicsContext antialiasing state instead of directly reading rcParams. While the API surface change (get/set_antialiased) is straightforward, correctly integrating it with existing backend text rendering paths and preserving default behavior (rcParams fallback) requires moderate-to-deep repository and backend knowledge. Verification will likely need a mix of unit tests for property propagation and at least one rendering-level test to ensure the antialiasing flag is honored without regressions.", "time_breakdown": {"understanding_and_investigation": 120, "implementation": 150, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "4-6", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 360,\n  \"justification\": \"This change requires adding a new per-artist property to Text (and likely Annotation), threading it through the drawing pipeline, and ensuring renderers/backends (notably Agg and Cairo) consume the GraphicsContext antialiasing state instead of directly reading rcParams. While the API surface change (get/set_antialiased) is straightforward, correctly integrating it with existing backend text rendering paths and preserving default behavior (rcParams fallback) requires moderate-to-deep repository and backend knowledge. Verification will likely need a mix of unit tests for property propagation and at least one rendering-level test to ensure the antialiasing flag is honored without regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 120,\n    \"implementation\": 150,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:54.797178"}
{"instance_id": "matplotlib__matplotlib-25332", "repo": "matplotlib/matplotlib", "estimated_minutes": 210.0, "justification": "The issue is clearly reproducible, but diagnosing the exact unpicklable object introduced by `Figure.align_labels()` requires tracing through Matplotlib\u2019s label-alignment/grouping internals to find where a `weakref.ReferenceType` enters the figure state. The fix will likely involve adjusting how alignment state is stored on the Figure (e.g., making the alignment helper/group picklable or excluding/reconstructing it during pickling), which needs careful consideration to avoid breaking alignment behavior. A regression test must be added to ensure figures remain pickleable after label alignment and that the change doesn\u2019t introduce serialization regressions elsewhere.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"The issue is clearly reproducible, but diagnosing the exact unpicklable object introduced by `Figure.align_labels()` requires tracing through Matplotlib\u2019s label-alignment/grouping internals to find where a `weakref.ReferenceType` enters the figure state. The fix will likely involve adjusting how alignment state is stored on the Figure (e.g., making the alignment helper/group picklable or excluding/reconstructing it during pickling), which needs careful consideration to avoid breaking alignment behavior. A regression test must be added to ensure figures remain pickleable after label alignment and that the change doesn\u2019t introduce serialization regressions elsewhere.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:56.223092"}
{"instance_id": "psf__requests-1142", "repo": "psf/requests", "estimated_minutes": 180.0, "justification": "Although the behavioral change sounds simple (stop sending Content-Length on body-less GET requests), Requests builds headers during request preparation and may interact with urllib3/http.client behavior, so an engineer will need to trace where Content-Length is injected and under what conditions. The fix likely involves adjusting request preparation logic to only set Content-Length when a body is present (or when explicitly provided), while ensuring compatibility for GET-with-body and other methods. Proper regression tests are needed to verify header emission rules across methods and to ensure no unintended side effects in redirect/auth/retry paths.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the behavioral change sounds simple (stop sending Content-Length on body-less GET requests), Requests builds headers during request preparation and may interact with urllib3/http.client behavior, so an engineer will need to trace where Content-Length is injected and under what conditions. The fix likely involves adjusting request preparation logic to only set Content-Length when a body is present (or when explicitly provided), while ensuring compatibility for GET-with-body and other methods. Proper regression tests are needed to verify header emission rules across methods and to ensure no unintended side effects in redirect/auth/retry paths.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:57.211265"}
{"instance_id": "mwaskom__seaborn-3069", "repo": "mwaskom/seaborn", "estimated_minutes": 330.0, "justification": "This change affects how seaborn\u2019s objects interface (`so.Nominal` and inferred nominal scales) finalizes axis behavior, which requires careful investigation of the scale/plot finalization pipeline and how it interacts with matplotlib\u2019s autoscaling, margins, sticky edges, grid state, and axis inversion. Implementing the +/-0.5 categorical padding reliably (often via sticky edges + zero margins) and ensuring grid/inversion semantics match existing categorical plots is moderately tricky and will likely require iterating against matplotlib behavior across orientations. Proper verification will also require adding/adjusting plot-level tests (potentially image-based) to ensure consistent results and avoid regressions across x/y axes and different themes.", "time_breakdown": {"understanding_and_investigation": 120, "implementation": 130, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 330,\n  \"justification\": \"This change affects how seaborn\u2019s objects interface (`so.Nominal` and inferred nominal scales) finalizes axis behavior, which requires careful investigation of the scale/plot finalization pipeline and how it interacts with matplotlib\u2019s autoscaling, margins, sticky edges, grid state, and axis inversion. Implementing the +/-0.5 categorical padding reliably (often via sticky edges + zero margins) and ensuring grid/inversion semantics match existing categorical plots is moderately tricky and will likely require iterating against matplotlib behavior across orientations. Proper verification will also require adding/adjusting plot-level tests (potentially image-based) to ensure consistent results and avoid regressions across x/y axes and different themes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 120,\n    \"implementation\": 130,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:46:57.264972"}
{"instance_id": "mwaskom__seaborn-3187", "repo": "mwaskom/seaborn", "estimated_minutes": 180.0, "justification": "Although the issue has a clear reproduction, fixing it correctly requires understanding how seaborn constructs legends for numeric semantics and how it reuses Matplotlib formatters (specifically ScalarFormatter) when an offset is active. The change will likely involve adjusting the scale/formatter plumbing so legend labels (and potentially titles) incorporate the offset/multiplicative information without breaking existing formatting across plot types. Writing robust regression tests is non-trivial because the behavior depends on Matplotlib formatter state and rcParams, and must be validated for both the new objects interface and classic functions like scatterplot/relplot.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 60, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the issue has a clear reproduction, fixing it correctly requires understanding how seaborn constructs legends for numeric semantics and how it reuses Matplotlib formatters (specifically ScalarFormatter) when an offset is active. The change will likely involve adjusting the scale/formatter plumbing so legend labels (and potentially titles) incorporate the offset/multiplicative information without breaking existing formatting across plot types. Writing robust regression tests is non-trivial because the behavior depends on Matplotlib formatter state and rcParams, and must be validated for both the new objects interface and classic functions like scatterplot/relplot.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 60,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:57.590992"}
{"instance_id": "matplotlib__matplotlib-26291", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The issue is reproducible and the traceback strongly localizes the failure to the inset locator being called with a `None` renderer during tight-bbox calculations in the inline backend. While the likely code fix is small (ensuring a renderer is obtained from the parent axes/figure when `renderer` is `None`), it requires careful understanding of Matplotlib's tight-bbox/layout pipeline to avoid regressions. Writing a robust regression test (e.g., exercising `savefig(..., bbox_inches='tight')`/tight-bbox behavior with `mpl_toolkits.axes_grid1.inset_locator.inset_axes`) and running the relevant test suites will take significant time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is reproducible and the traceback strongly localizes the failure to the inset locator being called with a `None` renderer during tight-bbox calculations in the inline backend. While the likely code fix is small (ensuring a renderer is obtained from the parent axes/figure when `renderer` is `None`), it requires careful understanding of Matplotlib's tight-bbox/layout pipeline to avoid regressions. Writing a robust regression test (e.g., exercising `savefig(..., bbox_inches='tight')`/tight-bbox behavior with `mpl_toolkits.axes_grid1.inset_locator.inset_axes`) and running the relevant test suites will take significant time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:58.011987"}
{"instance_id": "pallets__flask-5014", "repo": "pallets/flask", "estimated_minutes": 90.0, "justification": "Although the behavior change is conceptually small (validate that a Blueprint name is non-empty), it requires confirming where Blueprint names are used throughout registration, endpoint naming, and error reporting to ensure the new validation doesn\u2019t break legitimate edge cases. The engineer will likely need to locate the Blueprint constructor, check any related validation patterns in Flask, and ensure consistency with existing error types/messages. Adding a regression test and running the relevant test suite (potentially including blueprint registration and routing tests) contributes a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 20, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"Although the behavior change is conceptually small (validate that a Blueprint name is non-empty), it requires confirming where Blueprint names are used throughout registration, endpoint naming, and error reporting to ensure the new validation doesn\u2019t break legitimate edge cases. The engineer will likely need to locate the Blueprint constructor, check any related validation patterns in Flask, and ensure consistency with existing error types/messages. Adding a regression test and running the relevant test suite (potentially including blueprint registration and routing tests) contributes a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 20,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:58.433895"}
{"instance_id": "matplotlib__matplotlib-26113", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "Although the apparent fix is small (aligning the C!=None code path\u2019s threshold check from `len(vals) > mincnt` to `>=`), validating the intended semantics requires careful investigation of the current `Axes.hexbin` binning/reduction flow and how empty bins are handled when `C` is provided. The engineer will need to confirm this change doesn\u2019t break existing expectations around the default `mincnt` behavior (especially when `reduce_C_function` cannot handle empty arrays) and add targeted regression tests that robustly assert which bins are included. Matplotlib\u2019s testing style (often involving collection arrays and/or image-based tests) typically adds nontrivial time for crafting stable assertions and running the relevant test subsets.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 30, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the apparent fix is small (aligning the C!=None code path\u2019s threshold check from `len(vals) > mincnt` to `>=`), validating the intended semantics requires careful investigation of the current `Axes.hexbin` binning/reduction flow and how empty bins are handled when `C` is provided. The engineer will need to confirm this change doesn\u2019t break existing expectations around the default `mincnt` behavior (especially when `reduce_C_function` cannot handle empty arrays) and add targeted regression tests that robustly assert which bins are included. Matplotlib\u2019s testing style (often involving collection arrays and/or image-based tests) typically adds nontrivial time for crafting stable assertions and running the relevant test subsets.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 30,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:58.484369"}
{"instance_id": "psf__requests-6028", "repo": "psf/requests", "estimated_minutes": 210.0, "justification": "Although the regression is well-localized (bisected to a specific commit and function), an engineer still needs to understand how Requests 2.27.0 changed proxy parsing and how urllib3\u2019s parse_url represents auth/netloc to avoid reintroducing scheme/parsing bugs. The fix itself is likely small (reconstruct netloc including auth when prepending schemes), but it must be validated against multiple proxy URL shapes and redirect/proxy handling paths. Writing reliable tests is moderately involved because proxy behavior often requires careful unit-test design to avoid dependence on real proxy services while still asserting correct proxy-Authorization/auth preservation.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the regression is well-localized (bisected to a specific commit and function), an engineer still needs to understand how Requests 2.27.0 changed proxy parsing and how urllib3\u2019s parse_url represents auth/netloc to avoid reintroducing scheme/parsing bugs. The fix itself is likely small (reconstruct netloc including auth when prepending schemes), but it must be validated against multiple proxy URL shapes and redirect/proxy handling paths. Writing reliable tests is moderately involved because proxy behavior often requires careful unit-test design to avoid dependence on real proxy services while still asserting correct proxy-Authorization/auth preservation.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:46:59.707698"}
{"instance_id": "matplotlib__matplotlib-26466", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "Although the symptom suggests a simple fix (copying/converting the user-provided xy input), a developer will need to trace how Annotation/AnnotationBase stores and later uses xy/xytext (including arrow patch positioning) to ensure no other code paths depend on mutability or object identity. The fix should be applied carefully to avoid breaking support for non-ndarray sequences and unit conversions, and it may also require auditing related helpers (e.g., OffsetFrom) for similar reference-retention. Writing a robust regression test is non-trivial because it must demonstrate that mutating the original numpy array no longer changes the rendered/derived positions, ideally without relying on fragile image comparisons.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 35, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the symptom suggests a simple fix (copying/converting the user-provided xy input), a developer will need to trace how Annotation/AnnotationBase stores and later uses xy/xytext (including arrow patch positioning) to ensure no other code paths depend on mutability or object identity. The fix should be applied carefully to avoid breaking support for non-ndarray sequences and unit conversions, and it may also require auditing related helpers (e.g., OffsetFrom) for similar reference-retention. Writing a robust regression test is non-trivial because it must demonstrate that mutating the original numpy array no longer changes the rendered/derived positions, ideally without relying on fragile image comparisons.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 35,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:00.279001"}
{"instance_id": "psf__requests-1724", "repo": "psf/requests", "estimated_minutes": 150.0, "justification": "Although the repro is clear, an engineer will need to trace where the request method is normalized and how it propagates into urllib3/httplib on Python 2, ensuring the fix doesn\u2019t introduce encoding regressions elsewhere. The likely fix is small (coercing/normalizing the method to a native byte string on Py2 before calling `.upper()` and before handing off to urllib3), but Requests has multiple preparation layers that require careful placement. Writing a reliable regression test for Python 2 unicode behavior (without depending on real network conditions) adds non-trivial time for test harness setup and verification across supported environments.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the repro is clear, an engineer will need to trace where the request method is normalized and how it propagates into urllib3/httplib on Python 2, ensuring the fix doesn\u2019t introduce encoding regressions elsewhere. The likely fix is small (coercing/normalizing the method to a native byte string on Py2 before calling `.upper()` and before handing off to urllib3), but Requests has multiple preparation layers that require careful placement. Writing a reliable regression test for Python 2 unicode behavior (without depending on real network conditions) adds non-trivial time for test harness setup and verification across supported environments.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:00.955290"}
{"instance_id": "psf__requests-2931", "repo": "psf/requests", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible but requires tracing a regression introduced between 2.8.1 and 2.9 where request body handling incorrectly passes binary payloads through `to_native_string`, likely causing an unintended decode/encode step. Fixing it should be a small-to-moderate change in request preparation/encoding logic, but it requires careful review to avoid breaking other data/JSON/form cases. Adding a regression test to ensure `bytes` payloads remain bytes and running the full test suite to confirm no encoding-related regressions will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible but requires tracing a regression introduced between 2.8.1 and 2.9 where request body handling incorrectly passes binary payloads through `to_native_string`, likely causing an unintended decode/encode step. Fixing it should be a small-to-moderate change in request preparation/encoding logic, but it requires careful review to avoid breaking other data/JSON/form cases. Adding a regression test to ensure `bytes` payloads remain bytes and running the full test suite to confirm no encoding-related regressions will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:01.137166"}
{"instance_id": "matplotlib__matplotlib-25311", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The failure is reproducible and likely caused by the draggable helper (e.g., DraggableLegend/DraggableAnnotation) holding a strong reference to the figure canvas, which defeats Figure's normal pickle-sanitization and causes the backend canvas (e.g., FigureCanvasQTAgg) to be pickled. Fixing this cleanly requires investigating Matplotlib's draggable infrastructure, adjusting object state serialization (e.g., dropping canvas/callback IDs or using weak references), and ensuring behavior remains correct after unpickling. Adding regression tests for pickling figures with draggable legends/annotations and validating no backend-specific regressions adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 50, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The failure is reproducible and likely caused by the draggable helper (e.g., DraggableLegend/DraggableAnnotation) holding a strong reference to the figure canvas, which defeats Figure's normal pickle-sanitization and causes the backend canvas (e.g., FigureCanvasQTAgg) to be pickled. Fixing this cleanly requires investigating Matplotlib's draggable infrastructure, adjusting object state serialization (e.g., dropping canvas/callback IDs or using weak references), and ensuring behavior remains correct after unpickling. Adding regression tests for pickling figures with draggable legends/annotations and validating no backend-specific regressions adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 50,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:02.793903"}
{"instance_id": "pydata__xarray-3095", "repo": "pydata/xarray", "estimated_minutes": 150.0, "justification": "The issue is a clear regression with a minimal reproducer, but it likely involves subtle interactions between xarray's IndexVariable/coordinate handling and pandas/numpy copy semantics that can silently change dtypes (unicode -> object). An engineer will need to trace the behavior change introduced by the referenced commit, identify where deep copying of index-like arrays occurs, and adjust the copy pathway to preserve the original dtype without breaking pandas-index compatibility. Proper coverage requires targeted regression tests for Dataset.copy(deep=True), DataArray.copy(deep=True), and Python's copy.copy/copy.deepcopy on objects containing unicode coordinate indexes.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 45, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is a clear regression with a minimal reproducer, but it likely involves subtle interactions between xarray's IndexVariable/coordinate handling and pandas/numpy copy semantics that can silently change dtypes (unicode -> object). An engineer will need to trace the behavior change introduced by the referenced commit, identify where deep copying of index-like arrays occurs, and adjust the copy pathway to preserve the original dtype without breaking pandas-index compatibility. Proper coverage requires targeted regression tests for Dataset.copy(deep=True), DataArray.copy(deep=True), and Python's copy.copy/copy.deepcopy on objects containing unicode coordinate indexes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 45,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:02.997678"}
{"instance_id": "pydata__xarray-3151", "repo": "pydata/xarray", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible, but fixing it requires understanding the internal logic of `combine_by_coords`, particularly how it determines which coordinate dimensions are \"varying\" and when it enforces monotonic global indexes. The fix is likely localized (adjusting the monotonicity validation to skip dimensions whose coordinate values are identical across inputs), but it must be done carefully to avoid breaking legitimate error cases for truly varying, non-monotonic coordinates. New regression tests are needed to cover identical non-monotonic coordinates as well as a couple of adjacent edge cases to ensure behavior matches the documented contract.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible, but fixing it requires understanding the internal logic of `combine_by_coords`, particularly how it determines which coordinate dimensions are \\\"varying\\\" and when it enforces monotonic global indexes. The fix is likely localized (adjusting the monotonicity validation to skip dimensions whose coordinate values are identical across inputs), but it must be done carefully to avoid breaking legitimate error cases for truly varying, non-monotonic coordinates. New regression tests are needed to cover identical non-monotonic coordinates as well as a couple of adjacent edge cases to ensure behavior matches the documented contract.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:03.230330"}
{"instance_id": "matplotlib__matplotlib-24177", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "Although the bug has a clear reproduction and a strong hint pointing to path simplification/segment iteration affecting data limits, an engineer will still need to trace where Axes.hist constructs the step Polygon and how autoscaling computes limits from its Path. The fix is likely localized (e.g., ensuring limit calculations use unsimplified vertices or disable simplification during datalim computation), but it must be done carefully to avoid performance regressions and to preserve behavior for other patch/collection types. Writing a robust regression test for autoscaling (and ensuring it is deterministic across platforms/rcParams) adds additional time.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the bug has a clear reproduction and a strong hint pointing to path simplification/segment iteration affecting data limits, an engineer will still need to trace where Axes.hist constructs the step Polygon and how autoscaling computes limits from its Path. The fix is likely localized (e.g., ensuring limit calculations use unsimplified vertices or disable simplification during datalim computation), but it must be done carefully to avoid performance regressions and to preserve behavior for other patch/collection types. Writing a robust regression test for autoscaling (and ensuring it is deterministic across platforms/rcParams) adds additional time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:03.606141"}
{"instance_id": "psf__requests-1921", "repo": "psf/requests", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible but requires understanding how Requests merges session-level default headers with per-request headers during request preparation. The fix is likely localized to the header-merge logic (e.g., in session/request preparation) to ensure headers with value None are treated as \"unset\" rather than serialized to the string \"None\". Time is mainly driven by confirming the correct semantics across session headers vs per-request overrides and adding regression tests to avoid breaking existing header-merging behavior.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible but requires understanding how Requests merges session-level default headers with per-request headers during request preparation. The fix is likely localized to the header-merge logic (e.g., in session/request preparation) to ensure headers with value None are treated as \\\"unset\\\" rather than serialized to the string \\\"None\\\". Time is mainly driven by confirming the correct semantics across session headers vs per-request overrides and adding regression tests to avoid breaking existing header-merging behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:03.654981"}
{"instance_id": "matplotlib__matplotlib-26342", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "Adding a public \"set_paths\" API for ContourSet sounds small, but it requires understanding why Collection.set_paths is intentionally unimplemented and ensuring the new method is safe for ContourSet\u2019s internal representation of paths. The change will likely involve adding an override on ContourSet (or a narrowly-scoped implementation on the specific contour collection class) plus ensuring invalidation/staleness behavior matches Matplotlib conventions. Writing a regression test is non-trivial because it should confirm not just that get_paths returns the updated list, but that downstream consumers (notably clabel/label placement) actually use the replaced paths without breaking rendering.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Adding a public \\\"set_paths\\\" API for ContourSet sounds small, but it requires understanding why Collection.set_paths is intentionally unimplemented and ensuring the new method is safe for ContourSet\u2019s internal representation of paths. The change will likely involve adding an override on ContourSet (or a narrowly-scoped implementation on the specific contour collection class) plus ensuring invalidation/staleness behavior matches Matplotlib conventions. Writing a regression test is non-trivial because it should confirm not just that get_paths returns the updated list, but that downstream consumers (notably clabel/label placement) actually use the replaced paths without breaking rendering.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:03.763736"}
{"instance_id": "pydata__xarray-2905", "repo": "pydata/xarray", "estimated_minutes": 150.0, "justification": "The issue has a clear reproducer and points directly to a problematic coercion path that unwraps any object with a `.values` attribute, so the likely fix is to narrow that logic to explicit supported types (e.g., pandas objects and/or xarray wrappers). Even though the code change may be small, the engineer will need time to trace all call sites of the coercion helper to avoid regressions with xarray\u2019s internal array-like classes and to ensure no unintended nesting behavior changes. Proper coverage requires adding focused regression tests for both scalar construction and non-broadcasted indexed assignment on object dtype arrays, then running the relevant test suite subsets.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 40, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue has a clear reproducer and points directly to a problematic coercion path that unwraps any object with a `.values` attribute, so the likely fix is to narrow that logic to explicit supported types (e.g., pandas objects and/or xarray wrappers). Even though the code change may be small, the engineer will need time to trace all call sites of the coercion helper to avoid regressions with xarray\u2019s internal array-like classes and to ensure no unintended nesting behavior changes. Proper coverage requires adding focused regression tests for both scalar construction and non-broadcasted indexed assignment on object dtype arrays, then running the relevant test suite subsets.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 40,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:03.915561"}
{"instance_id": "psf__requests-5414", "repo": "psf/requests", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and likely originates from Requests' URL preparation path where hostnames are IDNA-encoded; an uncaught UnicodeError from the idna codec should be translated into Requests' InvalidURL for consistency. An experienced engineer will need some time to trace the exact call path (requests.models / urllib3 integration) and ensure the exception mapping matches existing behavior and messages. The code change itself is small (catch/re-raise), but adding a regression test and running the full suite across URL parsing edge cases adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and likely originates from Requests' URL preparation path where hostnames are IDNA-encoded; an uncaught UnicodeError from the idna codec should be translated into Requests' InvalidURL for consistency. An experienced engineer will need some time to trace the exact call path (requests.models / urllib3 integration) and ensure the exception mapping matches existing behavior and messages. The code change itself is small (catch/re-raise), but adding a regression test and running the full suite across URL parsing edge cases adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:04.011413"}
{"instance_id": "pydata__xarray-3305", "repo": "pydata/xarray", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and points to a likely gap in how `keep_attrs` is propagated through `DataArray.quantile` (and potentially into `Variable.quantile`). Fixing it will require tracing the call chain (DataArray -> temporary Dataset/Variable) and aligning behavior with xarray\u2019s established `keep_attrs` conventions for reductions. The change is small-to-moderate in code size but needs careful testing to ensure attribute behavior is correct across `keep_attrs=True/False` and does not regress other quantile/reduction paths.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and points to a likely gap in how `keep_attrs` is propagated through `DataArray.quantile` (and potentially into `Variable.quantile`). Fixing it will require tracing the call chain (DataArray -> temporary Dataset/Variable) and aligning behavior with xarray\u2019s established `keep_attrs` conventions for reductions. The change is small-to-moderate in code size but needs careful testing to ensure attribute behavior is correct across `keep_attrs=True/False` and does not regress other quantile/reduction paths.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:04.504082"}
{"instance_id": "pydata__xarray-4356", "repo": "pydata/xarray", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and likely localized to the min_count handling in xarray's nanops reduction logic when `axis` is a tuple (multiple dimensions), but confirming the exact call path and expected semantics across backends (NumPy vs. dask, skipna behavior) will take some investigation. The actual code change is probably small (fixing valid-count computation for multi-axis reductions), yet it requires careful handling of broadcasting and axis normalization. A meaningful portion of time will go to adding/adjusting tests to cover multi-dimension reductions, edge cases (all-NaN, min_count > size), and ensuring no regressions in existing reduction behavior.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and likely localized to the min_count handling in xarray's nanops reduction logic when `axis` is a tuple (multiple dimensions), but confirming the exact call path and expected semantics across backends (NumPy vs. dask, skipna behavior) will take some investigation. The actual code change is probably small (fixing valid-count computation for multi-axis reductions), yet it requires careful handling of broadcasting and axis normalization. A meaningful portion of time will go to adding/adjusting tests to cover multi-dimension reductions, edge cases (all-NaN, min_count > size), and ensuring no regressions in existing reduction behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:06.131591"}
{"instance_id": "pydata__xarray-3677", "repo": "pydata/xarray", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and the traceback points to a specific assumption in the Dataset.merge method path: merge internals iterate over `.items()` which a DataArray does not provide. The likely fix is to normalize/convert DataArray inputs (e.g., to a Dataset) in the Dataset.merge codepath to match the behavior of the top-level `xarray.merge()`. Although the code change is probably small, validating compatibility semantics and adding targeted regression tests (including edge cases like unnamed DataArrays) will take meaningful time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and the traceback points to a specific assumption in the Dataset.merge method path: merge internals iterate over `.items()` which a DataArray does not provide. The likely fix is to normalize/convert DataArray inputs (e.g., to a Dataset) in the Dataset.merge codepath to match the behavior of the top-level `xarray.merge()`. Although the code change is probably small, validating compatibility semantics and adding targeted regression tests (including edge cases like unnamed DataArrays) will take meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:06.262027"}
{"instance_id": "pydata__xarray-3993", "repo": "pydata/xarray", "estimated_minutes": 180.0, "justification": "This change requires investigating how DataArray.integrate is currently implemented and why it differs from Dataset.integrate/differentiate, then updating the public API while preserving backward compatibility. Because xarray is a mature library, the engineer will likely need to implement a deprecation path (support both arguments, emit warnings, update docs) and ensure behavior is unchanged across common and edge cases. Adding/adjusting tests and running the relevant test suite to avoid regressions will take a non-trivial amount of time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This change requires investigating how DataArray.integrate is currently implemented and why it differs from Dataset.integrate/differentiate, then updating the public API while preserving backward compatibility. Because xarray is a mature library, the engineer will likely need to implement a deprecation path (support both arguments, emit warnings, update docs) and ensure behavior is unchanged across common and edge cases. Adding/adjusting tests and running the relevant test suite to avoid regressions will take a non-trivial amount of time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:06.439917"}
{"instance_id": "pydata__xarray-4629", "repo": "pydata/xarray", "estimated_minutes": 90.0, "justification": "The issue is clearly reproducible and points to a specific line in the merge attribute-combining logic, so investigation is fairly contained. However, because this affects dataset/variable metadata semantics, an engineer will likely spend time confirming expected behavior across different `combine_attrs` modes and ensuring no unintended copying/regression elsewhere. Adding a focused regression test and running the relevant test suite portion will take a non-trivial share of the time.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 15, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clearly reproducible and points to a specific line in the merge attribute-combining logic, so investigation is fairly contained. However, because this affects dataset/variable metadata semantics, an engineer will likely spend time confirming expected behavior across different `combine_attrs` modes and ensuring no unintended copying/regression elsewhere. Adding a focused regression test and running the relevant test suite portion will take a non-trivial share of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 15,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:06.833598"}
{"instance_id": "pydata__xarray-4094", "repo": "pydata/xarray", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible with a small example, but fixing it likely requires understanding how `to_stacked_array` encodes the stacked dimension/coordinate and how `to_unstacked_dataset` reconstructs and merges per-variable pieces. The observed `MergeError` suggests a subtle conflict in coordinate/variable handling during unstacking (e.g., the stacked coordinate `y` being reintroduced inconsistently across variables), which typically takes moderate time to trace through xarray\u2019s stacking/unstacking internals. A correct fix should include a regression test covering single-dimension variables and verification that existing multi-dim roundtrips remain unaffected.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible with a small example, but fixing it likely requires understanding how `to_stacked_array` encodes the stacked dimension/coordinate and how `to_unstacked_dataset` reconstructs and merges per-variable pieces. The observed `MergeError` suggests a subtle conflict in coordinate/variable handling during unstacking (e.g., the stacked coordinate `y` being reintroduced inconsistently across variables), which typically takes moderate time to trace through xarray\u2019s stacking/unstacking internals. A correct fix should include a regression test covering single-dimension variables and verification that existing multi-dim roundtrips remain unaffected.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:06.999729"}
{"instance_id": "pydata__xarray-4075", "repo": "pydata/xarray", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and points to a likely root cause (boolean dtype causing `xr.dot` to behave like a logical reduction when computing `sum_of_weights`). An engineer will still need moderate investigation to find the exact code path in xarray\u2019s weighted reduction implementation and ensure the fix works consistently across NumPy/Dask-backed arrays and preserves existing dtype/NaN handling semantics. The implementation is likely a small targeted change (casting weights or the dot operands to an integer/float), but adding regression tests and running the relevant test suite will take a meaningful portion of time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and points to a likely root cause (boolean dtype causing `xr.dot` to behave like a logical reduction when computing `sum_of_weights`). An engineer will still need moderate investigation to find the exact code path in xarray\u2019s weighted reduction implementation and ensure the fix works consistently across NumPy/Dask-backed arrays and preserves existing dtype/NaN handling semantics. The implementation is likely a small targeted change (casting weights or the dot operands to an integer/float), but adding regression tests and running the relevant test suite will take a meaningful portion of time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:07.110494"}
{"instance_id": "matplotlib__matplotlib-24026", "repo": "matplotlib/matplotlib", "estimated_minutes": 180.0, "justification": "The bug is well-reproduced and likely localized to matplotlib/stackplot.py where stackplot currently calls Axes.set_prop_cycle(color=colors), which both mutates the Axes cycler and rejects 'C{n}' cycle references. The fix will require refactoring stackplot to choose colors without calling set_prop_cycle (e.g., using the provided colors directly, resolving/handling cycle references, and/or using a local cycler) while preserving expected color advancement semantics. Adding regression tests is moderately involved because it should verify both that 'C{n}' is accepted and that the Axes property cycle after stackplot is not overwritten, and then run the relevant test suite to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 60, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The bug is well-reproduced and likely localized to matplotlib/stackplot.py where stackplot currently calls Axes.set_prop_cycle(color=colors), which both mutates the Axes cycler and rejects 'C{n}' cycle references. The fix will require refactoring stackplot to choose colors without calling set_prop_cycle (e.g., using the provided colors directly, resolving/handling cycle references, and/or using a local cycler) while preserving expected color advancement semantics. Adding regression tests is moderately involved because it should verify both that 'C{n}' is accepted and that the Axes property cycle after stackplot is not overwritten, and then run the relevant test suite to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 60,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:08.965496"}
{"instance_id": "psf__requests-2317", "repo": "psf/requests", "estimated_minutes": 90.0, "justification": "The issue is well-scoped and points directly to a specific line in `requests/sessions.py`, with a clear suggested fix (use `to_native_str` instead of `builtin_str`) to properly handle `bytes` HTTP methods under Python 3. An experienced engineer will still need time to confirm the exact code path where the method is normalized, verify the behavior across supported Python versions, and ensure no regression for normal `str` inputs. Writing a focused unit test (e.g., asserting a prepared request created with `method=b'GET'` results in `method == 'GET'`) and running the full test suite should be straightforward but non-trivial given repository conventions and CI expectations.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 15, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is well-scoped and points directly to a specific line in `requests/sessions.py`, with a clear suggested fix (use `to_native_str` instead of `builtin_str`) to properly handle `bytes` HTTP methods under Python 3. An experienced engineer will still need time to confirm the exact code path where the method is normalized, verify the behavior across supported Python versions, and ensure no regression for normal `str` inputs. Writing a focused unit test (e.g., asserting a prepared request created with `method=b'GET'` results in `method == 'GET'`) and running the full test suite should be straightforward but non-trivial given repository conventions and CI expectations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 15,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:10.182766"}
{"instance_id": "pydata__xarray-7393", "repo": "pydata/xarray", "estimated_minutes": 120.0, "justification": "The issue is well-scoped with a clear MVCE and an explicit pointer to the buggy method in xarray/core/indexing.py, which reduces investigation time. However, the fix involves subtle interactions between xarray\u2019s array wrappers and pandas Index/MultiIndex behavior, so the engineer will need to confirm dtype restoration semantics and avoid breaking other index-backed array conversions. Adding targeted regression tests (including MultiIndex level handling and dtype overrides) and running the relevant test suite will likely dominate the effort.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 25, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped with a clear MVCE and an explicit pointer to the buggy method in xarray/core/indexing.py, which reduces investigation time. However, the fix involves subtle interactions between xarray\u2019s array wrappers and pandas Index/MultiIndex behavior, so the engineer will need to confirm dtype restoration semantics and avoid breaking other index-backed array conversions. Adding targeted regression tests (including MultiIndex level handling and dtype overrides) and running the relevant test suite will likely dominate the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 25,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:10.857905"}
{"instance_id": "pydata__xarray-4695", "repo": "pydata/xarray", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and the traceback points directly to an argument-name collision between a dimension named \"method\" and the DataArray/Dataset.sel() keyword parameter \"method\". While the code change is likely small (switching from **kwargs to passing an indexers dict), the engineer will need to confirm the correct calling convention across DataArray/Dataset, ensure no regressions for existing .loc behavior, and add targeted tests for reserved-name dimensions. Writing and running the indexing test suite (and validating behavior for both DataArray and Dataset) will likely dominate the effort.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 20, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and the traceback points directly to an argument-name collision between a dimension named \\\"method\\\" and the DataArray/Dataset.sel() keyword parameter \\\"method\\\". While the code change is likely small (switching from **kwargs to passing an indexers dict), the engineer will need to confirm the correct calling convention across DataArray/Dataset, ensure no regressions for existing .loc behavior, and add targeted tests for reserved-name dimensions. Writing and running the indexing test suite (and validating behavior for both DataArray and Dataset) will likely dominate the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 20,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:10.949189"}
{"instance_id": "pydata__xarray-6599", "repo": "pydata/xarray", "estimated_minutes": 210.0, "justification": "Reproducing the regression is straightforward from the MVCE, but identifying why the newer `polyval` path mishandles `timedelta64` requires reading the updated implementation and its numeric-coercion helpers. The fix will likely involve adjusting `_ensure_numeric`/`to_floatable` (and/or `datetime_to_numeric`) to correctly convert `timedelta64` coordinates to a stable numeric representation (e.g., in nanoseconds) without triggering dtype/broadcasting errors. Proper coverage will require new regression tests for `timedelta64` coordinates (and potentially a couple of related edge cases like DataArray vs ndarray inputs), plus running the relevant test suite subset to ensure no datetime handling regressions.", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 55, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Reproducing the regression is straightforward from the MVCE, but identifying why the newer `polyval` path mishandles `timedelta64` requires reading the updated implementation and its numeric-coercion helpers. The fix will likely involve adjusting `_ensure_numeric`/`to_floatable` (and/or `datetime_to_numeric`) to correctly convert `timedelta64` coordinates to a stable numeric representation (e.g., in nanoseconds) without triggering dtype/broadcasting errors. Proper coverage will require new regression tests for `timedelta64` coordinates (and potentially a couple of related edge cases like DataArray vs ndarray inputs), plus running the relevant test suite subset to ensure no datetime handling regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 55,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:10.988214"}
{"instance_id": "pydata__xarray-4687", "repo": "pydata/xarray", "estimated_minutes": 240.0, "justification": "Fixing this requires tracing how the top-level `xr.where` is implemented (likely via `apply_ufunc`) and how attribute propagation is currently controlled in xarray (global `OPTIONS[\"keep_attrs\"]`, `DataArray.where`, and binary op behavior like `__eq__`). The main change is small (threading `keep_attrs` through the `xr.where` code path), but deciding the default behavior to avoid a breaking change and matching existing conventions will take investigation. Solid coverage needs new/updated tests for DataArray/Dataset inputs and for both default and `keep_attrs`-enabled behavior, plus running the relevant test suite to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Fixing this requires tracing how the top-level `xr.where` is implemented (likely via `apply_ufunc`) and how attribute propagation is currently controlled in xarray (global `OPTIONS[\\\"keep_attrs\\\"]`, `DataArray.where`, and binary op behavior like `__eq__`). The main change is small (threading `keep_attrs` through the `xr.where` code path), but deciding the default behavior to avoid a breaking change and matching existing conventions will take investigation. Solid coverage needs new/updated tests for DataArray/Dataset inputs and for both default and `keep_attrs`-enabled behavior, plus running the relevant test suite to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:11.357206"}
{"instance_id": "pydata__xarray-7229", "repo": "pydata/xarray", "estimated_minutes": 210.0, "justification": "Although the MVCE is clear, the root cause sits in xarray\u2019s attribute/coord propagation logic for `where` (and likely shared machinery such as `apply_ufunc`/merge behavior), which typically requires careful tracing to avoid regressions. Fixing it is not just a one-line revert: the implementation must correctly distinguish variable attrs vs coordinate attrs across Dataset/DataArray paths and scalar/broadcast cases. Additional time is needed to add targeted regression tests covering coordinate attributes and to run/validate the broader test suite to ensure no unintended behavioral changes.", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 55, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the MVCE is clear, the root cause sits in xarray\u2019s attribute/coord propagation logic for `where` (and likely shared machinery such as `apply_ufunc`/merge behavior), which typically requires careful tracing to avoid regressions. Fixing it is not just a one-line revert: the implementation must correctly distinguish variable attrs vs coordinate attrs across Dataset/DataArray paths and scalar/broadcast cases. Additional time is needed to add targeted regression tests covering coordinate attributes and to run/validate the broader test suite to ensure no unintended behavioral changes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 55,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:11.493379"}
{"instance_id": "pydata__xarray-6992", "repo": "pydata/xarray", "estimated_minutes": 180.0, "justification": "The issue has a clear reproducer and a likely cause (DataVariables using an invalid assumption that coord names are a subset of variables, leading to negative lengths and repr failures), but it still requires digging into the post-index-refactor invariants around Dataset internals. The fix will likely involve adjusting DataVariables (and possibly related Dataset methods) to compute data-variable membership via set/key checks rather than arithmetic on counts, and ensuring no other call sites rely on the old invariant. Writing targeted regression tests for the specific set_index/reset_index behavior and running the relevant test suite to avoid regressions will take a substantial portion of the time.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue has a clear reproducer and a likely cause (DataVariables using an invalid assumption that coord names are a subset of variables, leading to negative lengths and repr failures), but it still requires digging into the post-index-refactor invariants around Dataset internals. The fix will likely involve adjusting DataVariables (and possibly related Dataset methods) to compute data-variable membership via set/key checks rather than arithmetic on counts, and ensuring no other call sites rely on the old invariant. Writing targeted regression tests for the specific set_index/reset_index behavior and running the relevant test suite to avoid regressions will take a substantial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": ">4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:11.995432"}
{"instance_id": "pydata__xarray-6744", "repo": "pydata/xarray", "estimated_minutes": 180.0, "justification": "Reproducing the discrepancy is straightforward, but fixing it likely requires understanding how xarray\u2019s rolling machinery implements centering (typically via shifting/label alignment) versus how the Rolling iterator currently slices windows. Aligning manual iteration semantics with the existing centered rolling reduction behavior must be done carefully to avoid changing labels/window edges incorrectly across odd/even window sizes and min_periods. Adding focused regression tests for iteration behavior (and ensuring no regressions for non-centered iteration) will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 55, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Reproducing the discrepancy is straightforward, but fixing it likely requires understanding how xarray\u2019s rolling machinery implements centering (typically via shifting/label alignment) versus how the Rolling iterator currently slices windows. Aligning manual iteration semantics with the existing centered rolling reduction behavior must be done carefully to avoid changing labels/window edges incorrectly across odd/even window sizes and min_periods. Adding focused regression tests for iteration behavior (and ensuring no regressions for non-centered iteration) will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 55,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:12.409536"}
{"instance_id": "psf__requests-1766", "repo": "psf/requests", "estimated_minutes": 135.0, "justification": "This change is likely centered in Requests' Digest authentication header construction/parsing logic (typically in the auth module), but it requires careful RFC2617/RFC2069 interpretation to ensure quoting changes don\u2019t break interoperability. An experienced engineer will need time to locate where `qop`/`qop-options` is parsed and where the Authorization header is assembled, then adjust formatting while preserving backward-compatible behavior. Tests should be added/updated to validate the exact header output (including quoting) and to ensure existing digest flows remain correct, which usually takes longer than the code change itself.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 135,\n  \"justification\": \"This change is likely centered in Requests' Digest authentication header construction/parsing logic (typically in the auth module), but it requires careful RFC2617/RFC2069 interpretation to ensure quoting changes don\u2019t break interoperability. An experienced engineer will need time to locate where `qop`/`qop-options` is parsed and where the Authorization header is assembled, then adjust formatting while preserving backward-compatible behavior. Tests should be added/updated to validate the exact header output (including quoting) and to ensure existing digest flows remain correct, which usually takes longer than the code change itself.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:12.753002"}
{"instance_id": "pylint-dev__pylint-4551", "repo": "pylint-dev/pylint", "estimated_minutes": 330.0, "justification": "Supporting PEP 484-style type hints in pyreverse likely requires tracing parameter annotations through assignments (e.g., `self.a = a`) and integrating that information into the existing attribute/type inference pipeline, which currently falls back to runtime defaults like `None`. The engineer will need to understand how pyreverse builds class models from astroid nodes, where attribute types are inferred/stored, and how UML labels are rendered. Implementing this cleanly also requires handling edge cases (missing annotations, forward refs/strings, `Optional[...]` patterns, imports/qualified names) and adding/adjusting functional tests to prevent regressions in UML output.", "time_breakdown": {"understanding_and_investigation": 100, "implementation": 150, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 330,\n  \"justification\": \"Supporting PEP 484-style type hints in pyreverse likely requires tracing parameter annotations through assignments (e.g., `self.a = a`) and integrating that information into the existing attribute/type inference pipeline, which currently falls back to runtime defaults like `None`. The engineer will need to understand how pyreverse builds class models from astroid nodes, where attribute types are inferred/stored, and how UML labels are rendered. Implementing this cleanly also requires handling edge cases (missing annotations, forward refs/strings, `Optional[...]` patterns, imports/qualified names) and adding/adjusting functional tests to prevent regressions in UML output.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 100,\n    \"implementation\": 150,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:13.075450"}
{"instance_id": "pylint-dev__pylint-4970", "repo": "pylint-dev/pylint", "estimated_minutes": 150.0, "justification": "Although the desired behavior is clear, an engineer will need to locate where the duplicate-code (R0801) similarity threshold is interpreted and confirm how configuration values flow into the duplicate-code checker. The implementation is likely a small conditional (treating 0 as \u201cdisabled\u201d), but it must be applied in the correct place to avoid unintended side effects (e.g., still allowing explicit enabling/disabling via message control). Writing or adjusting functional tests to assert that setting `min-similarity-lines=0` produces no R0801 findings while non-zero values still work will take a meaningful portion of the time, along with running the test suite and verifying no regressions.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 35, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the desired behavior is clear, an engineer will need to locate where the duplicate-code (R0801) similarity threshold is interpreted and confirm how configuration values flow into the duplicate-code checker. The implementation is likely a small conditional (treating 0 as \u201cdisabled\u201d), but it must be applied in the correct place to avoid unintended side effects (e.g., still allowing explicit enabling/disabling via message control). Writing or adjusting functional tests to assert that setting `min-similarity-lines=0` produces no R0801 findings while non-zero values still work will take a meaningful portion of the time, along with running the test suite and verifying no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 35,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:13.220727"}
{"instance_id": "pydata__xarray-6461", "repo": "pydata/xarray", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and points directly at the failing line in the `xr.where` implementation, but it still requires understanding how `apply_ufunc` assembles and passes attribute contexts when some inputs are Python scalars. The fix is likely a small change (making `keep_attrs` robust when the second argument has no attrs), but it must be done carefully to preserve existing behavior for DataArray/Dataset inputs. Writing targeted regression tests for scalar-vs-array combinations and running the relevant xarray test suite will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 30, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and points directly at the failing line in the `xr.where` implementation, but it still requires understanding how `apply_ufunc` assembles and passes attribute contexts when some inputs are Python scalars. The fix is likely a small change (making `keep_attrs` robust when the second argument has no attrs), but it must be done carefully to preserve existing behavior for DataArray/Dataset inputs. Writing targeted regression tests for scalar-vs-array combinations and running the relevant xarray test suite will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 30,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:13.821823"}
{"instance_id": "pylint-dev__pylint-4661", "repo": "pylint-dev/pylint", "estimated_minutes": 210.0, "justification": "Changing pylint\u2019s persistent data directory to be XDG Base Directory compliant requires locating and understanding where the default PYLINTHOME value is computed, how it interacts with CLI/config loading, and how/where stats files are written. The implementation likely needs a small abstraction for \u201cuser data dir\u201d that is cross-platform (Linux/macOS/Windows) and must preserve backwards compatibility (e.g., honoring an existing ~/.pylint.d or current behavior when explicitly set). Verifying correctness requires adding/updating tests around path resolution and ensuring no regressions in stats persistence, environment-variable overrides, and filesystem interactions across platforms.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 80, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "4-6", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Changing pylint\u2019s persistent data directory to be XDG Base Directory compliant requires locating and understanding where the default PYLINTHOME value is computed, how it interacts with CLI/config loading, and how/where stats files are written. The implementation likely needs a small abstraction for \u201cuser data dir\u201d that is cross-platform (Linux/macOS/Windows) and must preserve backwards compatibility (e.g., honoring an existing ~/.pylint.d or current behavior when explicitly set). Verifying correctness requires adding/updating tests around path resolution and ensuring no regressions in stats persistence, environment-variable overrides, and filesystem interactions across platforms.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 80,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:13.958188"}
{"instance_id": "pydata__xarray-6938", "repo": "pydata/xarray", "estimated_minutes": 180.0, "justification": "The issue is reproducible but involves a subtle mutability/aliasing bug where internal objects (likely Variables/IndexVariables or coordinate containers) are being reused and then mutated during `.swap_dims()`. An engineer will need to trace how `swap_dims` constructs the new Dataset and whether it performs shallow copies of variables/coords that later get their `.dims` reassigned. The fix is likely localized but must be done carefully to avoid performance regressions and to ensure no other dimension/coordinate transformation paths share the same mutability problem, requiring targeted regression tests and a broader test run.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is reproducible but involves a subtle mutability/aliasing bug where internal objects (likely Variables/IndexVariables or coordinate containers) are being reused and then mutated during `.swap_dims()`. An engineer will need to trace how `swap_dims` constructs the new Dataset and whether it performs shallow copies of variables/coords that later get their `.dims` reassigned. The fix is likely localized but must be done carefully to avoid performance regressions and to ensure no other dimension/coordinate transformation paths share the same mutability problem, requiring targeted regression tests and a broader test run.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:14.518653"}
{"instance_id": "pylint-dev__pylint-6903", "repo": "pylint-dev/pylint", "estimated_minutes": 150.0, "justification": "The issue is well-scoped to pylint.lint.run._query_cpu(), but the fix needs careful handling of multiple cgroup-based heuristics (quota/period vs shares) to ensure the result is never 0 while preserving existing behavior. An experienced engineer will spend time reproducing or simulating the Kubernetes/cgroup inputs, implementing a safe minimum of 1 for computed CPU counts, and ensuring the multiprocessing integration no longer crashes. Adding robust tests will take a meaningful portion of the time because it requires mocking filesystem reads and covering edge cases (e.g., quota=-1, very low shares).", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped to pylint.lint.run._query_cpu(), but the fix needs careful handling of multiple cgroup-based heuristics (quota/period vs shares) to ensure the result is never 0 while preserving existing behavior. An experienced engineer will spend time reproducing or simulating the Kubernetes/cgroup inputs, implementing a safe minimum of 1 for computed CPU counts, and ensuring the multiprocessing integration no longer crashes. Adding robust tests will take a meaningful portion of the time because it requires mocking filesystem reads and covering edge cases (e.g., quota=-1, very low shares).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:17.264222"}
{"instance_id": "pylint-dev__pylint-7080", "repo": "pylint-dev/pylint", "estimated_minutes": 150.0, "justification": "The bug is reasonably well-scoped (ignore-paths regex failing to match when recursive roots include a './' prefix), but confirming the exact path-normalization flow in Pylint\u2019s recursive file discovery and ignore filtering requires some targeted code reading and reproduction. The actual fix is likely small (normalize candidate paths before applying ignore-paths), yet it must be done carefully to avoid altering semantics across platforms and path formats. Adding regression tests for recursive traversal with different CLI roots (e.g., '.' vs 'src/') and ensuring they pass on Windows and POSIX accounts for a significant portion of the work.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The bug is reasonably well-scoped (ignore-paths regex failing to match when recursive roots include a './' prefix), but confirming the exact path-normalization flow in Pylint\u2019s recursive file discovery and ignore filtering requires some targeted code reading and reproduction. The actual fix is likely small (normalize candidate paths before applying ignore-paths), yet it must be done carefully to avoid altering semantics across platforms and path formats. Adding regression tests for recursive traversal with different CLI roots (e.g., '.' vs 'src/') and ensuring they pass on Windows and POSIX accounts for a significant portion of the work.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:17.666404"}
{"instance_id": "pytest-dev__pytest-10051", "repo": "pytest-dev/pytest", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and points directly to the root cause: `caplog.get_records()` references a list that diverges when `caplog.clear()` replaces `caplog.records` instead of clearing it in-place. However, fixing it safely requires understanding how caplog stores records per-phase (setup/call/teardown), ensuring no other code relies on list replacement semantics, and adding a regression test that covers the interaction between `get_records`, `records`, and `clear`. Running and validating the logging-related test suite plus checking for subtle behavioral regressions brings the total to roughly two hours.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 25, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and points directly to the root cause: `caplog.get_records()` references a list that diverges when `caplog.clear()` replaces `caplog.records` instead of clearing it in-place. However, fixing it safely requires understanding how caplog stores records per-phase (setup/call/teardown), ensuring no other code relies on list replacement semantics, and adding a regression test that covers the interaction between `get_records`, `records`, and `clear`. Running and validating the logging-related test suite plus checking for subtle behavioral regressions brings the total to roughly two hours.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 25,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:17.984140"}
{"instance_id": "pydata__xarray-4966", "repo": "pydata/xarray", "estimated_minutes": 210.0, "justification": "Although the code change is likely localized (handling `_Unsigned=False` symmetrically to the existing `_Unsigned=True` logic), it requires careful investigation to ensure the correct semantics for signed-vs-unsigned byte interpretation, especially because this is a bit-level reinterpretation (e.g., `uint8` values 128\u2013255 should become `int8` -128\u2013-1) rather than a numeric cast. The engineer will need to identify the exact decode path used by the pydap engine and ensure the fix is applied in the correct layer without breaking existing netCDF and CF decoding behavior. Adding robust tests (including correct two\u2019s-complement behavior and ensuring no regressions for existing `_Unsigned=True` handling) will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 55, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the code change is likely localized (handling `_Unsigned=False` symmetrically to the existing `_Unsigned=True` logic), it requires careful investigation to ensure the correct semantics for signed-vs-unsigned byte interpretation, especially because this is a bit-level reinterpretation (e.g., `uint8` values 128\u2013255 should become `int8` -128\u2013-1) rather than a numeric cast. The engineer will need to identify the exact decode path used by the pydap engine and ensure the fix is applied in the correct layer without breaking existing netCDF and CF decoding behavior. Adding robust tests (including correct two\u2019s-complement behavior and ensuring no regressions for existing `_Unsigned=True` handling) will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 55,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:18.242411"}
{"instance_id": "pylint-dev__pylint-6528", "repo": "pylint-dev/pylint", "estimated_minutes": 210.0, "justification": "Although the bug is easy to reproduce, it requires understanding how Pylint\u2019s recursive discovery builds the target file list and where ignore options are applied (or bypassed) compared to non-recursive execution. The fix will likely involve adjusting the recursive expansion logic to run the same ignore filtering (base-name ignores, path-based ignores, and regex ignores) at discovery time, and ensuring behavior matches the documented defaults. Adding regression tests is non-trivial because it needs filesystem-based fixtures and must validate behavior across multiple ignore mechanisms without breaking existing discovery semantics.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the bug is easy to reproduce, it requires understanding how Pylint\u2019s recursive discovery builds the target file list and where ignore options are applied (or bypassed) compared to non-recursive execution. The fix will likely involve adjusting the recursive expansion logic to run the same ignore filtering (base-name ignores, path-based ignores, and regex ignores) at discovery time, and ensuring behavior matches the documented defaults. Adding regression tests is non-trivial because it needs filesystem-based fixtures and must validate behavior across multiple ignore mechanisms without breaking existing discovery semantics.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:18.286106"}
{"instance_id": "pylint-dev__pylint-6386", "repo": "pylint-dev/pylint", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and likely rooted in how Pylint\u2019s CLI options are registered with argparse (the short alias -v appears to be configured differently than --verbose, causing it to expect a value). Fixing it should be localized to the option/argument definition layer, but will require some investigation to understand Pylint\u2019s custom option manager and how it maps long/short forms into argparse. Adding regression tests for command-line parsing behavior (including help output expectations) and running the relevant test suite will take a non-trivial portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and likely rooted in how Pylint\u2019s CLI options are registered with argparse (the short alias -v appears to be configured differently than --verbose, causing it to expect a value). Fixing it should be localized to the option/argument definition layer, but will require some investigation to understand Pylint\u2019s custom option manager and how it maps long/short forms into argparse. Adding regression tests for command-line parsing behavior (including help output expectations) and running the relevant test suite will take a non-trivial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:18.294734"}
{"instance_id": "pylint-dev__pylint-7277", "repo": "pylint-dev/pylint", "estimated_minutes": 180.0, "justification": "Although the code change is small (guarding the sys.path pop), the surrounding behavior is subtle because it depends on how pylint is invoked (as a module, via runpy, and with alter_sys=True) and on historical expectations documented in the docstring. An experienced engineer will need time to confirm the intent of the sys.path manipulation, identify the safest condition (\"\", \".\", and/or os.getcwd() equivalents), and ensure it doesn\u2019t break normal CLI/module execution paths. Writing a reliable regression test is the main time driver, since reproducing runpy-driven sys.path behavior typically requires subprocess/module-invocation style tests and careful isolation to avoid flaky interactions with the test runner\u2019s own sys.path.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the code change is small (guarding the sys.path pop), the surrounding behavior is subtle because it depends on how pylint is invoked (as a module, via runpy, and with alter_sys=True) and on historical expectations documented in the docstring. An experienced engineer will need time to confirm the intent of the sys.path manipulation, identify the safest condition (\\\"\\\", \\\".\\\", and/or os.getcwd() equivalents), and ensure it doesn\u2019t break normal CLI/module execution paths. Writing a reliable regression test is the main time driver, since reproducing runpy-driven sys.path behavior typically requires subprocess/module-invocation style tests and careful isolation to avoid flaky interactions with the test runner\u2019s own sys.path.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:18.303632"}
{"instance_id": "pylint-dev__pylint-8898", "repo": "pylint-dev/pylint", "estimated_minutes": 180.0, "justification": "Fixing this requires understanding how Pylint\u2019s configuration option types are parsed (especially the CSV-to-regex handling) and why commas are split before regex compilation. The implementation is likely localized (e.g., adjusting the comma-splitting logic to avoid splitting inside regex quantifiers like `{1,3}` and ensuring invalid regexes fail gracefully), but it must preserve backward compatibility for options that currently accept comma-separated regexes. Writing targeted tests for config parsing and regression cases (both crash avoidance and correct splitting behavior) and running the suite will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires understanding how Pylint\u2019s configuration option types are parsed (especially the CSV-to-regex handling) and why commas are split before regex compilation. The implementation is likely localized (e.g., adjusting the comma-splitting logic to avoid splitting inside regex quantifiers like `{1,3}` and ensuring invalid regexes fail gracefully), but it must preserve backward compatibility for options that currently accept comma-separated regexes. Writing targeted tests for config parsing and regression cases (both crash avoidance and correct splitting behavior) and running the suite will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:19.590015"}
{"instance_id": "pytest-dev__pytest-5809", "repo": "pytest-dev/pytest", "estimated_minutes": 120.0, "justification": "Although the core fix is small (changing the submitted lexer from \"python3\" to \"text\"), an engineer will need to confirm how pytest constructs and submits the paste payload and whether any other code paths depend on the lexer value. Proper coverage will require adding or adjusting tests that mock the network interaction (to avoid real bpaste calls) and assert the correct form fields are sent. Running the relevant test suite and checking for regressions around the pastebin feature adds additional verification time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 20, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"Although the core fix is small (changing the submitted lexer from \\\"python3\\\" to \\\"text\\\"), an engineer will need to confirm how pytest constructs and submits the paste payload and whether any other code paths depend on the lexer value. Proper coverage will require adding or adjusting tests that mock the network interaction (to avoid real bpaste calls) and assert the correct form fields are sent. Running the relevant test suite and checking for regressions around the pastebin feature adds additional verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 20,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:19.987545"}
{"instance_id": "pylint-dev__pylint-4604", "repo": "pylint-dev/pylint", "estimated_minutes": 180.0, "justification": "Fixing an unused-import false positive caused by references inside type comments requires tracing how Pylint\u2019s variables/unused-import logic records \"used names\" and where (or if) type comments are parsed into a form the checker can analyze. The reproduction is clear, but the fix likely touches AST handling (astroid nodes/type comment storage) and requires carefully parsing type comment strings to extract qualified names like \"abc.ABC\" without introducing regressions for other comment forms. Adding focused regression tests in Pylint\u2019s functional test suite and running the relevant test matrix adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 60, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing an unused-import false positive caused by references inside type comments requires tracing how Pylint\u2019s variables/unused-import logic records \\\"used names\\\" and where (or if) type comments are parsed into a form the checker can analyze. The reproduction is clear, but the fix likely touches AST handling (astroid nodes/type comment storage) and requires carefully parsing type comment strings to extract qualified names like \\\"abc.ABC\\\" without introducing regressions for other comment forms. Adding focused regression tests in Pylint\u2019s functional test suite and running the relevant test matrix adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 60,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:20.035305"}
{"instance_id": "pydata__xarray-7233", "repo": "pydata/xarray", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible but likely requires digging into how Coarsen.construct rebuilds a Dataset and how it decides which non-dimension coordinates belong in `.coords` vs `.data_vars`. Fixing it typically involves adjusting coordinate propagation logic in the coarsen/rolling construction path and ensuring the behavior is consistent for both Dataset and DataArray-backed cases. A proper regression test is needed to confirm that non-dimensional coordinates remain coordinates across construct and that no other coordinate-handling behaviors regress.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible but likely requires digging into how Coarsen.construct rebuilds a Dataset and how it decides which non-dimension coordinates belong in `.coords` vs `.data_vars`. Fixing it typically involves adjusting coordinate propagation logic in the coarsen/rolling construction path and ensuring the behavior is consistent for both Dataset and DataArray-backed cases. A proper regression test is needed to confirm that non-dimensional coordinates remain coordinates across construct and that no other coordinate-handling behaviors regress.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:21.056769"}
{"instance_id": "pytest-dev__pytest-5262", "repo": "pytest-dev/pytest", "estimated_minutes": 120.0, "justification": "Although the code change is likely small (adjusting `_pytest.capture.EncodedFile.mode` to not advertise binary mode), an engineer will need time to understand the capture stack and why `sys.stdout` in tests can be a `CaptureIO` without a `mode` attribute. Crafting a reliable regression test requires constructing/obtaining an `EncodedFile` instance (or the exact wrapper chain used during capturing) and asserting both the exposed `.mode` and behavior when third-party code branches on `'b' in out.mode`. Verifying the fix will also involve running the relevant capture tests and a focused subset of the suite to ensure no regressions in capturing semantics across platforms/Python versions.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 15, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"Although the code change is likely small (adjusting `_pytest.capture.EncodedFile.mode` to not advertise binary mode), an engineer will need time to understand the capture stack and why `sys.stdout` in tests can be a `CaptureIO` without a `mode` attribute. Crafting a reliable regression test requires constructing/obtaining an `EncodedFile` instance (or the exact wrapper chain used during capturing) and asserting both the exposed `.mode` and behavior when third-party code branches on `'b' in out.mode`. Verifying the fix will also involve running the relevant capture tests and a focused subset of the suite to ensure no regressions in capturing semantics across platforms/Python versions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 15,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:21.092578"}
{"instance_id": "pytest-dev__pytest-10356", "repo": "pytest-dev/pytest", "estimated_minutes": 270.0, "justification": "Fixing this requires understanding how pytest currently collects and normalizes class-level marks (the pytestmark attribute) and why multiple inheritance currently drops marks due to normal attribute lookup/MRO behavior. The implementation is likely not a one-liner because marks must be merged across the full MRO while preserving ordering semantics and avoiding duplicates (and potentially handling diamond inheritance), which risks subtle behavior changes. Proper coverage needs several focused tests (simple MI, diamond, interaction with per-function marks) plus running the test suite to ensure no regressions in collection and marker behavior.", "time_breakdown": {"understanding_and_investigation": 105, "implementation": 75, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 270,\n  \"justification\": \"Fixing this requires understanding how pytest currently collects and normalizes class-level marks (the pytestmark attribute) and why multiple inheritance currently drops marks due to normal attribute lookup/MRO behavior. The implementation is likely not a one-liner because marks must be merged across the full MRO while preserving ordering semantics and avoiding duplicates (and potentially handling diamond inheritance), which risks subtle behavior changes. Proper coverage needs several focused tests (simple MI, diamond, interaction with per-function marks) plus running the test suite to ensure no regressions in collection and marker behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 105,\n    \"implementation\": 75,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:21.474899"}
{"instance_id": "pytest-dev__pytest-6197", "repo": "pytest-dev/pytest", "estimated_minutes": 180.0, "justification": "Although the regression has a clear reproducer and a likely culprit (#5831), an engineer will still need to trace how collection rules changed to start treating arbitrary package __init__.py files as collectable test modules. The fix will likely involve adjusting collection heuristics (or reverting part of the change) while preserving intended behaviors such as collecting legitimate test packages and not breaking src-layout/coverage-related expectations. Writing a robust regression test is non-trivial because it must exercise collection without relying on platform-specific import failures and must ensure no unintended collection happens across directory layouts.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the regression has a clear reproducer and a likely culprit (#5831), an engineer will still need to trace how collection rules changed to start treating arbitrary package __init__.py files as collectable test modules. The fix will likely involve adjusting collection heuristics (or reverting part of the change) while preserving intended behaviors such as collecting legitimate test packages and not breaking src-layout/coverage-related expectations. Writing a robust regression test is non-trivial because it must exercise collection without relying on platform-specific import failures and must ensure no unintended collection happens across directory layouts.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:22.619733"}
{"instance_id": "pytest-dev__pytest-7324", "repo": "pytest-dev/pytest", "estimated_minutes": 150.0, "justification": "The crash is tied to a CPython debug-build assertion triggered by generating an AST Name node for reserved identifiers (True/False/None) on Python 3.8+, so the engineer must understand pytest's mark expression AST compilation path and confirm exactly where those identifiers are emitted. The fix is likely localized (replacing AST node construction for identifiers with version-appropriate Constant/NameConstant handling), but must be done carefully to preserve behavior across multiple Python versions. Adding regression tests is non-trivial because it involves ensuring the expression compiler handles these tokens correctly and ideally guarding against interpreter aborts on debug builds, plus running the relevant test suite across versions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 35, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The crash is tied to a CPython debug-build assertion triggered by generating an AST Name node for reserved identifiers (True/False/None) on Python 3.8+, so the engineer must understand pytest's mark expression AST compilation path and confirm exactly where those identifiers are emitted. The fix is likely localized (replacing AST node construction for identifiers with version-appropriate Constant/NameConstant handling), but must be done carefully to preserve behavior across multiple Python versions. Adding regression tests is non-trivial because it involves ensuring the expression compiler handles these tokens correctly and ideally guarding against interpreter aborts on debug builds, plus running the relevant test suite across versions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 35,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:22.930925"}
{"instance_id": "pytest-dev__pytest-6202", "repo": "pytest-dev/pytest", "estimated_minutes": 150.0, "justification": "Although the code change itself is likely a one-line adjustment (removing or altering the legacy \".[\" replacement), an experienced engineer will need time to confirm the historical intent, ensure no remaining collection/reporting paths depend on that behavior, and identify the correct place to assert the expected headline formatting. Adding a regression test that validates the failure headline for parametrized IDs containing \"..[\" (and ensuring it matches the long-report output) will take the bulk of the time, along with running the relevant tox environments to avoid regressions.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 15, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the code change itself is likely a one-line adjustment (removing or altering the legacy \\\".[\\\" replacement), an experienced engineer will need time to confirm the historical intent, ensure no remaining collection/reporting paths depend on that behavior, and identify the correct place to assert the expected headline formatting. Adding a regression test that validates the failure headline for parametrized IDs containing \\\"..[\\\" (and ensuring it matches the long-report output) will take the bulk of the time, along with running the relevant tox environments to avoid regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 15,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:24.666394"}
{"instance_id": "pytest-dev__pytest-8399", "repo": "pytest-dev/pytest", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and the likely fix (prefix generated xunit/unittest fixture names with an underscore) is straightforward, but it requires confirming all code paths that generate these fixtures across pytest\u2019s unittest and xunit integrations. Properly validating the change needs updating/adding tests that assert `pytest --fixtures` output hides \u201cprivate\u201d fixtures by default and shows them with `-v`, which tends to be the most time-consuming part due to output normalization and existing test conventions. Some additional time is needed to run the relevant suite sections to ensure no regressions in fixture discovery or naming.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and the likely fix (prefix generated xunit/unittest fixture names with an underscore) is straightforward, but it requires confirming all code paths that generate these fixtures across pytest\u2019s unittest and xunit integrations. Properly validating the change needs updating/adding tests that assert `pytest --fixtures` output hides \u201cprivate\u201d fixtures by default and shows them with `-v`, which tends to be the most time-consuming part due to output normalization and existing test conventions. Some additional time is needed to run the relevant suite sections to ensure no regressions in fixture discovery or naming.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:25.735393"}
{"instance_id": "pytest-dev__pytest-7521", "repo": "pytest-dev/pytest", "estimated_minutes": 150.0, "justification": "The issue is well-defined with a minimal reproducer and a known bisection point, but it involves pytest\u2019s capture subsystem and text/byte decoding layers where newline translation can be subtle. An engineer will need to trace how file descriptors are wrapped (likely via TextIOWrapper/EncodedFile) and identify where universal-newline handling or newline normalization started occurring after the referenced refactor. The fix itself is likely small (ensuring newline translation is disabled/preserved), but it must be validated across platforms and capture modes with a targeted regression test and a short sanity run of the broader test suite.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-defined with a minimal reproducer and a known bisection point, but it involves pytest\u2019s capture subsystem and text/byte decoding layers where newline translation can be subtle. An engineer will need to trace how file descriptors are wrapped (likely via TextIOWrapper/EncodedFile) and identify where universal-newline handling or newline normalization started occurring after the referenced refactor. The fix itself is likely small (ensuring newline translation is disabled/preserved), but it must be validated across platforms and capture modes with a targeted regression test and a short sanity run of the broader test suite.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:26.287192"}
{"instance_id": "pydata__xarray-6721", "repo": "pydata/xarray", "estimated_minutes": 180.0, "justification": "The stack trace strongly suggests that `Dataset.chunks` triggers `Variable.data`, which falls back to `.values` and forces `np.asarray(...)` on zarr-backed arrays, causing real I/O and large in-memory loads. Fixing this likely requires adjusting chunk-detection logic (e.g., in `get_chunksizes`) to inspect internal/lazy array wrappers or encoding metadata without touching `Variable.data`, which is subtle because it must preserve behavior for true dask-backed arrays. Writing a robust regression test that proves no eager materialization/IO occurs (without relying on flaky remote data) adds non-trivial effort.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The stack trace strongly suggests that `Dataset.chunks` triggers `Variable.data`, which falls back to `.values` and forces `np.asarray(...)` on zarr-backed arrays, causing real I/O and large in-memory loads. Fixing this likely requires adjusting chunk-detection logic (e.g., in `get_chunksizes`) to inspect internal/lazy array wrappers or encoding metadata without touching `Variable.data`, which is subtle because it must preserve behavior for true dask-backed arrays. Writing a robust regression test that proves no eager materialization/IO occurs (without relying on flaky remote data) adds non-trivial effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:26.620842"}
{"instance_id": "pytest-dev__pytest-7982", "repo": "pytest-dev/pytest", "estimated_minutes": 150.0, "justification": "The issue is well-scoped (a regression introduced by explicitly setting follow_symlinks=False) but still requires locating the exact collection/scanning code path and confirming the pre-6.1.0 behavior. The code change itself is likely small, however pytest\u2019s collection behavior is subtle and needs a focused regression test that works across platforms (including handling environments where symlink creation is restricted). Verification will include running the relevant collection test suite and ensuring the change doesn\u2019t introduce unintended recursion or collection explosions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 30, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped (a regression introduced by explicitly setting follow_symlinks=False) but still requires locating the exact collection/scanning code path and confirming the pre-6.1.0 behavior. The code change itself is likely small, however pytest\u2019s collection behavior is subtle and needs a focused regression test that works across platforms (including handling environments where symlink creation is restricted). Verification will include running the relevant collection test suite and ensuring the change doesn\u2019t introduce unintended recursion or collection explosions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 30,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:26.973497"}
{"instance_id": "pytest-dev__pytest-5631", "repo": "pytest-dev/pytest", "estimated_minutes": 120.0, "justification": "The issue is well-localized to _pytest/compat.py (num_mock_patch_args) and the failure mechanism is clear: using the `in` operator triggers `__eq__` for non-sentinel objects, which breaks for numpy-like objects that return non-boolean comparison results. The fix is small (switch membership testing to identity checks against known sentinel objects), but it requires careful validation to avoid changing behavior for normal mock.patch usage. Writing a regression test will take meaningful time because pytest should not depend on numpy in its own tests, so a numpy-like stand-in object must be crafted and exercised via a collection run using pytester.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 20, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-localized to _pytest/compat.py (num_mock_patch_args) and the failure mechanism is clear: using the `in` operator triggers `__eq__` for non-sentinel objects, which breaks for numpy-like objects that return non-boolean comparison results. The fix is small (switch membership testing to identity checks against known sentinel objects), but it requires careful validation to avoid changing behavior for normal mock.patch usage. Writing a regression test will take meaningful time because pytest should not depend on numpy in its own tests, so a numpy-like stand-in object must be crafted and exercised via a collection run using pytester.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 20,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:27.249764"}
{"instance_id": "scikit-learn__scikit-learn-10297", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "The issue is well-scoped (missing `store_cv_values` parameter on `RidgeClassifierCV` despite documented behavior), but requires some repository investigation to understand how `RidgeClassifierCV` is implemented relative to `RidgeCV` and where `cv_values_` is computed/stored. The fix likely involves adding/plumbing a new init parameter through to shared ridge CV code paths and ensuring the estimator exposes `cv_values_` only in the supported configuration (`store_cv_values=True` and `cv=None`). Writing a targeted regression test and running the relevant linear_model test suite will take a meaningful portion of the time due to scikit-learn\u2019s testing conventions and CI expectations.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped (missing `store_cv_values` parameter on `RidgeClassifierCV` despite documented behavior), but requires some repository investigation to understand how `RidgeClassifierCV` is implemented relative to `RidgeCV` and where `cv_values_` is computed/stored. The fix likely involves adding/plumbing a new init parameter through to shared ridge CV code paths and ensuring the estimator exposes `cv_values_` only in the supported configuration (`store_cv_values=True` and `cv=None`). Writing a targeted regression test and running the relevant linear_model test suite will take a meaningful portion of the time due to scikit-learn\u2019s testing conventions and CI expectations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:27.309037"}
{"instance_id": "pytest-dev__pytest-7571", "repo": "pytest-dev/pytest", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible, but fixing it requires investigating pytest's logging/caplog internals and identifying the exact lifecycle regression introduced in the referenced commit. The fix will likely involve restoring previous behavior around saving/restoring handler/logger levels across tests, which must be done carefully to avoid side effects with other logging features. Adding a focused regression test and running the relevant logging-related test suite should be straightforward but non-trivial due to pytest\u2019s extensive logging integration.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible, but fixing it requires investigating pytest's logging/caplog internals and identifying the exact lifecycle regression introduced in the referenced commit. The fix will likely involve restoring previous behavior around saving/restoring handler/logger levels across tests, which must be done carefully to avoid side effects with other logging features. Adding a focused regression test and running the relevant logging-related test suite should be straightforward but non-trivial due to pytest\u2019s extensive logging integration.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:27.358610"}
{"instance_id": "pytest-dev__pytest-7205", "repo": "pytest-dev/pytest", "estimated_minutes": 120.0, "justification": "The issue has clear reproduction steps and a pinpointed failure location in _pytest/setuponly.py, but the engineer will still need to confirm how cached fixture parameters are stored and how setup-show output is formatted across versions. The fix itself is small (switching from implicit str() formatting to saferepr/repr with an appropriate maxsize), but pytest\u2019s output behavior is heavily test-driven, so adding/adjusting tests to cover bytes parameters under --setup-show and ensuring no BytesWarning under -bb will take a meaningful portion of the time. Verification should include running the relevant unit tests and ensuring the changed formatting doesn\u2019t break existing expectations for setup-show output.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 25, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue has clear reproduction steps and a pinpointed failure location in _pytest/setuponly.py, but the engineer will still need to confirm how cached fixture parameters are stored and how setup-show output is formatted across versions. The fix itself is small (switching from implicit str() formatting to saferepr/repr with an appropriate maxsize), but pytest\u2019s output behavior is heavily test-driven, so adding/adjusting tests to cover bytes parameters under --setup-show and ensuring no BytesWarning under -bb will take a meaningful portion of the time. Verification should include running the relevant unit tests and ensuring the changed formatting doesn\u2019t break existing expectations for setup-show output.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 25,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:27.477366"}
{"instance_id": "pytest-dev__pytest-7432", "repo": "pytest-dev/pytest", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and localized to a specific hook (`pytest_runtest_makereport`) in `src/_pytest/skipping.py`, but requires some investigation to understand how `--runxfail` alters report/exception handling and why it changes the reported skip location to the plugin file. The actual code change is likely small (adjusting how the report\u2019s longrepr/location is preserved when `--runxfail` logic runs), but pytest\u2019s reporting internals are subtle and need careful handling to avoid regressions. Adding a regression test will take meaningful time because it likely needs to assert terminal summary output (`-rs`) behavior under both `--runxfail` and normal runs.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 35, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and localized to a specific hook (`pytest_runtest_makereport`) in `src/_pytest/skipping.py`, but requires some investigation to understand how `--runxfail` alters report/exception handling and why it changes the reported skip location to the plugin file. The actual code change is likely small (adjusting how the report\u2019s longrepr/location is preserved when `--runxfail` logic runs), but pytest\u2019s reporting internals are subtle and need careful handling to avoid regressions. Adding a regression test will take meaningful time because it likely needs to assert terminal summary output (`-rs`) behavior under both `--runxfail` and normal runs.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 35,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:27.650367"}
{"instance_id": "pytest-dev__pytest-7490", "repo": "pytest-dev/pytest", "estimated_minutes": 150.0, "justification": "This appears to be a regression in pytest 6\u2019s xfail handling where xfail evaluation is likely cached or decided too early (e.g., at collection/setup) and therefore misses markers added dynamically during the test call phase. An experienced engineer will need to trace the xfail decision path (notably around the referenced commit), identify where marker state is read/cached, and adjust the logic to re-check markers at the correct time without breaking existing xfail/strict semantics. The fix should be accompanied by a focused regression test ensuring dynamically added xfail markers during test execution properly convert failures into xfailed outcomes, plus a short run of the relevant test suite subset to ensure no unintended changes.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This appears to be a regression in pytest 6\u2019s xfail handling where xfail evaluation is likely cached or decided too early (e.g., at collection/setup) and therefore misses markers added dynamically during the test call phase. An experienced engineer will need to trace the xfail decision path (notably around the referenced commit), identify where marker state is read/cached, and adjust the logic to re-check markers at the correct time without breaking existing xfail/strict semantics. The fix should be accompanied by a focused regression test ensuring dynamically added xfail markers during test execution properly convert failures into xfailed outcomes, plus a short run of the relevant test suite subset to ensure no unintended changes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:27.844733"}
{"instance_id": "scikit-learn__scikit-learn-11578", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 180.0, "justification": "Although the code change is small (ensuring the temporary LogisticRegression instance in _log_reg_scoring_path is constructed with multi_class='multinomial' when requested), an engineer will need to confirm which estimator attributes/constructor args affect scoring paths like predict_proba and decision_function. The bulk of the time is in designing a stable non-regression test that fails on the buggy behavior and is robust across solvers/platforms, then running and iterating on the test suite to ensure no unintended regressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 30, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the code change is small (ensuring the temporary LogisticRegression instance in _log_reg_scoring_path is constructed with multi_class='multinomial' when requested), an engineer will need to confirm which estimator attributes/constructor args affect scoring paths like predict_proba and decision_function. The bulk of the time is in designing a stable non-regression test that fails on the buggy behavior and is robust across solvers/platforms, then running and iterating on the test suite to ensure no unintended regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 30,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:28.971350"}
{"instance_id": "scikit-learn__scikit-learn-10908", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "The issue is well-scoped and reproducible, but requires understanding how CountVectorizer manages fitted state (vocabulary_ creation via _validate_vocabulary) and how feature-name APIs check fittedness. The fix is likely small (making get_feature_names / get_feature_names_out trigger vocabulary validation when an explicit vocabulary was provided), but care is needed to preserve ordering semantics and avoid changing behavior for truly unfitted vectorizers without a vocabulary. Writing robust regression tests for multiple vocabulary forms (list vs dict) and running the relevant sklearn test suite will take a substantial portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped and reproducible, but requires understanding how CountVectorizer manages fitted state (vocabulary_ creation via _validate_vocabulary) and how feature-name APIs check fittedness. The fix is likely small (making get_feature_names / get_feature_names_out trigger vocabulary validation when an explicit vocabulary was provided), but care is needed to preserve ordering semantics and avoid changing behavior for truly unfitted vectorizers without a vocabulary. Writing robust regression tests for multiple vocabulary forms (list vs dict) and running the relevant sklearn test suite will take a substantial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:29.553837"}
{"instance_id": "scikit-learn__scikit-learn-13328", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and the traceback points directly to an invalid unary negation on boolean data inside HuberRegressor's loss/gradient computation, so initial debugging should be fairly quick. However, scikit-learn has strict input validation conventions (e.g., check_array/validate_data and dtype handling) and the fix must be done in a way that preserves behavior for sparse/dense inputs and doesn\u2019t regress numerical stability. Adding a targeted regression test and running the relevant linear_model test suite (plus basic estimator checks) will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 35, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and the traceback points directly to an invalid unary negation on boolean data inside HuberRegressor's loss/gradient computation, so initial debugging should be fairly quick. However, scikit-learn has strict input validation conventions (e.g., check_array/validate_data and dtype handling) and the fix must be done in a way that preserves behavior for sparse/dense inputs and doesn\u2019t regress numerical stability. Adding a targeted regression test and running the relevant linear_model test suite (plus basic estimator checks) will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 35,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:30.983851"}
{"instance_id": "scikit-learn__scikit-learn-13135", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "The issue has clear reproduction steps and points directly to KBinsDiscretizer's kmeans-derived bin_edges being non-monotonic, which breaks np.digitize, but the engineer still needs to trace how cluster centers are computed and converted into edges and ensure the fix is correct for edge cases (duplicates/empty clusters). The implementation is likely small (sorting centers/edges and possibly handling ties) but must preserve intended semantics and be robust across features and random states. Time is also needed to add/adjust regression tests and run the relevant preprocessing and discretization test suites to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 40, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue has clear reproduction steps and points directly to KBinsDiscretizer's kmeans-derived bin_edges being non-monotonic, which breaks np.digitize, but the engineer still needs to trace how cluster centers are computed and converted into edges and ensure the fix is correct for edge cases (duplicates/empty clusters). The implementation is likely small (sorting centers/edges and possibly handling ties) but must preserve intended semantics and be robust across features and random states. Time is also needed to add/adjust regression tests and run the relevant preprocessing and discretization test suites to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 40,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:32.257151"}
{"instance_id": "scikit-learn__scikit-learn-13142", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 180.0, "justification": "The issue is well-reproduced and the hint points to a specific root cause: `fit_predict` performs an E-step using the parameters from the last initialization/EM run rather than recomputing responsibilities after restoring `best_params` when `n_init>1`. Fixing this is likely a small, localized change, but it requires careful reading of the EM loop and parameter-setting semantics to ensure mathematical consistency. Additional time is needed to add a regression test that reliably fails on the buggy behavior (controlling randomness) and to run/verify the relevant mixture-model test suite without introducing flakiness.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 35, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-reproduced and the hint points to a specific root cause: `fit_predict` performs an E-step using the parameters from the last initialization/EM run rather than recomputing responsibilities after restoring `best_params` when `n_init>1`. Fixing this is likely a small, localized change, but it requires careful reading of the EM loop and parameter-setting semantics to ensure mathematical consistency. Additional time is needed to add a regression test that reliably fails on the buggy behavior (controlling randomness) and to run/verify the relevant mixture-model test suite without introducing flakiness.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 35,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:32.409469"}
{"instance_id": "scikit-learn__scikit-learn-11310", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 180.0, "justification": "Implementing a new \"refit_time_\" attribute in BaseSearchCV requires understanding the current fit/refit flow in model_selection._search (including edge cases like refit=False, callable refit, and multi-metric scoring). The code change itself is small (timing around the final refit on full data), but scikit-learn requires careful API consistency, docs/attribute semantics, and robust tests to ensure the attribute is set only when appropriate and doesn\u2019t break existing behavior. Verification will include adding/adjusting unit tests and running the relevant test suite to guard against regressions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Implementing a new \\\"refit_time_\\\" attribute in BaseSearchCV requires understanding the current fit/refit flow in model_selection._search (including edge cases like refit=False, callable refit, and multi-metric scoring). The code change itself is small (timing around the final refit on full data), but scikit-learn requires careful API consistency, docs/attribute semantics, and robust tests to ensure the attribute is set only when appropriate and doesn\u2019t break existing behavior. Verification will include adding/adjusting unit tests and running the relevant test suite to guard against regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:32.570924"}
{"instance_id": "pytest-dev__pytest-5787", "repo": "pytest-dev/pytest", "estimated_minutes": 300.0, "justification": "This issue requires tracing how pytest represents exceptions locally versus how failures are serialized and transmitted when running under xdist, then identifying where exception chaining (__cause__/__context__) is being dropped. The fix is likely not a single-line change because it involves report/longrepr serialization semantics and ensuring chained traceback rendering survives pickling/transport. Proper coverage will require adding regression tests that exercise chained exceptions through the same serialization path used by workers and verifying formatting remains stable across configurations.", "time_breakdown": {"understanding_and_investigation": 120, "implementation": 110, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 300,\n  \"justification\": \"This issue requires tracing how pytest represents exceptions locally versus how failures are serialized and transmitted when running under xdist, then identifying where exception chaining (__cause__/__context__) is being dropped. The fix is likely not a single-line change because it involves report/longrepr serialization semantics and ensuring chained traceback rendering survives pickling/transport. Proper coverage will require adding regression tests that exercise chained exceptions through the same serialization path used by workers and verifying formatting remains stable across configurations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 120,\n    \"implementation\": 110,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:34.409330"}
{"instance_id": "scikit-learn__scikit-learn-10844", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "Although the functional change is small (ensuring the denominator computation in fowlkes_mallows_score does not overflow), an engineer will need time to confirm the current dtypes of tk/pk/qk across sparse/dense paths and NumPy versions and to choose the most appropriate fix (e.g., casting to int64 vs float vs algebraic rearrangement) without harming numerical stability. A robust regression test must be crafted to reliably trigger the overflow scenario (typically by forcing int32 intermediates) while keeping test runtime and memory usage reasonable. Finally, verification requires running the relevant metrics/cluster test suite and checking that no related metrics regress (and that warnings/NaNs are eliminated).", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 35, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the functional change is small (ensuring the denominator computation in fowlkes_mallows_score does not overflow), an engineer will need time to confirm the current dtypes of tk/pk/qk across sparse/dense paths and NumPy versions and to choose the most appropriate fix (e.g., casting to int64 vs float vs algebraic rearrangement) without harming numerical stability. A robust regression test must be crafted to reliably trigger the overflow scenario (typically by forcing int32 intermediates) while keeping test runtime and memory usage reasonable. Finally, verification requires running the relevant metrics/cluster test suite and checking that no related metrics regress (and that warnings/NaNs are eliminated).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 35,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:34.718132"}
{"instance_id": "scikit-learn__scikit-learn-14496", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 165.0, "justification": "Although the core bug is a small type conversion issue, completing it properly in scikit-learn involves tracing all code paths where float-valued `min_samples`/`min_cluster_size` are accepted (including `cluster_optics_xi`), updating the parameter documentation, and adding robust regression tests. Writing tests is the main driver because OPTICS behavior can be sensitive and the test should specifically assert correct coercion and absence of the previous TypeError while staying deterministic. Finally, running the relevant test suite subset and updating the changelog entry adds additional overhead typical of scikit-learn contributions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 165,\n  \"justification\": \"Although the core bug is a small type conversion issue, completing it properly in scikit-learn involves tracing all code paths where float-valued `min_samples`/`min_cluster_size` are accepted (including `cluster_optics_xi`), updating the parameter documentation, and adding robust regression tests. Writing tests is the main driver because OPTICS behavior can be sensitive and the test should specifically assert correct coercion and absence of the previous TypeError while staying deterministic. Finally, running the relevant test suite subset and updating the changelog entry adds additional overhead typical of scikit-learn contributions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:34.840570"}
{"instance_id": "scikit-learn__scikit-learn-12585", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "Although the reproduction is clear and the likely fix is small, the engineer needs to carefully inspect sklearn.base.clone() to ensure the estimator-detection logic does not regress for non-estimator objects that legitimately implement get_params (e.g., kernels). Implementing the change is likely a small conditional tweak, but adding robust regression tests (including edge cases around classes vs. instances and safe vs. unsafe cloning) and running the relevant test suite portion will take most of the time. Given scikit-learn\u2019s strict backward-compatibility and testing conventions, moderate investigation and verification effort is required even for a seemingly one-line fix.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 25, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the reproduction is clear and the likely fix is small, the engineer needs to carefully inspect sklearn.base.clone() to ensure the estimator-detection logic does not regress for non-estimator objects that legitimately implement get_params (e.g., kernels). Implementing the change is likely a small conditional tweak, but adding robust regression tests (including edge cases around classes vs. instances and safe vs. unsafe cloning) and running the relevant test suite portion will take most of the time. Given scikit-learn\u2019s strict backward-compatibility and testing conventions, moderate investigation and verification effort is required even for a seemingly one-line fix.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 25,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:35.385071"}
{"instance_id": "scikit-learn__scikit-learn-12973", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "The issue is well-scoped and points directly to the problematic code, but an engineer still needs to trace how `copy_X` is used inside `LassoLarsIC.fit` and any downstream calls to ensure behavior and memory-copy semantics remain consistent. Implementing the fix (changing the `fit` signature to accept `copy_X=None` and only overriding `self.copy_X` when explicitly passed) is straightforward, but scikit-learn requires careful backward-compatibility handling, documentation updates, and robust tests. Writing/adjusting tests to cover both initialization-time and fit-time overrides, plus running the relevant test suite subset to avoid regressions, will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-scoped and points directly to the problematic code, but an engineer still needs to trace how `copy_X` is used inside `LassoLarsIC.fit` and any downstream calls to ensure behavior and memory-copy semantics remain consistent. Implementing the fix (changing the `fit` signature to accept `copy_X=None` and only overriding `self.copy_X` when explicitly passed) is straightforward, but scikit-learn requires careful backward-compatibility handling, documentation updates, and robust tests. Writing/adjusting tests to cover both initialization-time and fit-time overrides, plus running the relevant test suite subset to avoid regressions, will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:35.625290"}
{"instance_id": "scikit-learn__scikit-learn-13779", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and localized to the VotingClassifier/VotingRegressor fit path when handling sample_weight alongside an estimator set to None via set_params. Fixing it likely requires adjusting the internal loop that detects sample_weight support so that None estimators are skipped consistently (matching how they are handled elsewhere in voting/ensemble code). Although the code change should be small, scikit-learn requires adding a focused regression test and running the relevant ensemble test suite to ensure no behavior regressions across classifier/regressor and hard/soft voting variants.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and localized to the VotingClassifier/VotingRegressor fit path when handling sample_weight alongside an estimator set to None via set_params. Fixing it likely requires adjusting the internal loop that detects sample_weight support so that None estimators are skipped consistently (matching how they are handled elsewhere in voting/ensemble code). Although the code change should be small, scikit-learn requires adding a focused regression test and running the relevant ensemble test suite to ensure no behavior regressions across classifier/regressor and hard/soft voting variants.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:35.821731"}
{"instance_id": "scikit-learn__scikit-learn-14053", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "The issue is reproducible and points to a specific faulty control-flow in `export_text` where leaf sentinel values (e.g., -2) from `tree_.feature` are incorrectly used to index `feature_names`. An experienced contributor will still need time to trace how `export_text` constructs node labels, choose the least invasive fix consistent with scikit-learn conventions, and ensure it works across classifiers/regressors and different tree shapes. Adding a targeted regression test and running the relevant test suite (including formatting-sensitive assertions) will take a substantial portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is reproducible and points to a specific faulty control-flow in `export_text` where leaf sentinel values (e.g., -2) from `tree_.feature` are incorrectly used to index `feature_names`. An experienced contributor will still need time to trace how `export_text` constructs node labels, choose the least invasive fix consistent with scikit-learn conventions, and ensure it works across classifiers/regressors and different tree shapes. Adding a targeted regression test and running the relevant test suite (including formatting-sensitive assertions) will take a substantial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:35.824976"}
{"instance_id": "scikit-learn__scikit-learn-13439", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 90.0, "justification": "The issue is well-scoped: Pipeline recently gained indexing/slicing support but lacks a __len__ implementation, causing len(pipe) and slice expressions like pipe[:len(pipe)] to fail. An engineer will need to inspect sklearn.pipeline.Pipeline\u2019s existing __getitem__ behavior and decide the intended length semantics (almost certainly len(self.steps)) while ensuring no unintended \u201csequence-like\u201d behavior is added beyond __len__. Adding the method is quick, but scikit-learn-quality tests (including a regression test for slicing with len(pipe) and checking behavior with passthrough/None-like steps) and running relevant test subsets will take the bulk of the time.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 15, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is well-scoped: Pipeline recently gained indexing/slicing support but lacks a __len__ implementation, causing len(pipe) and slice expressions like pipe[:len(pipe)] to fail. An engineer will need to inspect sklearn.pipeline.Pipeline\u2019s existing __getitem__ behavior and decide the intended length semantics (almost certainly len(self.steps)) while ensuring no unintended \u201csequence-like\u201d behavior is added beyond __len__. Adding the method is quick, but scikit-learn-quality tests (including a regression test for slicing with len(pipe) and checking behavior with passthrough/None-like steps) and running relevant test subsets will take the bulk of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 15,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:36.136079"}
{"instance_id": "scikit-learn__scikit-learn-13496", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 180.0, "justification": "The change is conceptually straightforward (plumb an existing BaseBagging parameter through IsolationForest), but it requires careful investigation to ensure IsolationForest\u2019s fit path correctly honors warm_start and to match scikit-learn\u2019s API/documentation conventions. Implementing the init signature and docstring updates is quick, but adding a robust regression test for estimator reuse/addition and running the relevant test suite (plus any doc build checks if updated) adds meaningful time. Some iteration is likely to align with existing patterns in ensemble estimators and avoid subtle failures (e.g., behavior when n_estimators is not increased).", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The change is conceptually straightforward (plumb an existing BaseBagging parameter through IsolationForest), but it requires careful investigation to ensure IsolationForest\u2019s fit path correctly honors warm_start and to match scikit-learn\u2019s API/documentation conventions. Implementing the init signature and docstring updates is quick, but adding a robust regression test for estimator reuse/addition and running the relevant test suite (plus any doc build checks if updated) adds meaningful time. Some iteration is likely to align with existing patterns in ensemble estimators and avoid subtle failures (e.g., behavior when n_estimators is not increased).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:36.223248"}
{"instance_id": "pytest-dev__pytest-5840", "repo": "pytest-dev/pytest", "estimated_minutes": 210.0, "justification": "The regression appears Windows-specific and likely tied to a recent change (e.g., using os.normcase) that lowercases paths and breaks conftest/module import name derivation and/or conftest caching keys. An engineer will need to trace how conftest paths are normalized, how py.path.local.pyimport computes module names from sys.path, and confirm the exact failure mode on Windows. The fix is likely localized (adjust path normalization to preserve correct casing or use a casing-preserving resolution strategy) but requires a targeted regression test that reliably exercises mixed-case package paths on Windows and ensures no cross-platform regressions.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"The regression appears Windows-specific and likely tied to a recent change (e.g., using os.normcase) that lowercases paths and breaks conftest/module import name derivation and/or conftest caching keys. An engineer will need to trace how conftest paths are normalized, how py.path.local.pyimport computes module names from sys.path, and confirm the exact failure mode on Windows. The fix is likely localized (adjust path normalization to preserve correct casing or use a casing-preserving resolution strategy) but requires a targeted regression test that reliably exercises mixed-case package paths on Windows and ensures no cross-platform regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:36.588659"}
{"instance_id": "scikit-learn__scikit-learn-14087", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 210.0, "justification": "Although the issue has a minimal reproducer and a clear regression window (works in 0.20.3, fails in 0.21.2), fixing it requires investigating LogisticRegressionCV\u2019s coefficient-path shapes across solvers and refit settings to understand why the indexing assumes a 4D array. The actual code change is likely small (adjusting shape handling / indexing when refit=False), but care is needed to avoid breaking multinomial/OVR cases and solver-specific paths. Writing a focused regression test and running relevant linear_model CV tests to ensure no regressions adds meaningful time.", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 55, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the issue has a minimal reproducer and a clear regression window (works in 0.20.3, fails in 0.21.2), fixing it requires investigating LogisticRegressionCV\u2019s coefficient-path shapes across solvers and refit settings to understand why the indexing assumes a 4D array. The actual code change is likely small (adjusting shape handling / indexing when refit=False), but care is needed to avoid breaking multinomial/OVR cases and solver-specific paths. Writing a focused regression test and running relevant linear_model CV tests to ensure no regressions adds meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 55,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:36.749108"}
{"instance_id": "scikit-learn__scikit-learn-14141", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 90.0, "justification": "This change is small in scope but requires locating and understanding the existing show_versions implementation and its conventions for importing and reporting optional vs required dependencies. The implementation likely involves adding joblib to the dependency list and ensuring graceful handling/reporting, plus updating or adding a focused unit test to lock in the new output. Verification involves running the relevant test suite portion and ensuring no formatting or ordering regressions in show_versions output.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 25, "testing_and_verification": 35}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"This change is small in scope but requires locating and understanding the existing show_versions implementation and its conventions for importing and reporting optional vs required dependencies. The implementation likely involves adding joblib to the dependency list and ensuring graceful handling/reporting, plus updating or adding a focused unit test to lock in the new output. Verification involves running the relevant test suite portion and ensuring no formatting or ordering regressions in show_versions output.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 25,\n    \"testing_and_verification\": 35\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:38.268940"}
{"instance_id": "scikit-learn__scikit-learn-25931", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 180.0, "justification": "The issue is well-reproduced and the root cause is already identified (an internal call during `fit` uses a NumPy array, triggering feature-name validation warnings). However, fixing it cleanly in scikit-learn typically requires following established patterns (e.g., introducing an internal non-validating helper like `_score_samples`) and ensuring behavior stays consistent across `fit`, `score_samples`, and related methods. Writing a non-regression test for the warning and running the relevant test suite adds meaningful overhead even though the code change itself is modest.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-reproduced and the root cause is already identified (an internal call during `fit` uses a NumPy array, triggering feature-name validation warnings). However, fixing it cleanly in scikit-learn typically requires following established patterns (e.g., introducing an internal non-validating helper like `_score_samples`) and ensuring behavior stays consistent across `fit`, `score_samples`, and related methods. Writing a non-regression test for the warning and running the relevant test suite adds meaningful overhead even though the code change itself is modest.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:42.080961"}
{"instance_id": "scikit-learn__scikit-learn-14983", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "While the symptom is clear and easy to reproduce, fixing it correctly requires understanding how cross-validation splitters implement `__repr__` in `sklearn/model_selection/_split.py` and how `_build_repr` derives parameter values. The hinted solution (adding `__repr__` to `_RepeatedSplits`) uncovers a nuance where key parameters live in `cvargs`, so the engineer likely needs to adjust `_build_repr` carefully to avoid changing representations of other splitters. Writing a regression test and running the relevant model_selection test suite to ensure no broader repr regressions will take a non-trivial amount of time in scikit-learn\u2019s CI-heavy codebase.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 45, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"While the symptom is clear and easy to reproduce, fixing it correctly requires understanding how cross-validation splitters implement `__repr__` in `sklearn/model_selection/_split.py` and how `_build_repr` derives parameter values. The hinted solution (adding `__repr__` to `_RepeatedSplits`) uncovers a nuance where key parameters live in `cvargs`, so the engineer likely needs to adjust `_build_repr` carefully to avoid changing representations of other splitters. Writing a regression test and running the relevant model_selection test suite to ensure no broader repr regressions will take a non-trivial amount of time in scikit-learn\u2019s CI-heavy codebase.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 45,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:43.065543"}
{"instance_id": "scikit-learn__scikit-learn-9288", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 210.0, "justification": "Although the symptom is easy to reproduce and the hint points directly to seed handling in the KMeans n_init parallelization path, confirming the exact cause requires reading the initialization/parallel code and ensuring deterministic behavior across job counts. The fix is likely small (aligning how RandomState seeds are generated for sequential vs parallel runs), but it must be done carefully to avoid unintended changes in other estimators or regressions in clustering quality. Writing robust tests for determinism across n_jobs values and running the relevant test suite (at least sklearn.cluster and a subset of global tests) adds substantial time.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the symptom is easy to reproduce and the hint points directly to seed handling in the KMeans n_init parallelization path, confirming the exact cause requires reading the initialization/parallel code and ensuring deterministic behavior across job counts. The fix is likely small (aligning how RandomState seeds are generated for sequential vs parallel runs), but it must be done carefully to avoid unintended changes in other estimators or regressions in clustering quality. Writing robust tests for determinism across n_jobs values and running the relevant test suite (at least sklearn.cluster and a subset of global tests) adds substantial time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:43.158319"}
{"instance_id": "scikit-learn__scikit-learn-15100", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 90.0, "justification": "The issue is clearly reproducible and the proposed fix is a small, localized change to `strip_accents_unicode`, but an engineer will still need to inspect the current implementation and its callers (e.g., `CountVectorizer`) to ensure no unintended behavior changes. Adding a non-regression test for the NFKD-input case and running the relevant scikit-learn test suite portion (and likely a broader sanity run) will take the majority of the time due to repository conventions and test execution overhead. Overall, this is a straightforward bug fix with simple implementation but standard project-quality verification steps.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 15, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clearly reproducible and the proposed fix is a small, localized change to `strip_accents_unicode`, but an engineer will still need to inspect the current implementation and its callers (e.g., `CountVectorizer`) to ensure no unintended behavior changes. Adding a non-regression test for the NFKD-input case and running the relevant scikit-learn test suite portion (and likely a broader sanity run) will take the majority of the time due to repository conventions and test execution overhead. Overall, this is a straightforward bug fix with simple implementation but standard project-quality verification steps.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 15,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:43.599564"}
{"instance_id": "scikit-learn__scikit-learn-14894", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "The issue has clear reproduction steps and points directly to a failing line in `sklearn/svm/base.py` within `_sparse_fit`, but an engineer will still need time to understand how libsvm\u2019s sparse outputs are post-processed and why `support_vectors_` can be empty in this code path. The fix is likely a small conditional/early-exit to construct correctly-shaped empty `dual_coef_`/`support_vectors_` without triggering a division by zero, but it must preserve expected shapes and behavior across SVR/SVC variants. Adding a targeted regression test and running relevant SVM test suites on both sparse and dense paths will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue has clear reproduction steps and points directly to a failing line in `sklearn/svm/base.py` within `_sparse_fit`, but an engineer will still need time to understand how libsvm\u2019s sparse outputs are post-processed and why `support_vectors_` can be empty in this code path. The fix is likely a small conditional/early-exit to construct correctly-shaped empty `dual_coef_`/`support_vectors_` without triggering a division by zero, but it must preserve expected shapes and behavior across SVR/SVC variants. Adding a targeted regression test and running relevant SVM test suites on both sparse and dense paths will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:43.690607"}
{"instance_id": "scikit-learn__scikit-learn-26323", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 165.0, "justification": "The issue is well-reproduced and localized to ColumnTransformer\u2019s output-wrapping path, but fixing it correctly requires understanding how ColumnTransformer stores/iterates over fitted transformers and how set_output propagates configuration. The change will likely involve ensuring the `remainder` estimator is included in the internal iteration used to call `set_output` and possibly adjusting result-collection logic for pandas output. Writing a regression test for the specific remainder-estimator case (and verifying no regressions for `remainder='drop'/'passthrough'`) plus running the relevant test suite will take a substantial fraction of the time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 165,\n  \"justification\": \"The issue is well-reproduced and localized to ColumnTransformer\u2019s output-wrapping path, but fixing it correctly requires understanding how ColumnTransformer stores/iterates over fitted transformers and how set_output propagates configuration. The change will likely involve ensuring the `remainder` estimator is included in the internal iteration used to call `set_output` and possibly adjusting result-collection logic for pandas output. Writing a regression test for the specific remainder-estimator case (and verifying no regressions for `remainder='drop'/'passthrough'`) plus running the relevant test suite will take a substantial fraction of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:43.851516"}
{"instance_id": "scikit-learn__scikit-learn-14629", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 210.0, "justification": "Although the reproduction is clear, fixing it correctly requires understanding how `cross_val_predict(..., method='predict_proba')` uses `classes_` to align probability columns and how multi-output estimators should expose class metadata. The likely proper fix is to add a `classes_` attribute to `MultiOutputClassifier` (similar to `ClassifierChain`) and ensure `cross_val_predict` handles multi-output `classes_` consistently, which requires careful inspection of edge cases and output shapes. Writing robust regression tests for multi-output probabilistic predictions across CV folds and verifying no regressions in related model-selection utilities adds non-trivial time.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 55, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the reproduction is clear, fixing it correctly requires understanding how `cross_val_predict(..., method='predict_proba')` uses `classes_` to align probability columns and how multi-output estimators should expose class metadata. The likely proper fix is to add a `classes_` attribute to `MultiOutputClassifier` (similar to `ClassifierChain`) and ensure `cross_val_predict` handles multi-output `classes_` consistently, which requires careful inspection of edge cases and output shapes. Writing robust regression tests for multi-output probabilistic predictions across CV folds and verifying no regressions in related model-selection utilities adds non-trivial time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 55,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:44.307760"}
{"instance_id": "sphinx-doc__sphinx-10435", "repo": "sphinx-doc/sphinx", "estimated_minutes": 150.0, "justification": "The issue is well-reproduced but requires tracing how the new inline syntax-highlighting path (from #10251) renders Docutils \"code\" roles specifically in the LaTeX writer, and where whitespace is being introduced (likely via token joining or macro wrapping). The fix is probably localized (e.g., adding LaTeX comment markers or adjusting how highlighted inline fragments are emitted) but must be done carefully to avoid breaking TeX escaping and other inline roles. Adding/adjusting regression tests in the existing LaTeX build test suite and verifying output across a few cases will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-reproduced but requires tracing how the new inline syntax-highlighting path (from #10251) renders Docutils \\\"code\\\" roles specifically in the LaTeX writer, and where whitespace is being introduced (likely via token joining or macro wrapping). The fix is probably localized (e.g., adding LaTeX comment markers or adjusting how highlighted inline fragments are emitted) but must be done carefully to avoid breaking TeX escaping and other inline roles. Adding/adjusting regression tests in the existing LaTeX build test suite and verifying output across a few cases will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:45.721370"}
{"instance_id": "sphinx-doc__sphinx-10323", "repo": "sphinx-doc/sphinx", "estimated_minutes": 210.0, "justification": "Although the user-facing symptom is clear, the root cause sits at the intersection of docutils option parsing (which strips leading whitespace) and Sphinx's literalinclude processing pipeline, so some code reading is required to pinpoint where dedent/prepend/append are combined. The likely fix is to change the order/scope of dedent so it applies only to the extracted file content and not to the prepend/append strings, which is a contained behavioral change but must be regression-tested. Writing and validating tests is non-trivial because it requires building/inspecting rendered output and ensuring warnings (-W) behavior is correct.", "time_breakdown": {"understanding_and_investigation": 85, "implementation": 65, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the user-facing symptom is clear, the root cause sits at the intersection of docutils option parsing (which strips leading whitespace) and Sphinx's literalinclude processing pipeline, so some code reading is required to pinpoint where dedent/prepend/append are combined. The likely fix is to change the order/scope of dedent so it applies only to the extracted file content and not to the prepend/append strings, which is a contained behavioral change but must be regression-tested. Writing and validating tests is non-trivial because it requires building/inspecting rendered output and ensuring warnings (-W) behavior is correct.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 85,\n    \"implementation\": 65,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:46.101744"}
{"instance_id": "scikit-learn__scikit-learn-13124", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 165.0, "justification": "The issue is a behavioral regression in StratifiedKFold\u2019s shuffling logic, likely caused by reusing (or reinitializing) the same RNG state for each class/stratum so each stratum is permuted identically, which preserves deterministic pairings across classes. Fixing it should be a localized change in the split-generation code, but it requires careful investigation to confirm the regression point, ensure reproducibility guarantees with random_state, and avoid changing non-shuffle behavior. Adding robust tests for randomness/reproducibility and running relevant portions of scikit-learn\u2019s test suite will take a meaningful amount of time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 165,\n  \"justification\": \"The issue is a behavioral regression in StratifiedKFold\u2019s shuffling logic, likely caused by reusing (or reinitializing) the same RNG state for each class/stratum so each stratum is permuted identically, which preserves deterministic pairings across classes. Fixing it should be a localized change in the split-generation code, but it requires careful investigation to confirm the regression point, ensure reproducibility guarantees with random_state, and avoid changing non-shuffle behavior. Adding robust tests for randomness/reproducibility and running relevant portions of scikit-learn\u2019s test suite will take a meaningful amount of time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:46.338182"}
{"instance_id": "django__django-14999", "repo": "django/django", "estimated_minutes": 210.0, "justification": "This change requires investigating how RenameModel performs database-side work beyond just renaming the main table (notably updating/recreating constraints on related fields), and why that work is still triggered even when the model\u2019s db_table is fixed. The fix is likely a targeted conditional in the migration operation (and possibly related state handling) to skip schema-altering steps when the resolved old/new db_table names are identical, while ensuring state transitions and any necessary non-schema updates remain correct. Proper regression coverage will require adding migration operation tests that assert no constraint/table-rebuild SQL is emitted in this scenario across backends, which adds moderate test complexity.", "time_breakdown": {"understanding_and_investigation": 85, "implementation": 55, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This change requires investigating how RenameModel performs database-side work beyond just renaming the main table (notably updating/recreating constraints on related fields), and why that work is still triggered even when the model\u2019s db_table is fixed. The fix is likely a targeted conditional in the migration operation (and possibly related state handling) to skip schema-altering steps when the resolved old/new db_table names are identical, while ensuring state transitions and any necessary non-schema updates remain correct. Proper regression coverage will require adding migration operation tests that assert no constraint/table-rebuild SQL is emitted in this scenario across backends, which adds moderate test complexity.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 85,\n    \"implementation\": 55,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:46.804775"}
{"instance_id": "scikit-learn__scikit-learn-12682", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 180.0, "justification": "Fixing this requires investigating how `SparseCoder` dispatches to different underlying solvers (e.g., `Lasso`, `LassoLars`, `Lars`) and where solver-specific parameters are currently constructed and forwarded. The code change itself is likely small (ensuring `max_iter` is correctly passed through for the `lasso_cd`/`Lasso` path and/or aligning behavior across solvers), but care is needed to match scikit-learn\u2019s API conventions and avoid breaking existing behavior. Writing a robust test is the main time driver because the implementation may not expose the underlying estimator directly, so the test must verify parameter forwarding or warning behavior in a non-flaky way.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 40, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires investigating how `SparseCoder` dispatches to different underlying solvers (e.g., `Lasso`, `LassoLars`, `Lars`) and where solver-specific parameters are currently constructed and forwarded. The code change itself is likely small (ensuring `max_iter` is correctly passed through for the `lasso_cd`/`Lasso` path and/or aligning behavior across solvers), but care is needed to match scikit-learn\u2019s API conventions and avoid breaking existing behavior. Writing a robust test is the main time driver because the implementation may not expose the underlying estimator directly, so the test must verify parameter forwarding or warning behavior in a non-flaky way.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 40,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:47.709193"}
{"instance_id": "scikit-learn__scikit-learn-25232", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 180.0, "justification": "Adding a new public parameter to IterativeImputer requires more than a local change: the class API, parameter validation, documentation, and the internal initialization logic (which currently instantiates a SimpleImputer without exposing fill_value) must be updated consistently. The engineer will also need to add/adjust tests to cover the constant initialization path (including fill_value=np.nan) and ensure the behavior is unchanged for other strategies. In scikit-learn, this typically involves navigating established conventions (parameter constraints, repr, docstrings, and regression tests), which adds non-trivial investigation and verification time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Adding a new public parameter to IterativeImputer requires more than a local change: the class API, parameter validation, documentation, and the internal initialization logic (which currently instantiates a SimpleImputer without exposing fill_value) must be updated consistently. The engineer will also need to add/adjust tests to cover the constant initialization path (including fill_value=np.nan) and ensure the behavior is unchanged for other strategies. In scikit-learn, this typically involves navigating established conventions (parameter constraints, repr, docstrings, and regression tests), which adds non-trivial investigation and verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:48.651488"}
{"instance_id": "scikit-learn__scikit-learn-14710", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible and localized to early-stopping scoring in HistGradientBoostingClassifier, but fixing it correctly requires understanding how targets are label-encoded and how the early-stopping scorer is invoked. The implementation is likely small (decode integer-encoded y back to original class labels before calling the scorer), but care is needed to avoid breaking custom scorers and multiclass behavior. Writing robust regression tests for both train-score and validation-score early stopping paths, and running the relevant scikit-learn test subset, will take a non-trivial amount of time.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 35, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible and localized to early-stopping scoring in HistGradientBoostingClassifier, but fixing it correctly requires understanding how targets are label-encoded and how the early-stopping scorer is invoked. The implementation is likely small (decode integer-encoded y back to original class labels before calling the scorer), but care is needed to avoid breaking custom scorers and multiclass behavior. Writing robust regression tests for both train-score and validation-score early stopping paths, and running the relevant scikit-learn test subset, will take a non-trivial amount of time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 35,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:50.848325"}
{"instance_id": "scikit-learn__scikit-learn-25102", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 420.0, "justification": "Supporting mixed-dtype preservation for pandas output is not a localized bug fix: it requires understanding the current `set_output` wrapping pipeline and carefully deciding where dtype information can be preserved without lying about computations. A practical implementation likely targets a subset of transformers (e.g., feature selectors that output a strict subset of original columns) by selecting columns on the original DataFrame rather than reconstructing from a NumPy array, which requires non-trivial refactoring and compatibility checks. Additional time is needed to add robust tests for categorical/mixed-float dtypes, interaction with `Pipeline`/`ColumnTransformer`, and to ensure no regressions in existing `set_output` behaviors.", "time_breakdown": {"understanding_and_investigation": 120, "implementation": 180, "testing_and_verification": 120}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "4-6", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 420,\n  \"justification\": \"Supporting mixed-dtype preservation for pandas output is not a localized bug fix: it requires understanding the current `set_output` wrapping pipeline and carefully deciding where dtype information can be preserved without lying about computations. A practical implementation likely targets a subset of transformers (e.g., feature selectors that output a strict subset of original columns) by selecting columns on the original DataFrame rather than reconstructing from a NumPy array, which requires non-trivial refactoring and compatibility checks. Additional time is needed to add robust tests for categorical/mixed-float dtypes, interaction with `Pipeline`/`ColumnTransformer`, and to ensure no regressions in existing `set_output` behaviors.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 120,\n    \"implementation\": 180,\n    \"testing_and_verification\": 120\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:51.123292"}
{"instance_id": "sphinx-doc__sphinx-10449", "repo": "sphinx-doc/sphinx", "estimated_minutes": 240.0, "justification": "Although the repro is clear, the underlying behavior involves Sphinx autodoc\u2019s class-signature generation and the separate code path that moves type hints into the description. An engineer will need time to trace how `__init__` annotations are being interpreted as a class \u201creturn type\u201d under `autodoc_typehints = \"description\"`, identify the correct suppression rule (likely for class directives and/or `__init__`), and ensure it doesn\u2019t regress other signature/typehint behaviors. Writing a focused regression test using Sphinx\u2019s extension test harness and validating output across a couple of scenarios will take a meaningful portion of the effort.", "time_breakdown": {"understanding_and_investigation": 100, "implementation": 55, "testing_and_verification": 85}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Although the repro is clear, the underlying behavior involves Sphinx autodoc\u2019s class-signature generation and the separate code path that moves type hints into the description. An engineer will need time to trace how `__init__` annotations are being interpreted as a class \u201creturn type\u201d under `autodoc_typehints = \\\"description\\\"`, identify the correct suppression rule (likely for class directives and/or `__init__`), and ensure it doesn\u2019t regress other signature/typehint behaviors. Writing a focused regression test using Sphinx\u2019s extension test harness and validating output across a couple of scenarios will take a meaningful portion of the effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 100,\n    \"implementation\": 55,\n    \"testing_and_verification\": 85\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:51.571085"}
{"instance_id": "scikit-learn__scikit-learn-25973", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 180.0, "justification": "The issue is clear and reproducible: SequentialFeatureSelector reuses the provided `cv` object multiple times, so a generator of splits gets consumed on the first pass and later scoring fails. Fixing it likely requires adding logic in `SequentialFeatureSelector.fit` (or its internal scoring routine) to detect non-reiterable iterables (e.g., generators) and materialize them into a list of `(train, test)` splits, while keeping the API consistent with other `cv` parameters in scikit-learn. The work also needs a focused non-regression test and running the relevant feature selection/model selection test suite to ensure no behavioral regressions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clear and reproducible: SequentialFeatureSelector reuses the provided `cv` object multiple times, so a generator of splits gets consumed on the first pass and later scoring fails. Fixing it likely requires adding logic in `SequentialFeatureSelector.fit` (or its internal scoring routine) to detect non-reiterable iterables (e.g., generators) and materialize them into a list of `(train, test)` splits, while keeping the API consistent with other `cv` parameters in scikit-learn. The work also needs a focused non-regression test and running the relevant feature selection/model selection test suite to ensure no behavioral regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:51.601675"}
{"instance_id": "scikit-learn__scikit-learn-25747", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 210.0, "justification": "The issue is clearly reproducible and appears to stem from the pandas wrapping logic in sklearn.utils._set_output incorrectly forcing the original input index onto a transformer output whose row count/index differs. Fixing it requires careful investigation to ensure the change doesn\u2019t break the intended \"preserve input index\" behavior for the common case while handling mismatched lengths gracefully. Proper regression tests are needed for FeatureUnion (and likely ColumnTransformer) under transform_output='pandas', plus verification across related estimators that rely on set_output.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 45, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"The issue is clearly reproducible and appears to stem from the pandas wrapping logic in sklearn.utils._set_output incorrectly forcing the original input index onto a transformer output whose row count/index differs. Fixing it requires careful investigation to ensure the change doesn\u2019t break the intended \\\"preserve input index\\\" behavior for the common case while handling mismatched lengths gracefully. Proper regression tests are needed for FeatureUnion (and likely ColumnTransformer) under transform_output='pandas', plus verification across related estimators that rely on set_output.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 45,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:52.114127"}
{"instance_id": "sphinx-doc__sphinx-10466", "repo": "sphinx-doc/sphinx", "estimated_minutes": 210.0, "justification": "Although the symptom (duplicate location lines in generated POT files) is clear, confirming the root cause requires tracing how Sphinx collects message metadata, normalizes paths, and serializes locations via Babel. The fix likely needs more than a simple dedupe: it must deduplicate after path normalization (e.g., relpath) and ensure deterministic ordering to avoid noisy diffs. Adding a regression test is non-trivial because it requires building a small Sphinx project with gettext output and asserting on the produced POT content without introducing platform-dependent path behavior.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the symptom (duplicate location lines in generated POT files) is clear, confirming the root cause requires tracing how Sphinx collects message metadata, normalizes paths, and serializes locations via Babel. The fix likely needs more than a simple dedupe: it must deduplicate after path normalization (e.g., relpath) and ensure deterministic ordering to avoid noisy diffs. Adding a regression test is non-trivial because it requires building a small Sphinx project with gettext output and asserting on the produced POT content without introducing platform-dependent path behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:52.481719"}
{"instance_id": "sphinx-doc__sphinx-7462", "repo": "sphinx-doc/sphinx", "estimated_minutes": 135.0, "justification": "The bug is well-scoped with a clear traceback pointing to `sphinx/domains/python.py` and a suggested fix (handling `ast.Tuple` with no elements) that is likely correct, so investigation and implementation are relatively straightforward. The main time cost is adding/adjusting a regression test that exercises autodoc/type-annotation rendering and ensuring it passes across Sphinx\u2019s test harness and supported Python versions. Verification requires running the relevant unit/integration tests to ensure no regressions in signature unparsing for tuples and other annotations.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 135,\n  \"justification\": \"The bug is well-scoped with a clear traceback pointing to `sphinx/domains/python.py` and a suggested fix (handling `ast.Tuple` with no elements) that is likely correct, so investigation and implementation are relatively straightforward. The main time cost is adding/adjusting a regression test that exercises autodoc/type-annotation rendering and ensuring it passes across Sphinx\u2019s test harness and supported Python versions. Verification requires running the relevant unit/integration tests to ensure no regressions in signature unparsing for tuples and other annotations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:53.884153"}
{"instance_id": "sphinx-doc__sphinx-11445", "repo": "sphinx-doc/sphinx", "estimated_minutes": 120.0, "justification": "The bug is well-reproduced and the likely root cause is already identified: rst_prolog is prepended in a way that can split a top-level heading when the title is a domain role, so the fix is probably a small adjustment to how the prolog is concatenated (ensuring proper blank-line separation). Even with a small code change, an engineer will need to confirm how Sphinx injects prolog/epilog into the docutils source, verify there are no side effects for other directives/roles, and add a regression test that builds docs and inspects the doctree/toctree output. Running and iterating on Sphinx\u2019s test suite/build-based tests will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 25, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The bug is well-reproduced and the likely root cause is already identified: rst_prolog is prepended in a way that can split a top-level heading when the title is a domain role, so the fix is probably a small adjustment to how the prolog is concatenated (ensuring proper blank-line separation). Even with a small code change, an engineer will need to confirm how Sphinx injects prolog/epilog into the docutils source, verify there are no side effects for other directives/roles, and add a regression test that builds docs and inspects the doctree/toctree output. Running and iterating on Sphinx\u2019s test suite/build-based tests will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 25,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:54.023354"}
{"instance_id": "pytest-dev__pytest-7236", "repo": "pytest-dev/pytest", "estimated_minutes": 240.0, "justification": "Although the reproduction is clear, the root cause likely lies in a subtle interaction between pytest's unittest integration (setup/call/teardown staging) and the --pdb debugging plugin behavior introduced/changed around the referenced regression PR. An experienced engineer will need to trace pytest's runtest protocol for unittest-based items under skip conditions and confirm exactly why teardown is still being invoked, then implement a guard or protocol adjustment without breaking teardown-on-error semantics for non-skipped tests. Writing a robust regression test is moderately complex because --pdb normally enters an interactive debugger, so the test must use pytest's existing debugging-test utilities/stubs (e.g., custom pdbcls) to assert the debugger is not entered and teardown isn't run.", "time_breakdown": {"understanding_and_investigation": 110, "implementation": 50, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "expert", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Although the reproduction is clear, the root cause likely lies in a subtle interaction between pytest's unittest integration (setup/call/teardown staging) and the --pdb debugging plugin behavior introduced/changed around the referenced regression PR. An experienced engineer will need to trace pytest's runtest protocol for unittest-based items under skip conditions and confirm exactly why teardown is still being invoked, then implement a guard or protocol adjustment without breaking teardown-on-error semantics for non-skipped tests. Writing a robust regression test is moderately complex because --pdb normally enters an interactive debugger, so the test must use pytest's existing debugging-test utilities/stubs (e.g., custom pdbcls) to assert the debugger is not entered and teardown isn't run.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 110,\n    \"implementation\": 50,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"expert\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:54.486379"}
{"instance_id": "sphinx-doc__sphinx-10673", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "Although the user-facing request is simple, Sphinx\u2019s toctree validation and resolution logic is tied to the environment\u2019s known source documents, while genindex/modindex/search are builder-generated \u201cspecial\u201d pages. An experienced engineer will need to locate where missing-doc warnings are emitted, decide the correct architectural approach (suppress warning vs. treat as resolvable targets), and ensure the resulting links resolve correctly for the HTML builder without breaking other builders. Adding regression tests will require building a small test project and asserting both warning behavior and generated navigation output.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 55, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the user-facing request is simple, Sphinx\u2019s toctree validation and resolution logic is tied to the environment\u2019s known source documents, while genindex/modindex/search are builder-generated \u201cspecial\u201d pages. An experienced engineer will need to locate where missing-doc warnings are emitted, decide the correct architectural approach (suppress warning vs. treat as resolvable targets), and ensure the resulting links resolve correctly for the HTML builder without breaking other builders. Adding regression tests will require building a small test project and asserting both warning behavior and generated navigation output.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 55,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:56.501422"}
{"instance_id": "sphinx-doc__sphinx-7748", "repo": "sphinx-doc/sphinx", "estimated_minutes": 600.0, "justification": "Supporting multiple signatures extracted from a docstring is not just a parser tweak: Sphinx\u2019s Python autodoc and domain machinery generally assumes a single canonical signature per documented object, so the change likely requires updates across directive rendering and object description handling. The issue is also partially underspecified (exact desired output/formatting and how it should interact with existing autodoc options), which increases investigation and design time. Adding reliable tests is non-trivial because it involves building docs and asserting rendered output for multiple signature lines and their interaction with docstrings/overloads.", "time_breakdown": {"understanding_and_investigation": 180, "implementation": 270, "testing_and_verification": 150}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "4-6", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 600,\n  \"justification\": \"Supporting multiple signatures extracted from a docstring is not just a parser tweak: Sphinx\u2019s Python autodoc and domain machinery generally assumes a single canonical signature per documented object, so the change likely requires updates across directive rendering and object description handling. The issue is also partially underspecified (exact desired output/formatting and how it should interact with existing autodoc options), which increases investigation and design time. Adding reliable tests is non-trivial because it involves building docs and asserting rendered output for multiple signature lines and their interaction with docstrings/overloads.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 180,\n    \"implementation\": 270,\n    \"testing_and_verification\": 150\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:56.609116"}
{"instance_id": "sphinx-doc__sphinx-7757", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible, but fixing it likely requires tracing how Sphinx parses Python signatures and renders parameter lists, specifically around the positional-only marker \"/\" introduced in Python 3.8. An engineer will need to identify where defaults are dropped for parameters preceding \"/\" (likely in the Python domain signature parser/rendering code), implement a small but careful fix, and add a regression test that asserts the rendered signature includes \"b=0\". Verification will include running the relevant domain tests and building a minimal documentation root to ensure no regressions in other signature edge cases.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible, but fixing it likely requires tracing how Sphinx parses Python signatures and renders parameter lists, specifically around the positional-only marker \\\"/\\\" introduced in Python 3.8. An engineer will need to identify where defaults are dropped for parameters preceding \\\"/\\\" (likely in the Python domain signature parser/rendering code), implement a small but careful fix, and add a regression test that asserts the rendered signature includes \\\"b=0\\\". Verification will include running the relevant domain tests and building a minimal documentation root to ensure no regressions in other signature edge cases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:56.794178"}
{"instance_id": "sphinx-doc__sphinx-7889", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "Although the failure is reproducible, the engineer will need to trace how autodoc\u2019s mocking machinery builds subclass names and why generic typing objects (e.g., TypeVar / typing internals) end up in string concatenation paths. The fix is likely localized (e.g., in sphinx.ext.autodoc.mock._make_subclass) but must be careful to preserve existing behavior for normal classes and other typing constructs across supported Python versions. Adding a regression test that exercises autodoc with a generic-typed class and confirming no regressions in the broader autodoc mocking behavior will take a meaningful amount of time.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 45, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the failure is reproducible, the engineer will need to trace how autodoc\u2019s mocking machinery builds subclass names and why generic typing objects (e.g., TypeVar / typing internals) end up in string concatenation paths. The fix is likely localized (e.g., in sphinx.ext.autodoc.mock._make_subclass) but must be careful to preserve existing behavior for normal classes and other typing constructs across supported Python versions. Adding a regression test that exercises autodoc with a generic-typed class and confirming no regressions in the broader autodoc mocking behavior will take a meaningful amount of time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 45,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:56.868280"}
{"instance_id": "sphinx-doc__sphinx-7590", "repo": "sphinx-doc/sphinx", "estimated_minutes": 210.0, "justification": "Supporting C++ user-defined literals (e.g., `6.6e-34q_J`, `1q_s`) requires updating Sphinx\u2019s C++ domain expression/initializer parsing so numeric literals may legally include an identifier suffix without whitespace. This is moderately complex because the C++ domain has its own tokenizer/parser logic and the change must avoid breaking existing numeric/identifier parsing and error reporting. Proper coverage will require adding/adjusting regression tests for declarations with `constexpr` initializers and ensuring parsing works across common numeric forms (integer, floating, scientific notation) plus suffixes.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 80, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Supporting C++ user-defined literals (e.g., `6.6e-34q_J`, `1q_s`) requires updating Sphinx\u2019s C++ domain expression/initializer parsing so numeric literals may legally include an identifier suffix without whitespace. This is moderately complex because the C++ domain has its own tokenizer/parser logic and the change must avoid breaking existing numeric/identifier parsing and error reporting. Proper coverage will require adding/adjusting regression tests for declarations with `constexpr` initializers and ensuring parsing works across common numeric forms (integer, floating, scientific notation) plus suffixes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 80,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": ">4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:57.156008"}
{"instance_id": "sphinx-doc__sphinx-11510", "repo": "sphinx-doc/sphinx", "estimated_minutes": 240.0, "justification": "Fixing this requires understanding how Sphinx reads sources vs. how docutils executes the include directive (where the included text is injected after the source-read phase), and then threading Sphinx\u2019s event mechanism into that include path without breaking docutils semantics. The implementation will likely involve modifying or wrapping Sphinx\u2019s include directive (or its integration with docutils) so that included file contents are passed through the same preprocessing pipeline, and ensuring correctness for path handling and nested includes. Meaningful regression tests are needed to confirm that replacements occur in the including document output and that behavior remains stable across builders and parallel reading.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 80, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Fixing this requires understanding how Sphinx reads sources vs. how docutils executes the include directive (where the included text is injected after the source-read phase), and then threading Sphinx\u2019s event mechanism into that include path without breaking docutils semantics. The implementation will likely involve modifying or wrapping Sphinx\u2019s include directive (or its integration with docutils) so that included file contents are passed through the same preprocessing pipeline, and ensuring correctness for path handling and nested includes. Meaningful regression tests are needed to confirm that replacements occur in the including document output and that behavior remains stable across builders and parallel reading.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 80,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:57.948165"}
{"instance_id": "sphinx-doc__sphinx-8056", "repo": "sphinx-doc/sphinx", "estimated_minutes": 210.0, "justification": "This requires investigating how sphinx.ext.napoleon parses and renders NumPy-style parameter fields, specifically the grammar for \"name : type\" when multiple names are comma-separated and when qualifiers like \"optional\" are present. The fix will likely involve adjusting the parsing/normalization logic and the reStructuredText node generation so that the parameter names and the full type/qualifier string are preserved and rendered correctly. Adding regression tests for both the multi-name case and the multi-name+optional case, and validating HTML output against existing napoleon expectations, adds non-trivial verification time.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This requires investigating how sphinx.ext.napoleon parses and renders NumPy-style parameter fields, specifically the grammar for \\\"name : type\\\" when multiple names are comma-separated and when qualifiers like \\\"optional\\\" are present. The fix will likely involve adjusting the parsing/normalization logic and the reStructuredText node generation so that the parameter names and the full type/qualifier string are preserved and rendered correctly. Adding regression tests for both the multi-name case and the multi-name+optional case, and validating HTML output against existing napoleon expectations, adds non-trivial verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:47:58.276723"}
{"instance_id": "sphinx-doc__sphinx-8035", "repo": "sphinx-doc/sphinx", "estimated_minutes": 240.0, "justification": "This change requires understanding how autodoc parses directive options and how member selection is implemented, because `:private-members:` currently behaves like a boolean flag while `:members:` supports argument parsing and filtering. Implementing argument support will likely touch both option parsing (directive option specs) and the logic that decides which members are included/excluded, with careful handling of backward compatibility (no-argument meaning \"all private members\"). New tests are needed to cover argument parsing, interaction with existing options like `:members:`/`:exclude-members:`, and to ensure no regressions in default behavior across Python member types (methods/attributes).", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 90, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"This change requires understanding how autodoc parses directive options and how member selection is implemented, because `:private-members:` currently behaves like a boolean flag while `:members:` supports argument parsing and filtering. Implementing argument support will likely touch both option parsing (directive option specs) and the logic that decides which members are included/excluded, with careful handling of backward compatibility (no-argument meaning \\\"all private members\\\"). New tests are needed to cover argument parsing, interaction with existing options like `:members:`/`:exclude-members:`, and to ensure no regressions in default behavior across Python member types (methods/attributes).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 90,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:47:59.730092"}
{"instance_id": "sphinx-doc__sphinx-7910", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "Although the root cause is identified (decorated functions change the callable whose __globals__ is inspected), the engineer will still need to trace Sphinx\u2019s autodoc/napoleon member-discovery logic to ensure a robust fix that works for decorated __init__ and decorated classes without regressions. The implementation likely involves unwrapping decorated callables (e.g., via __wrapped__/inspect.unwrap) and/or adjusting the owner-class resolution logic to avoid relying on the wrapper\u2019s globals. Adding regression tests will require building small doc projects and asserting emitted documentation includes __init__ content under napoleon_include_init_with_doc, which adds meaningful time for test authoring and verification.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the root cause is identified (decorated functions change the callable whose __globals__ is inspected), the engineer will still need to trace Sphinx\u2019s autodoc/napoleon member-discovery logic to ensure a robust fix that works for decorated __init__ and decorated classes without regressions. The implementation likely involves unwrapping decorated callables (e.g., via __wrapped__/inspect.unwrap) and/or adjusting the owner-class resolution logic to avoid relying on the wrapper\u2019s globals. Adding regression tests will require building small doc projects and asserting emitted documentation includes __init__ content under napoleon_include_init_with_doc, which adds meaningful time for test authoring and verification.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:00.068606"}
{"instance_id": "sphinx-doc__sphinx-7440", "repo": "sphinx-doc/sphinx", "estimated_minutes": 240.0, "justification": "The issue has clear reproduction steps but requires understanding how Sphinx normalizes glossary terms (likely lower/casefold) for indexing and duplicate detection, and why that changed in 3.0.0. Fixing it safely may require adjusting the internal keying strategy to distinguish case for duplicates while considering implications for case-insensitive :term: resolution and potential ambiguity. Proper regression coverage will involve adding/adjusting domain/glossary tests and running the relevant Sphinx test suite to ensure no indexing/cross-reference regressions.", "time_breakdown": {"understanding_and_investigation": 100, "implementation": 60, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"The issue has clear reproduction steps but requires understanding how Sphinx normalizes glossary terms (likely lower/casefold) for indexing and duplicate detection, and why that changed in 3.0.0. Fixing it safely may require adjusting the internal keying strategy to distinguish case for duplicates while considering implications for case-insensitive :term: resolution and potential ambiguity. Proper regression coverage will involve adding/adjusting domain/glossary tests and running the relevant Sphinx test suite to ensure no indexing/cross-reference regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 100,\n    \"implementation\": 60,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:00.103693"}
{"instance_id": "sphinx-doc__sphinx-8269", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "The issue is well-scoped and reproducible, but requires understanding the linkcheck workflow to see why anchor-checking logic overrides HTTP error reporting when `linkcheck_anchors=True`. The fix likely involves adjusting result prioritization/branching so non-2xx responses are surfaced before attempting (or at least before reporting) anchor validation. Adding/adjusting tests is moderately involved because linkcheck behavior is typically validated via mocked HTTP responses and needs to cover both error-status and anchor-check paths without introducing network flakiness.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-scoped and reproducible, but requires understanding the linkcheck workflow to see why anchor-checking logic overrides HTTP error reporting when `linkcheck_anchors=True`. The fix likely involves adjusting result prioritization/branching so non-2xx responses are surfaced before attempting (or at least before reporting) anchor validation. Adding/adjusting tests is moderately involved because linkcheck behavior is typically validated via mocked HTTP responses and needs to cover both error-status and anchor-check paths without introducing network flakiness.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:00.670240"}
{"instance_id": "sphinx-doc__sphinx-7454", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible, but fixing it requires understanding two distinct rendering paths in autodoc: how annotations are converted into clickable references in the signature node tree versus how they are emitted as reST in the description. The engineer will likely need to trace where `None` is treated as a special-case (or not) during signature annotation formatting and then align it with the description-mode behavior without affecting other builtins or typing constructs. Adding a regression test will require building docs via Sphinx\u2019s test harness and asserting on generated HTML (or doctree) output, which is moderately time-consuming in this repository.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible, but fixing it requires understanding two distinct rendering paths in autodoc: how annotations are converted into clickable references in the signature node tree versus how they are emitted as reST in the description. The engineer will likely need to trace where `None` is treated as a special-case (or not) during signature annotation formatting and then align it with the description-mode behavior without affecting other builtins or typing constructs. Adding a regression test will require building docs via Sphinx\u2019s test harness and asserting on generated HTML (or doctree) output, which is moderately time-consuming in this repository.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:01.026788"}
{"instance_id": "sphinx-doc__sphinx-8475", "repo": "sphinx-doc/sphinx", "estimated_minutes": 150.0, "justification": "The change is conceptually small (treat `TooManyRedirects` from the HEAD request path like other HEAD failures and retry with GET), but it requires understanding Sphinx's linkcheck request flow and how exceptions from the underlying HTTP client are handled. Implementing the fix will likely touch the linkcheck builder logic and possibly shared request utilities. The main time cost is adding reliable regression tests that simulate an infinite redirect loop (or forced `TooManyRedirects`) without depending on external websites, plus running and validating the full test suite to avoid regressions.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The change is conceptually small (treat `TooManyRedirects` from the HEAD request path like other HEAD failures and retry with GET), but it requires understanding Sphinx's linkcheck request flow and how exceptions from the underlying HTTP client are handled. Implementing the fix will likely touch the linkcheck builder logic and possibly shared request utilities. The main time cost is adding reliable regression tests that simulate an infinite redirect loop (or forced `TooManyRedirects`) without depending on external websites, plus running and validating the full test suite to avoid regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:02.142336"}
{"instance_id": "sphinx-doc__sphinx-8459", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible, but the behavior depends on the internal branching logic for `autodoc_typehints='description'`, which likely uses a different code path to render annotations than the signature-based mode where `autodoc_type_aliases` already works. An experienced engineer will need moderate time to trace how annotations are converted into rendered text/field lists and where type alias substitution is (or is not) applied, then ensure the alias resolution is consistently applied in both modes. Adding a focused regression test (and confirming no output regressions across multiple autodoc configurations) adds meaningful verification time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 45, "testing_and_verification": 65}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible, but the behavior depends on the internal branching logic for `autodoc_typehints='description'`, which likely uses a different code path to render annotations than the signature-based mode where `autodoc_type_aliases` already works. An experienced engineer will need moderate time to trace how annotations are converted into rendered text/field lists and where type alias substitution is (or is not) applied, then ensure the alias resolution is consistently applied in both modes. Adding a focused regression test (and confirming no output regressions across multiple autodoc configurations) adds meaningful verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 45,\n    \"testing_and_verification\": 65\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:02.638028"}
{"instance_id": "sphinx-doc__sphinx-7985", "repo": "sphinx-doc/sphinx", "estimated_minutes": 270.0, "justification": "Implementing local (internal) link validation in Sphinx's linkcheck builder requires first understanding how linkcheck currently classifies and reports non-HTTP(S) targets (typically marked as \"-local-\" and skipped). A robust solution will likely need a new optional configuration flag and careful resolution of relative paths against the build output (or source) directory while accounting for builder-specific output structure and edge cases like anchors/fragments and absolute paths. Writing reliable tests will take meaningful time because they need to construct a small Sphinx project, run the linkcheck builder under different configurations, and assert on emitted results without introducing platform-specific assumptions.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 90, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 270,\n  \"justification\": \"Implementing local (internal) link validation in Sphinx's linkcheck builder requires first understanding how linkcheck currently classifies and reports non-HTTP(S) targets (typically marked as \\\"-local-\\\" and skipped). A robust solution will likely need a new optional configuration flag and careful resolution of relative paths against the build output (or source) directory while accounting for builder-specific output structure and edge cases like anchors/fragments and absolute paths. Writing reliable tests will take meaningful time because they need to construct a small Sphinx project, run the linkcheck builder under different configurations, and assert on emitted results without introducing platform-specific assumptions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 90,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:02.694188"}
{"instance_id": "sphinx-doc__sphinx-8595", "repo": "sphinx-doc/sphinx", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and likely caused by a truthiness check (e.g., `if __all__:`) that incorrectly treats an empty list as \u201cno __all__ provided.\u201d Fixing it should be a small, localized change in autodoc\u2019s member-filtering logic, but will require confirming how autodoc currently derives members and how it treats missing vs. empty `__all__`. Adding a targeted regression test and running the relevant Sphinx test suite will take a meaningful portion of the time to ensure no behavior changes for modules without `__all__` or with non-list `__all__` values.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and likely caused by a truthiness check (e.g., `if __all__:`) that incorrectly treats an empty list as \u201cno __all__ provided.\u201d Fixing it should be a small, localized change in autodoc\u2019s member-filtering logic, but will require confirming how autodoc currently derives members and how it treats missing vs. empty `__all__`. Adding a targeted regression test and running the relevant Sphinx test suite will take a meaningful portion of the time to ensure no behavior changes for modules without `__all__` or with non-list `__all__` values.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:05.009435"}
{"instance_id": "sphinx-doc__sphinx-8120", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "Fixing this requires understanding how Sphinx currently constructs and chains gettext translation catalogs (built-in locale vs. user-provided locale_dirs) and why locale_dirs is only consulted as a fallback. The change is likely small in code (adjusting translation load/precedence or fallback ordering), but it must be validated across multiple locale_dirs and ensure no regressions for languages without custom overrides. Writing a reliable regression test is moderately time-consuming because it involves creating/compiling a test .mo catalog and running a Sphinx build asserting specific localized output.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires understanding how Sphinx currently constructs and chains gettext translation catalogs (built-in locale vs. user-provided locale_dirs) and why locale_dirs is only consulted as a fallback. The change is likely small in code (adjusting translation load/precedence or fallback ordering), but it must be validated across multiple locale_dirs and ensure no regressions for languages without custom overrides. Writing a reliable regression test is moderately time-consuming because it involves creating/compiling a test .mo catalog and running a Sphinx build asserting specific localized output.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:06.076647"}
{"instance_id": "scikit-learn__scikit-learn-26194", "repo": "scikit-learn/scikit-learn", "estimated_minutes": 210.0, "justification": "Although the symptom is clear (the prepended threshold is computed as `thresholds[0] + 1`), deciding the correct public-facing behavior requires some investigation because `roc_curve` is designed to accept arbitrary scores (not only probabilities) and the initial threshold is tied to guaranteeing the (0,0) point. A robust fix will likely replace the finite `+ 1` sentinel with a stable convention (e.g., `np.inf`) and then adjust/extend tests accordingly, ensuring no downstream assumptions about threshold finiteness are broken. The work is moderate because the change is small but must be validated against edge cases (scores equal to 1, constant scores, different dtypes) and the metrics test suite/regression expectations.", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 40, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the symptom is clear (the prepended threshold is computed as `thresholds[0] + 1`), deciding the correct public-facing behavior requires some investigation because `roc_curve` is designed to accept arbitrary scores (not only probabilities) and the initial threshold is tied to guaranteeing the (0,0) point. A robust fix will likely replace the finite `+ 1` sentinel with a stable convention (e.g., `np.inf`) and then adjust/extend tests accordingly, ensuring no downstream assumptions about threshold finiteness are broken. The work is moderate because the change is small but must be validated against edge cases (scores equal to 1, constant scores, different dtypes) and the metrics test suite/regression expectations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 40,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:06.644635"}
{"instance_id": "sphinx-doc__sphinx-9230", "repo": "sphinx-doc/sphinx", "estimated_minutes": 150.0, "justification": "The issue is well-defined with a clear reproduction case, but diagnosing it requires tracing how Sphinx parses and renders typed :param fields (likely in the docfield/type parsing logic used by autodoc and the Python domain). The fix is probably a small-to-medium change to a regex/tokenization routine so that commas inside parenthesized type expressions (e.g., dict(str, str)) are preserved and not split incorrectly. A proper regression test will need to be added (likely in the Python domain or autodoc test suite) and verified across builders to ensure no formatting regressions for other complex type strings.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-defined with a clear reproduction case, but diagnosing it requires tracing how Sphinx parses and renders typed :param fields (likely in the docfield/type parsing logic used by autodoc and the Python domain). The fix is probably a small-to-medium change to a regex/tokenization routine so that commas inside parenthesized type expressions (e.g., dict(str, str)) are preserved and not split incorrectly. A proper regression test will need to be added (likely in the Python domain or autodoc test suite) and verified across builders to ensure no formatting regressions for other complex type strings.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:06.797119"}
{"instance_id": "sphinx-doc__sphinx-8265", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "Although the symptom is clear (tuple default values in autodoc method signatures lose parentheses in HTML output), the root cause is likely in Sphinx\u2019s signature stringification and/or node-building logic where arguments may be split or re-tokenized around commas. An engineer will need to reproduce the issue, trace how `inspect.signature()`/default reprs are converted into `desc_signature` nodes, and ensure the fix doesn\u2019t break other complex defaults (lists, dicts, callables, long defaults). Adding a focused regression test for HTML output is required and may involve updating test roots and expected HTML, which typically adds nontrivial verification time.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 50, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the symptom is clear (tuple default values in autodoc method signatures lose parentheses in HTML output), the root cause is likely in Sphinx\u2019s signature stringification and/or node-building logic where arguments may be split or re-tokenized around commas. An engineer will need to reproduce the issue, trace how `inspect.signature()`/default reprs are converted into `desc_signature` nodes, and ensure the fix doesn\u2019t break other complex defaults (lists, dicts, callables, long defaults). Adding a focused regression test for HTML output is required and may involve updating test roots and expected HTML, which typically adds nontrivial verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 50,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:07.058718"}
{"instance_id": "sphinx-doc__sphinx-9320", "repo": "sphinx-doc/sphinx", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible but requires digging into `sphinx-quickstart`'s interactive prompting and path validation logic to understand why the \"Enter to exit\" path is rejected. Implementing the fix is likely small (adjusting prompt/validation flow or early-exiting when `conf.py` is detected), but Sphinx typically requires updating or adding CLI-facing tests to cover interactive behavior and exit codes. Verifying behavior across edge cases (existing directory, existing `conf.py`, empty input, non-empty invalid input) and running the relevant test suite adds non-trivial overhead.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible but requires digging into `sphinx-quickstart`'s interactive prompting and path validation logic to understand why the \\\"Enter to exit\\\" path is rejected. Implementing the fix is likely small (adjusting prompt/validation flow or early-exiting when `conf.py` is detected), but Sphinx typically requires updating or adding CLI-facing tests to cover interactive behavior and exit codes. Verifying behavior across edge cases (existing directory, existing `conf.py`, empty input, non-empty invalid input) and running the relevant test suite adds non-trivial overhead.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:07.426374"}
{"instance_id": "sphinx-doc__sphinx-10614", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "The issue is well-reproduced but requires understanding how Sphinx\u2019s graphviz/inheritance_diagram pipeline generates SVGs and rewrites intra-doc links. The core fix likely involves computing link targets relative to the SVG file\u2019s output location (e.g., the _images directory) rather than relative to the embedding HTML page, which is subtle and easy to get wrong across nested documents. Adding a regression test is non-trivial because it involves building HTML with SVG output enabled and asserting on emitted SVG/link content, potentially under graphviz-availability constraints.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-reproduced but requires understanding how Sphinx\u2019s graphviz/inheritance_diagram pipeline generates SVGs and rewrites intra-doc links. The core fix likely involves computing link targets relative to the SVG file\u2019s output location (e.g., the _images directory) rather than relative to the embedding HTML page, which is subtle and easy to get wrong across nested documents. Adding a regression test is non-trivial because it involves building HTML with SVG output enabled and asserting on emitted SVG/link content, potentially under graphviz-availability constraints.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:07.534372"}
{"instance_id": "sphinx-doc__sphinx-8548", "repo": "sphinx-doc/sphinx", "estimated_minutes": 240.0, "justification": "Fixing autodoc\u2019s handling of inherited attribute docstrings requires understanding how Sphinx caches and looks up \u201ccomment-based\u201d attribute docs (e.g., \"#:\" inline docs) and why the lookup key (namespace, attrname) fails across base classes. The implementation will likely involve updating the attribute doc resolution to traverse the class MRO and/or merge per-module parsed attribute comments so `Inherited.ham` can reuse `Base.ham` documentation when `:inherited-members:` is enabled. A regression test is needed to reproduce the provided minimal example and confirm that inherited methods and inherited attributes are both shown correctly without breaking existing autodoc behavior.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 70, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Fixing autodoc\u2019s handling of inherited attribute docstrings requires understanding how Sphinx caches and looks up \u201ccomment-based\u201d attribute docs (e.g., \\\"#:\\\" inline docs) and why the lookup key (namespace, attrname) fails across base classes. The implementation will likely involve updating the attribute doc resolution to traverse the class MRO and/or merge per-module parsed attribute comments so `Inherited.ham` can reuse `Base.ham` documentation when `:inherited-members:` is enabled. A regression test is needed to reproduce the provided minimal example and confirm that inherited methods and inherited attributes are both shown correctly without breaking existing autodoc behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 70,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:08.096724"}
{"instance_id": "sphinx-doc__sphinx-9258", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "Implementing support for union types using the pipe syntax (e.g., \"bytes | str\") likely requires updating Sphinx's type-field parsing/linking logic in the Python domain (which currently recognizes \"or\"-separated types) while avoiding regressions for existing type expressions and literal content. An experienced engineer will need time to locate the exact parsing path (field list handling vs. type reference resolution), decide on precise tokenization rules (e.g., spacing requirements, avoiding conflicts with other uses of \"|\"), and ensure output linking behavior matches existing conventions. Writing and running targeted tests across the domain rendering/linking behavior will take a meaningful portion of the effort to confirm no breakage in other type notations.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Implementing support for union types using the pipe syntax (e.g., \\\"bytes | str\\\") likely requires updating Sphinx's type-field parsing/linking logic in the Python domain (which currently recognizes \\\"or\\\"-separated types) while avoiding regressions for existing type expressions and literal content. An experienced engineer will need time to locate the exact parsing path (field list handling vs. type reference resolution), decide on precise tokenization rules (e.g., spacing requirements, avoiding conflicts with other uses of \\\"|\\\"), and ensure output linking behavior matches existing conventions. Writing and running targeted tests across the domain rendering/linking behavior will take a meaningful portion of the effort to confirm no breakage in other type notations.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:08.172566"}
{"instance_id": "sphinx-doc__sphinx-9461", "repo": "sphinx-doc/sphinx", "estimated_minutes": 240.0, "justification": "Fixing autodoc to properly detect and extract docstrings from descriptors produced by stacking @classmethod and @property requires non-trivial investigation into Sphinx\u2019s member inspection pipeline and how it handles Python descriptor edge cases (which differ across Python 3.9 vs 3.10+). The implementation will likely involve adjusting how autodoc classifies members and/or how it resolves the original wrapped object for docstring/signature extraction, while preserving behavior for normal properties, classmethods, and attributes. Writing reliable regression tests is moderately involved because it needs version-aware coverage and integration-level autodoc output assertions to avoid regressions in other descriptor/documentation paths.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 80, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Fixing autodoc to properly detect and extract docstrings from descriptors produced by stacking @classmethod and @property requires non-trivial investigation into Sphinx\u2019s member inspection pipeline and how it handles Python descriptor edge cases (which differ across Python 3.9 vs 3.10+). The implementation will likely involve adjusting how autodoc classifies members and/or how it resolves the original wrapped object for docstring/signature extraction, while preserving behavior for normal properties, classmethods, and attributes. Writing reliable regression tests is moderately involved because it needs version-aware coverage and integration-level autodoc output assertions to avoid regressions in other descriptor/documentation paths.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 80,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:08.620503"}
{"instance_id": "sphinx-doc__sphinx-9367", "repo": "sphinx-doc/sphinx", "estimated_minutes": 90.0, "justification": "The issue is clearly reproducible via an existing unit test and points directly to the failing behavior: pretty-printing/unparsing of Python AST tuples drops the trailing comma for 1-element tuples. Fixing it likely involves adjusting a specific rendering branch for `ast.Tuple` (or equivalent) to emit a comma when the tuple has exactly one element, which is a localized change but requires careful handling of surrounding parentheses and formatting rules. Time is mainly spent confirming the current unparse logic, implementing the special-case correctly without breaking other tuple/parenthesis cases, and running/adjusting tests to avoid regressions.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 25, "testing_and_verification": 35}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clearly reproducible via an existing unit test and points directly to the failing behavior: pretty-printing/unparsing of Python AST tuples drops the trailing comma for 1-element tuples. Fixing it likely involves adjusting a specific rendering branch for `ast.Tuple` (or equivalent) to emit a comma when the tuple has exactly one element, which is a localized change but requires careful handling of surrounding parentheses and formatting rules. Time is mainly spent confirming the current unparse logic, implementing the special-case correctly without breaking other tuple/parenthesis cases, and running/adjusting tests to avoid regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 25,\n    \"testing_and_verification\": 35\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:10.290711"}
{"instance_id": "sphinx-doc__sphinx-8551", "repo": "sphinx-doc/sphinx", "estimated_minutes": 210.0, "justification": "This issue involves subtle differences between how Python domain explicit roles and docfield-generated implicit cross-references (from :type:/:rtype:/:param:) propagate context like current module/class, which requires non-trivial code reading and reproduction. The likely fix is localized but touches cross-reference creation/resolution paths (e.g., docfields utilities and/or the Python domain resolver) and must preserve existing behavior while changing lookup priority to match explicit roles. Writing regression tests is necessary to ensure both the ambiguous-warning behavior and the previously silently-wrong resolution cases are handled correctly across module and non-module scopes.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This issue involves subtle differences between how Python domain explicit roles and docfield-generated implicit cross-references (from :type:/:rtype:/:param:) propagate context like current module/class, which requires non-trivial code reading and reproduction. The likely fix is localized but touches cross-reference creation/resolution paths (e.g., docfields utilities and/or the Python domain resolver) and must preserve existing behavior while changing lookup priority to match explicit roles. Writing regression tests is necessary to ensure both the ambiguous-warning behavior and the previously silently-wrong resolution cases are handled correctly across module and non-module scopes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:11.642572"}
{"instance_id": "sphinx-doc__sphinx-9698", "repo": "sphinx-doc/sphinx", "estimated_minutes": 120.0, "justification": "The bug is well-scoped with a clear reproduction: the Python domain is generating an index entry for a method-like object and incorrectly appending \"()\" even when the directive is marked as a property. Fixing it likely requires tracing how `py:method` builds its index text and adding a conditional path when `:property:` is set, which is localized but requires understanding Sphinx\u2019s Python domain indexing conventions. A regression test should be added/updated to assert the generated index entries for both `py:method :property:` and `py:property`, and the test suite run to ensure no unintended behavior changes for normal methods.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The bug is well-scoped with a clear reproduction: the Python domain is generating an index entry for a method-like object and incorrectly appending \\\"()\\\" even when the directive is marked as a property. Fixing it likely requires tracing how `py:method` builds its index text and adding a conditional path when `:property:` is set, which is localized but requires understanding Sphinx\u2019s Python domain indexing conventions. A regression test should be added/updated to assert the generated index entries for both `py:method :property:` and `py:property`, and the test suite run to ensure no unintended behavior changes for normal methods.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:13.165935"}
{"instance_id": "sphinx-doc__sphinx-8593", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "Fixing this requires understanding how autodoc decides whether a member is public/private, and why the existing `:meta public:` mechanism is applied to functions/classes but not module variables extracted from `#:` comments. The engineer will likely need to trace the module member collection path (ModuleDocumenter/DataDocumenter and ModuleAnalyzer) and ensure metadata parsing is consistently applied for attribute/variable docstrings. Adding a regression test in Sphinx\u2019s autodoc test suite and validating behavior across related options (e.g., `:members:`, `:private-members:`, underscore-prefixed names) adds non-trivial verification time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires understanding how autodoc decides whether a member is public/private, and why the existing `:meta public:` mechanism is applied to functions/classes but not module variables extracted from `#:` comments. The engineer will likely need to trace the module member collection path (ModuleDocumenter/DataDocumenter and ModuleAnalyzer) and ensure metadata parsing is consistently applied for attribute/variable docstrings. Adding a regression test in Sphinx\u2019s autodoc test suite and validating behavior across related options (e.g., `:members:`, `:private-members:`, underscore-prefixed names) adds non-trivial verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:13.617814"}
{"instance_id": "sphinx-doc__sphinx-9602", "repo": "sphinx-doc/sphinx", "estimated_minutes": 240.0, "justification": "Fixing this requires tracing how Sphinx converts typing annotations into cross-reference nodes (likely via sphinx.util.typing stringification and autodoc/typehints rendering) and identifying why Literal parameters are being treated as \"py:class\" targets. The change is conceptually small (special-case Literal arguments that are values like True/False/None/strings/ints so they render as plain text or a non-class role), but it touches a central annotation-rendering path with potential regressions. Writing robust tests is non-trivial because it must exercise autodoc output and nitpicky mode behavior across multiple Literal value types and ensure no new unresolved references are introduced.", "time_breakdown": {"understanding_and_investigation": 105, "implementation": 55, "testing_and_verification": 80}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Fixing this requires tracing how Sphinx converts typing annotations into cross-reference nodes (likely via sphinx.util.typing stringification and autodoc/typehints rendering) and identifying why Literal parameters are being treated as \\\"py:class\\\" targets. The change is conceptually small (special-case Literal arguments that are values like True/False/None/strings/ints so they render as plain text or a non-class role), but it touches a central annotation-rendering path with potential regressions. Writing robust tests is non-trivial because it must exercise autodoc output and nitpicky mode behavior across multiple Literal value types and ensure no new unresolved references are introduced.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 105,\n    \"implementation\": 55,\n    \"testing_and_verification\": 80\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:13.751071"}
{"instance_id": "sphinx-doc__sphinx-9673", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "The issue is well-scoped and reproducible, but it sits at the intersection of autodoc\u2019s type-hint injection and docfield parsing, with an integration wrinkle introduced by napoleon generating a `:returns:` field internally. An engineer will need to trace how `autodoc_typehints_description_target=\"documented\"` detects whether a return description exists, then adjust the logic to treat `returns` as equivalent to `return` (and ensure no regressions for other field names). Adding/adjusting tests will likely require creating a small Sphinx build fixture enabling napoleon and asserting the rendered output includes the return type in the expected place.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 45, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is well-scoped and reproducible, but it sits at the intersection of autodoc\u2019s type-hint injection and docfield parsing, with an integration wrinkle introduced by napoleon generating a `:returns:` field internally. An engineer will need to trace how `autodoc_typehints_description_target=\\\"documented\\\"` detects whether a return description exists, then adjust the logic to treat `returns` as equivalent to `return` (and ensure no regressions for other field names). Adding/adjusting tests will likely require creating a small Sphinx build fixture enabling napoleon and asserting the rendered output includes the return type in the expected place.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 45,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:13.810011"}
{"instance_id": "sphinx-doc__sphinx-9711", "repo": "sphinx-doc/sphinx", "estimated_minutes": 150.0, "justification": "The bug is clearly reproducible and likely localized to the code path that validates `needs_extensions` by comparing version strings lexicographically instead of semver-aware ordering. Fixing it should be straightforward (switching to a proper version parser such as `packaging.version.Version` and ensuring consistent behavior across Sphinx), but it requires moderate repository investigation to find the exact comparison logic and confirm no other callers rely on string ordering. Additional time is needed to add regression tests covering multi-digit components (e.g., 0.10 vs 0.6), run the full test suite, and verify no compatibility issues with unusual version strings.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The bug is clearly reproducible and likely localized to the code path that validates `needs_extensions` by comparing version strings lexicographically instead of semver-aware ordering. Fixing it should be straightforward (switching to a proper version parser such as `packaging.version.Version` and ensuring consistent behavior across Sphinx), but it requires moderate repository investigation to find the exact comparison logic and confirm no other callers rely on string ordering. Additional time is needed to add regression tests covering multi-digit components (e.g., 0.10 vs 0.6), run the full test suite, and verify no compatibility issues with unusual version strings.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:13.906485"}
{"instance_id": "sympy__sympy-12481", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "This requires investigating the current Permutation constructor logic to find where non-disjoint cycle inputs are rejected and how cycle-based construction is expected to behave elsewhere in SymPy. The fix is conceptually straightforward (compose cycles left-to-right rather than enforcing disjointness), but it may interact with existing assumptions about cycle notation, size inference, and canonicalization. Proper regression tests are needed for overlapping cycles, repeated cycles, and ordering semantics, and the engineer should run a focused test suite to ensure no behavior changes for existing disjoint-cycle inputs.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This requires investigating the current Permutation constructor logic to find where non-disjoint cycle inputs are rejected and how cycle-based construction is expected to behave elsewhere in SymPy. The fix is conceptually straightforward (compose cycles left-to-right rather than enforcing disjointness), but it may interact with existing assumptions about cycle notation, size inference, and canonicalization. Proper regression tests are needed for overlapping cycles, repeated cycles, and ordering semantics, and the engineer should run a focused test suite to ensure no behavior changes for existing disjoint-cycle inputs.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:14.143387"}
{"instance_id": "sphinx-doc__sphinx-8721", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "This issue likely stems from how sphinx.ext.viewcode registers/generated \u201cviewcode\u201d module documents into the environment in a way that persists across subsequent builds (e.g., when running separate html then epub builds that reuse the pickled environment). Fixing it will require investigating the extension\u2019s event hooks and how/when it adds documents so that epub builds can reliably exclude them when viewcode_enable_epub is False, even if a previous html build generated them. Writing a regression test is moderately involved because it must reproduce the multi-target build behavior (html then epub) and assert that no viewcode pages end up in the epub output without breaking normal html behavior.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This issue likely stems from how sphinx.ext.viewcode registers/generated \u201cviewcode\u201d module documents into the environment in a way that persists across subsequent builds (e.g., when running separate html then epub builds that reuse the pickled environment). Fixing it will require investigating the extension\u2019s event hooks and how/when it adds documents so that epub builds can reliably exclude them when viewcode_enable_epub is False, even if a previous html build generated them. Writing a regression test is moderately involved because it must reproduce the multi-target build behavior (html then epub) and assert that no viewcode pages end up in the epub output without breaking normal html behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:14.675293"}
{"instance_id": "sphinx-doc__sphinx-9591", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "This bug is reproducible but likely sits at the intersection of autodoc\u2019s property handling and the Python domain\u2019s annotation-to-crossref conversion pipeline. An engineer will need to trace how `@property` members are documented (often via a specialized documenter) and where type annotations are rendered as plain text instead of producing `pending_xref` nodes. The fix is probably localized but requires careful alignment with existing annotation parsing utilities and adding a regression test that asserts real cross-reference resolution in built output.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This bug is reproducible but likely sits at the intersection of autodoc\u2019s property handling and the Python domain\u2019s annotation-to-crossref conversion pipeline. An engineer will need to trace how `@property` members are documented (often via a specialized documenter) and where type annotations are rendered as plain text instead of producing `pending_xref` nodes. The fix is probably localized but requires careful alignment with existing annotation parsing utilities and adding a regression test that asserts real cross-reference resolution in built output.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:14.709044"}
{"instance_id": "sphinx-doc__sphinx-9281", "repo": "sphinx-doc/sphinx", "estimated_minutes": 180.0, "justification": "Fixing this likely requires tracing how autodoc converts default argument values into rendered signature text (typically via repr()), then adding a targeted special-case for enum.Enum members to use a cleaner representation (e.g., str() or a custom formatter). While the behavioral change is small, it touches Sphinx\u2019s signature/stringification utilities and must avoid regressions for other default-value types. Writing a focused regression test that exercises autodoc output rendering for an Enum default and validating it across builders adds non-trivial but manageable effort.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this likely requires tracing how autodoc converts default argument values into rendered signature text (typically via repr()), then adding a targeted special-case for enum.Enum members to use a cleaner representation (e.g., str() or a custom formatter). While the behavioral change is small, it touches Sphinx\u2019s signature/stringification utilities and must avoid regressions for other default-value types. Writing a focused regression test that exercises autodoc output rendering for an Enum default and validating it across builders adds non-trivial but manageable effort.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:15.664567"}
{"instance_id": "sympy__sympy-12489", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "Fixing this requires understanding SymPy's custom object construction pattern in `Permutation.__new__` and how `_af_new` is used across different construction pathways, then converting it to a `classmethod` without breaking existing call sites. Although the change itself is conceptually small (use `cls` instead of a hard-coded `Permutation` reference in `Basic.__new__`), it risks subtle regressions if other internals depend on the current behavior or if `_af_new` is referenced as a function pointer. Writing a focused regression test for subclassing and running the relevant combinatorics test suite (and possibly a broader subset) adds a meaningful amount of time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 35, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing this requires understanding SymPy's custom object construction pattern in `Permutation.__new__` and how `_af_new` is used across different construction pathways, then converting it to a `classmethod` without breaking existing call sites. Although the change itself is conceptually small (use `cls` instead of a hard-coded `Permutation` reference in `Basic.__new__`), it risks subtle regressions if other internals depend on the current behavior or if `_af_new` is referenced as a function pointer. Writing a focused regression test for subclassing and running the relevant combinatorics test suite (and possibly a broader subset) adds a meaningful amount of time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 35,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:16.201296"}
{"instance_id": "sympy__sympy-13480", "repo": "sympy/sympy", "estimated_minutes": 45.0, "justification": "The issue is clearly reproducible and the hint points to a specific typo in a single file, so the debugging and implementation are straightforward. However, an experienced engineer will still spend time confirming the failure mode, understanding the relevant eval path in SymPy's hyperbolic function implementation, and adding a regression test that covers the failing substitution cases. Running the appropriate subset of SymPy's test suite and ensuring no related simplification/substitution behavior regresses adds some verification overhead.", "time_breakdown": {"understanding_and_investigation": 20, "implementation": 5, "testing_and_verification": 20}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "1", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 45,\n  \"justification\": \"The issue is clearly reproducible and the hint points to a specific typo in a single file, so the debugging and implementation are straightforward. However, an experienced engineer will still spend time confirming the failure mode, understanding the relevant eval path in SymPy's hyperbolic function implementation, and adding a regression test that covers the failing substitution cases. Running the appropriate subset of SymPy's test suite and ensuring no related simplification/substitution behavior regresses adds some verification overhead.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 20,\n    \"implementation\": 5,\n    \"testing_and_verification\": 20\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "15 min - 1 hour", "processed_at": "2026-01-23T17:48:17.122960"}
{"instance_id": "sympy__sympy-12419", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "Although the issue has a clear reproducer, the incorrect result emerges from an interaction between matrix element access for symbolic indices (e.g., Identity._entry) and SymPy's summation/denesting logic, which typically requires some tracing through matrix-expressions internals to confirm the right fix. Implementing the fix is likely small (e.g., returning KroneckerDelta or a Piecewise/Relational-based form instead of assuming i!=j), but ensuring it doesn\u2019t regress other matrix indexing and simplification behavior requires careful test coverage. Additional time is needed to validate behavior for both nested Sum forms and the multi-limit Sum form, and to run relevant SymPy test subsets.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 35, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the issue has a clear reproducer, the incorrect result emerges from an interaction between matrix element access for symbolic indices (e.g., Identity._entry) and SymPy's summation/denesting logic, which typically requires some tracing through matrix-expressions internals to confirm the right fix. Implementing the fix is likely small (e.g., returning KroneckerDelta or a Piecewise/Relational-based form instead of assuming i!=j), but ensuring it doesn\u2019t regress other matrix indexing and simplification behavior requires careful test coverage. Additional time is needed to validate behavior for both nested Sum forms and the multi-limit Sum form, and to run relevant SymPy test subsets.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 35,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:17.989002"}
{"instance_id": "sympy__sympy-12096", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "Although the symptom is clear and localized to `Function._eval_evalf`, fixing it correctly requires understanding SymPy's evalf protocol (precision propagation, `subs`/`_eval_evalf` interactions) and how implemented functions store and invoke `_imp_`. The implementation is likely small (ensuring the `_imp_` result is evalf'd recursively with the correct precision/context), but writing robust regression tests for composed implemented functions and verifying precision-sensitive behavior will take additional time. Running and interpreting relevant parts of SymPy\u2019s test suite to ensure no regressions (especially around evalf and lambdify) contributes meaningful overhead.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 40, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the symptom is clear and localized to `Function._eval_evalf`, fixing it correctly requires understanding SymPy's evalf protocol (precision propagation, `subs`/`_eval_evalf` interactions) and how implemented functions store and invoke `_imp_`. The implementation is likely small (ensuring the `_imp_` result is evalf'd recursively with the correct precision/context), but writing robust regression tests for composed implemented functions and verifying precision-sensitive behavior will take additional time. Running and interpreting relevant parts of SymPy\u2019s test suite to ensure no regressions (especially around evalf and lambdify) contributes meaningful overhead.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 40,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:18.664528"}
{"instance_id": "sympy__sympy-13091", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "Although the core change may be a one-liner (returning NotImplemented instead of False), an engineer will need to audit SymPy's rich comparison implementations to ensure consistent behavior across Basic and key subclasses without breaking existing comparison semantics. The biggest time cost is validating test-suite impact and adding targeted tests for symmetric delegation to reflected methods (custom non-SymPy classes) across == and ordering comparisons. Some iteration is likely if changing Basic.__eq__/__ne__ affects assumptions in existing tests or canonicalization logic.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the core change may be a one-liner (returning NotImplemented instead of False), an engineer will need to audit SymPy's rich comparison implementations to ensure consistent behavior across Basic and key subclasses without breaking existing comparison semantics. The biggest time cost is validating test-suite impact and adding targeted tests for symmetric delegation to reflected methods (custom non-SymPy classes) across == and ordering comparisons. Some iteration is likely if changing Basic.__eq__/__ne__ affects assumptions in existing tests or canonicalization logic.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:18.920362"}
{"instance_id": "sympy__sympy-13031", "repo": "sympy/sympy", "estimated_minutes": 210.0, "justification": "Although the bug is easy to reproduce, fixing it correctly requires understanding SymPy's matrix stacking/joining dispatch (e.g., how hstack/vstack call row_join/col_join and how class promotion works between DenseMatrix and SparseMatrix). The hints indicate the current behavior is entangled with API/design issues (SparseMatrix implementing col_join directly vs. _eval_col_join), which increases investigation and debugging time. A proper fix also needs targeted regression tests for multiple zero-dimension edge cases across SparseMatrix and interactions with DenseMatrix.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the bug is easy to reproduce, fixing it correctly requires understanding SymPy's matrix stacking/joining dispatch (e.g., how hstack/vstack call row_join/col_join and how class promotion works between DenseMatrix and SparseMatrix). The hints indicate the current behavior is entangled with API/design issues (SparseMatrix implementing col_join directly vs. _eval_col_join), which increases investigation and debugging time. A proper fix also needs targeted regression tests for multiple zero-dimension edge cases across SparseMatrix and interactions with DenseMatrix.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:19.818448"}
{"instance_id": "sympy__sympy-13757", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible but requires understanding SymPy's interaction between core expression multiplication (Mul/Expr) and Poly's special arithmetic hooks (__mul__/__rmul__), including how coercion and evaluation are triggered. Fixing it likely involves adjusting Poly's reverse-multiplication behavior (and possibly assumptions about when to return an Expr vs a Poly), which requires careful handling to avoid breaking existing polynomial/expr mixing semantics. Adding regression tests is straightforward but needs coverage for both Python ints vs SymPy Integers and for left/right operand order to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 45, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible but requires understanding SymPy's interaction between core expression multiplication (Mul/Expr) and Poly's special arithmetic hooks (__mul__/__rmul__), including how coercion and evaluation are triggered. Fixing it likely involves adjusting Poly's reverse-multiplication behavior (and possibly assumptions about when to return an Expr vs a Poly), which requires careful handling to avoid breaking existing polynomial/expr mixing semantics. Adding regression tests is straightforward but needs coverage for both Python ints vs SymPy Integers and for left/right operand order to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 45,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:20.296478"}
{"instance_id": "sympy__sympy-13372", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "Although the failure is easy to reproduce, fixing it correctly requires understanding evalf's internal tuple/precision conventions (e.g., what reprec/imprec = None means) and why argument order in evalf_mul exposes the bug. The code change itself is likely small (adding a missing else-path or raising), but choosing the right behavior needs some investigation and may require adjusting related logic to avoid new regressions. Proper coverage needs at least one focused regression test plus running relevant portions of SymPy's test suite to ensure no other evalf pathways are impacted.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the failure is easy to reproduce, fixing it correctly requires understanding evalf's internal tuple/precision conventions (e.g., what reprec/imprec = None means) and why argument order in evalf_mul exposes the bug. The code change itself is likely small (adding a missing else-path or raising), but choosing the right behavior needs some investigation and may require adjusting related logic to avoid new regressions. Proper coverage needs at least one focused regression test plus running relevant portions of SymPy's test suite to ensure no other evalf pathways are impacted.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:20.571866"}
{"instance_id": "sphinx-doc__sphinx-9229", "repo": "sphinx-doc/sphinx", "estimated_minutes": 210.0, "justification": "Although the issue has clear reproduction steps, the root cause likely sits in Sphinx autodoc\u2019s object classification and docstring retrieval logic for \u201ctype alias\u201d-like assignments, where Sphinx sometimes emits the default \u201calias of \u2026\u201d text and sometimes uses extracted variable doc comments. An engineer will need to trace how module-level assignment docstrings are discovered (via the analyzer) and how that information is merged/overridden when autodoc decides an object is an alias. Implementing a fix should be localized but requires care to avoid regressions in other alias/documenter behaviors, plus adding a focused regression test that builds docs and asserts the rendered output.", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 55, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the issue has clear reproduction steps, the root cause likely sits in Sphinx autodoc\u2019s object classification and docstring retrieval logic for \u201ctype alias\u201d-like assignments, where Sphinx sometimes emits the default \u201calias of \u2026\u201d text and sometimes uses extracted variable doc comments. An engineer will need to trace how module-level assignment docstrings are discovered (via the analyzer) and how that information is merged/overridden when autodoc decides an object is an alias. Implementing a fix should be localized but requires care to avoid regressions in other alias/documenter behaviors, plus adding a focused regression test that builds docs and asserts the rendered output.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 55,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:20.627578"}
{"instance_id": "sphinx-doc__sphinx-8638", "repo": "sphinx-doc/sphinx", "estimated_minutes": 300.0, "justification": "Fixing this requires reproducing the behavior in a controlled Sphinx test build and then tracing how Python-domain cross-reference resolution and/or autosummary/autodoc link generation decides which target to link for an attribute name. The bug is subtle because it depends on context (module/class scope), object inventories, and Sphinx\u2019s \u201cfuzzy\u201d resolution heuristics when unqualified names collide, so investigation time is significant. The implementation will likely involve ensuring that generated references for class/instance attributes are qualified (or that resolution prefers the current class/module scope), followed by adding a regression test that proves the correct target is chosen across packages and classes.", "time_breakdown": {"understanding_and_investigation": 140, "implementation": 90, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 300,\n  \"justification\": \"Fixing this requires reproducing the behavior in a controlled Sphinx test build and then tracing how Python-domain cross-reference resolution and/or autosummary/autodoc link generation decides which target to link for an attribute name. The bug is subtle because it depends on context (module/class scope), object inventories, and Sphinx\u2019s \u201cfuzzy\u201d resolution heuristics when unqualified names collide, so investigation time is significant. The implementation will likely involve ensuring that generated references for class/instance attributes are qualified (or that resolution prefers the current class/module scope), followed by adding a regression test that proves the correct target is chosen across packages and classes.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 140,\n    \"implementation\": 90,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:20.755851"}
{"instance_id": "sphinx-doc__sphinx-9658", "repo": "sphinx-doc/sphinx", "estimated_minutes": 240.0, "justification": "Although the symptom is clear (truncated base class name in the rendered \"Bases\" line when the base comes from a mocked import), pinpointing the exact formatting path in Sphinx requires non-trivial investigation across autodoc\u2019s mocking/import and type/identifier rendering utilities. The fix is likely localized (adjusting how mocked base classes are represented or how base-class names are extracted/qualified), but it must be done carefully to avoid regressions in normal (non-mocked) inheritance, intersphinx links, and older behaviors. Adding a reliable regression test will also take time because it must simulate mocked third-party modules and verify the produced reST/HTML output consistently across environments.", "time_breakdown": {"understanding_and_investigation": 110, "implementation": 60, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Although the symptom is clear (truncated base class name in the rendered \\\"Bases\\\" line when the base comes from a mocked import), pinpointing the exact formatting path in Sphinx requires non-trivial investigation across autodoc\u2019s mocking/import and type/identifier rendering utilities. The fix is likely localized (adjusting how mocked base classes are represented or how base-class names are extracted/qualified), but it must be done carefully to avoid regressions in normal (non-mocked) inheritance, intersphinx links, and older behaviors. Adding a reliable regression test will also take time because it must simulate mocked third-party modules and verify the produced reST/HTML output consistently across environments.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 110,\n    \"implementation\": 60,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:20.961475"}
{"instance_id": "sympy__sympy-13647", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and points to a likely culprit in sympy/matrices/common.py, but an engineer will still need time to trace how col_insert is implemented across different Matrix classes after the matrix refactor. The fix is likely small (an indexing/position variable misuse), yet it must be validated across multiple matrix representations and edge cases (insertion at beginning/end, symbolic sizes, immutable matrices). Adding/regressing tests and running the relevant matrix test suite will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and points to a likely culprit in sympy/matrices/common.py, but an engineer will still need time to trace how col_insert is implemented across different Matrix classes after the matrix refactor. The fix is likely small (an indexing/position variable misuse), yet it must be validated across multiple matrix representations and edge cases (insertion at beginning/end, symbolic sizes, immutable matrices). Adding/regressing tests and running the relevant matrix test suite will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:21.342036"}
{"instance_id": "sympy__sympy-11618", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible but requires investigating SymPy's geometry point classes (Point/Point2D/Point3D) to confirm intended semantics when computing distances between points of differing dimensions. The likely fix involves adjusting the distance calculation to avoid truncation from Python's zip (e.g., padding missing coordinates or explicitly handling dimension mismatch) and ensuring consistent behavior across related geometry APIs. Adding focused unit tests and running the relevant SymPy test suite subset to prevent regressions will take a substantial portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible but requires investigating SymPy's geometry point classes (Point/Point2D/Point3D) to confirm intended semantics when computing distances between points of differing dimensions. The likely fix involves adjusting the distance calculation to avoid truncation from Python's zip (e.g., padding missing coordinates or explicitly handling dimension mismatch) and ensuring consistent behavior across related geometry APIs. Adding focused unit tests and running the relevant SymPy test suite subset to prevent regressions will take a substantial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:21.345900"}
{"instance_id": "sympy__sympy-13878", "repo": "sympy/sympy", "estimated_minutes": 600.0, "justification": "This issue requires adding explicit `_cdf` implementations for a fairly large set of continuous distributions (about a dozen), each needing correct symbolic formulas (often involving Piecewise logic and special functions like lowergamma/uppergamma/hypergeometric) and ensuring they behave well under SymPy assumptions. An experienced engineer will need time to study SymPy Stats\u2019 existing CDF/PDF architecture, mirror established patterns (e.g., Normal/Uniform), and carefully handle edge cases to avoid hangs or incorrect integrals. Substantial testing is needed to ensure symbolic correctness (differentiate CDF vs PDF), avoid unintended floats, and verify numeric evaluation across representative parameter choices.", "time_breakdown": {"understanding_and_investigation": 150, "implementation": 300, "testing_and_verification": 150}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "4-6", "testing_complexity": "complex", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 600,\n  \"justification\": \"This issue requires adding explicit `_cdf` implementations for a fairly large set of continuous distributions (about a dozen), each needing correct symbolic formulas (often involving Piecewise logic and special functions like lowergamma/uppergamma/hypergeometric) and ensuring they behave well under SymPy assumptions. An experienced engineer will need time to study SymPy Stats\u2019 existing CDF/PDF architecture, mirror established patterns (e.g., Normal/Uniform), and carefully handle edge cases to avoid hangs or incorrect integrals. Substantial testing is needed to ensure symbolic correctness (differentiate CDF vs PDF), avoid unintended floats, and verify numeric evaluation across representative parameter choices.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 150,\n    \"implementation\": 300,\n    \"testing_and_verification\": 150\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"4-6\",\n    \"testing_complexity\": \"complex\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": ">4 hours", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:22.504701"}
{"instance_id": "sympy__sympy-13798", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "This change is conceptually small (allowing `mul_symbol` to accept an arbitrary LaTeX string when it is not one of the predefined keys), but it requires moderate investigation to ensure the option is threaded consistently through the LaTeX printer and doesn\u2019t affect other formatting rules. Implementation will likely involve a localized modification in the LaTeX printing options/mapping logic plus small documentation/comment updates. Tests are needed to cover both the existing four symbolic choices (to ensure no regression) and the new behavior (e.g., `mul_symbol='\\\\,'` and possibly edge cases like empty string).", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"This change is conceptually small (allowing `mul_symbol` to accept an arbitrary LaTeX string when it is not one of the predefined keys), but it requires moderate investigation to ensure the option is threaded consistently through the LaTeX printer and doesn\u2019t affect other formatting rules. Implementation will likely involve a localized modification in the LaTeX printing options/mapping logic plus small documentation/comment updates. Tests are needed to cover both the existing four symbolic choices (to ensure no regression) and the new behavior (e.g., `mul_symbol='\\\\\\\\,'` and possibly edge cases like empty string).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:24.357155"}
{"instance_id": "sympy__sympy-13852", "repo": "sympy/sympy", "estimated_minutes": 210.0, "justification": "This issue likely requires understanding SymPy\u2019s existing `polylog` implementation and its branch-cut handling, especially why `expand_func(polylog(1, z))` introduces `exp_polar` and how to remove/adjust it without changing analytic behavior. Adding a closed-form evaluation for `polylog(2, Rational(1, 2))` is conceptually straightforward but must be implemented in the right evaluation/rewriting pathway and validated against SymPy\u2019s conventions. Ensuring derivatives/simplification remain consistent and adding robust tests around expansion and known special values will take substantial verification time to avoid subtle regressions.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This issue likely requires understanding SymPy\u2019s existing `polylog` implementation and its branch-cut handling, especially why `expand_func(polylog(1, z))` introduces `exp_polar` and how to remove/adjust it without changing analytic behavior. Adding a closed-form evaluation for `polylog(2, Rational(1, 2))` is conceptually straightforward but must be implemented in the right evaluation/rewriting pathway and validated against SymPy\u2019s conventions. Ensuring derivatives/simplification remain consistent and adding robust tests around expansion and known special values will take substantial verification time to avoid subtle regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:24.627045"}
{"instance_id": "sympy__sympy-14248", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible but requires investigating SymPy's matrix expression classes (e.g., MatAdd/MatMul) and how the string/pretty/latex printers handle negative coefficients for non-commutative matrix terms. The fix will likely involve adjusting printer logic to treat \"(-1)*X\" as \"-X\" and to format MatAdd as subtraction where appropriate, mirroring scalar Add printing behavior. Time is mainly spent ensuring consistent behavior across multiple printers and adding regression tests to avoid formatting regressions for other matrix expressions.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible but requires investigating SymPy's matrix expression classes (e.g., MatAdd/MatMul) and how the string/pretty/latex printers handle negative coefficients for non-commutative matrix terms. The fix will likely involve adjusting printer logic to treat \\\"(-1)*X\\\" as \\\"-X\\\" and to format MatAdd as subtraction where appropriate, mirroring scalar Add printing behavior. Time is mainly spent ensuring consistent behavior across multiple printers and adding regression tests to avoid formatting regressions for other matrix expressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:25.551365"}
{"instance_id": "sympy__sympy-15349", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "The issue is reproducible and likely stems from a sign/convention error in the quaternion-to-rotation-matrix formula, but confirming the intended rotation convention (active vs. passive, right- vs. left-handed, multiplication order) requires careful code and doc investigation. The code change itself is probably small (fixing a couple of matrix entries), but it needs validation against standard axis-angle cases and must not break any existing expectations in SymPy. Writing robust tests for multiple axes/angles and running the relevant test suite to ensure no regressions will take a significant portion of the work.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 30, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is reproducible and likely stems from a sign/convention error in the quaternion-to-rotation-matrix formula, but confirming the intended rotation convention (active vs. passive, right- vs. left-handed, multiplication order) requires careful code and doc investigation. The code change itself is probably small (fixing a couple of matrix entries), but it needs validation against standard axis-angle cases and must not break any existing expectations in SymPy. Writing robust tests for multiple axes/angles and running the relevant test suite to ensure no regressions will take a significant portion of the work.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 30,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:27.065483"}
{"instance_id": "sympy__sympy-13877", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "The issue is reproducible but the root cause spans multiple layers: matrix determinant computation (Bareiss), simplification/cancellation, and a failure path inside factor_terms that triggers an invalid NaN comparison. An experienced engineer will need time to trace where the 0/0-style intermediate arises, decide whether to adjust Bareiss pivoting/zero-detection or make factor_terms more robust (or introduce a safe fallback), and ensure the chosen fix doesn\u2019t change determinant semantics or performance broadly. Writing regression tests is non-trivial because it must cover both the specific matrix family and ensure no new NaN/TypeError occurs across determinant methods.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 50, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is reproducible but the root cause spans multiple layers: matrix determinant computation (Bareiss), simplification/cancellation, and a failure path inside factor_terms that triggers an invalid NaN comparison. An experienced engineer will need time to trace where the 0/0-style intermediate arises, decide whether to adjust Bareiss pivoting/zero-detection or make factor_terms more robust (or introduce a safe fallback), and ensure the chosen fix doesn\u2019t change determinant semantics or performance broadly. Writing regression tests is non-trivial because it must cover both the specific matrix family and ensure no new NaN/TypeError occurs across determinant methods.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 50,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:27.233888"}
{"instance_id": "sympy__sympy-13974", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is well-scoped and has clear reproduction steps plus a concrete implementation hint: add proper handling for `Pow` in `tensor_product_simp` so that `(TensorProduct(...))**n` simplifies to `TensorProduct(arg**n, ...)`. An experienced engineer will still need moderate time to inspect how `tensor_product_simp` dispatches on expression types, ensure the rewrite is mathematically valid for relevant exponent types (especially integer vs symbolic/negative), and align with SymPy\u2019s canonicalization rules. Writing targeted tests for the provided examples and a few edge cases, then running the relevant SymPy test suite, constitutes a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 35, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-scoped and has clear reproduction steps plus a concrete implementation hint: add proper handling for `Pow` in `tensor_product_simp` so that `(TensorProduct(...))**n` simplifies to `TensorProduct(arg**n, ...)`. An experienced engineer will still need moderate time to inspect how `tensor_product_simp` dispatches on expression types, ensure the rewrite is mathematically valid for relevant exponent types (especially integer vs symbolic/negative), and align with SymPy\u2019s canonicalization rules. Writing targeted tests for the provided examples and a few edge cases, then running the relevant SymPy test suite, constitutes a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 35,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:27.364613"}
{"instance_id": "sympy__sympy-14711", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and likely stems from Python's built-in sum() starting with an integer 0, causing Vector.__radd__/__add__ to reject the non-Vector operand. Fixing it should be localized to the vector addition logic (e.g., treating 0 as an additive identity), but requires careful review to ensure it matches existing SymPy conventions and does not mask genuine type errors. Adding focused tests for sum() behavior and a couple of related edge cases (e.g., start=0, empty sums) plus running the relevant test suite makes this a moderate, well-bounded change.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 35, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and likely stems from Python's built-in sum() starting with an integer 0, causing Vector.__radd__/__add__ to reject the non-Vector operand. Fixing it should be localized to the vector addition logic (e.g., treating 0 as an additive identity), but requires careful review to ensure it matches existing SymPy conventions and does not mask genuine type errors. Adding focused tests for sum() behavior and a couple of related edge cases (e.g., start=0, empty sums) plus running the relevant test suite makes this a moderate, well-bounded change.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 35,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:27.479317"}
{"instance_id": "sympy__sympy-15017", "repo": "sympy/sympy", "estimated_minutes": 90.0, "justification": "The issue is clearly reproducible but requires investigating SymPy's intended semantics for rank-0 arrays (scalar NDimArray) and how iteration, shape, and size are defined across dense/sparse array implementations. The actual fix is likely small (adjusting NDimArray.__len__ to return the number of elements for rank-0 arrays rather than 0), but care is needed to avoid breaking existing behavior for higher-rank arrays and to ensure consistency with other array methods (e.g., iteration and reshape). Writing targeted unit tests for scalar arrays and running the relevant tensor/array test suite adds non-trivial verification time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 20, "testing_and_verification": 35}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clearly reproducible but requires investigating SymPy's intended semantics for rank-0 arrays (scalar NDimArray) and how iteration, shape, and size are defined across dense/sparse array implementations. The actual fix is likely small (adjusting NDimArray.__len__ to return the number of elements for rank-0 arrays rather than 0), but care is needed to avoid breaking existing behavior for higher-rank arrays and to ensure consistency with other array methods (e.g., iteration and reshape). Writing targeted unit tests for scalar arrays and running the relevant tensor/array test suite adds non-trivial verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 20,\n    \"testing_and_verification\": 35\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:28.244173"}
{"instance_id": "sympy__sympy-15875", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "The issue is reproducible but likely originates from subtle assumption logic in `Add._eval_is_zero` (or related handlers) where cancellation across terms can make `is_zero` return an unsound `False` instead of `None`. An engineer will need to trace assumption evaluation for complex terms (especially Gaussian integers and expanded powers) and determine when the code is making an invalid nonzero inference. The fix should be relatively localized (core assumptions for `Add`) but requires carefully chosen tests to ensure `is_zero` never returns an incorrect boolean and does not regress performance or other assumption cases.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 55, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is reproducible but likely originates from subtle assumption logic in `Add._eval_is_zero` (or related handlers) where cancellation across terms can make `is_zero` return an unsound `False` instead of `None`. An engineer will need to trace assumption evaluation for complex terms (especially Gaussian integers and expanded powers) and determine when the code is making an invalid nonzero inference. The fix should be relatively localized (core assumptions for `Add`) but requires carefully chosen tests to ensure `is_zero` never returns an incorrect boolean and does not regress performance or other assumption cases.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 55,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:30.029977"}
{"instance_id": "sympy__sympy-13615", "repo": "sympy/sympy", "estimated_minutes": 210.0, "justification": "This issue likely stems from incorrect simplification in set membership/containment logic (e.g., `Set.contains` returning `True` for symbolic elements) which causes `Complement` to eagerly drop symbolic elements from a `FiniteSet`. Fixing it requires tracing how `Complement` delegates to difference/contains across multiple set types (Interval, ComplexRegion, FiniteSet) and ensuring the result remains unevaluated when membership is indeterminate. The change must be validated against multiple reported edge cases and requires adding regression tests to prevent future overly-aggressive boolean evaluation.", "time_breakdown": {"understanding_and_investigation": 95, "implementation": 65, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "extensive", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This issue likely stems from incorrect simplification in set membership/containment logic (e.g., `Set.contains` returning `True` for symbolic elements) which causes `Complement` to eagerly drop symbolic elements from a `FiniteSet`. Fixing it requires tracing how `Complement` delegates to difference/contains across multiple set types (Interval, ComplexRegion, FiniteSet) and ensuring the result remains unevaluated when membership is indeterminate. The change must be validated against multiple reported edge cases and requires adding regression tests to prevent future overly-aggressive boolean evaluation.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 95,\n    \"implementation\": 65,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"extensive\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:30.040331"}
{"instance_id": "sympy__sympy-15976", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "Although the symptom is clear (symbols ending with digits are wrapped as `<mi><msub>...</msub></mi>` in presentation MathML), the engineer will need to trace how SymPy\u2019s MathML presentation printer decides to split symbol names into base/subscript and how it wraps identifier nodes. The likely fix is localized (adjusting the Symbol printing logic to avoid invalid/undesired nesting when the produced node is already an `<msub>`/`<msup>` structure), but it must be done carefully to avoid breaking other MathML outputs and naming edge-cases (multiple digits, underscores, Greek names, etc.). Proper regression tests should be added to assert the exact generated MathML tree/string for representative symbols and expressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the symptom is clear (symbols ending with digits are wrapped as `<mi><msub>...</msub></mi>` in presentation MathML), the engineer will need to trace how SymPy\u2019s MathML presentation printer decides to split symbol names into base/subscript and how it wraps identifier nodes. The likely fix is localized (adjusting the Symbol printing logic to avoid invalid/undesired nesting when the produced node is already an `<msub>`/`<msup>` structure), but it must be done carefully to avoid breaking other MathML outputs and naming edge-cases (multiple digits, underscores, Greek names, etc.). Proper regression tests should be added to assert the exact generated MathML tree/string for representative symbols and expressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:31.470006"}
{"instance_id": "sphinx-doc__sphinx-8621", "repo": "sphinx-doc/sphinx", "estimated_minutes": 150.0, "justification": "The issue is well-reproduced and likely isolated to the parsing logic used by Sphinx\u2019s :kbd: role, which currently splits on separator characters too simplistically. Fixing it requires implementing a slightly smarter tokenizer that treats '-', '+', and '^' as separators only when they appear between two non-empty keystroke tokens, while preserving them as literal keystrokes at the start/end (or otherwise not flanked). The change should be contained but needs careful regression tests across HTML output and a quick sweep for related edge cases to avoid breaking existing :kbd: behavior.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 60, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-reproduced and likely isolated to the parsing logic used by Sphinx\u2019s :kbd: role, which currently splits on separator characters too simplistically. Fixing it requires implementing a slightly smarter tokenizer that treats '-', '+', and '^' as separators only when they appear between two non-empty keystroke tokens, while preserving them as literal keystrokes at the start/end (or otherwise not flanked). The change should be contained but needs careful regression tests across HTML output and a quick sweep for related edge cases to avoid breaking existing :kbd: behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 60,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:31.939112"}
{"instance_id": "sympy__sympy-16766", "repo": "sympy/sympy", "estimated_minutes": 90.0, "justification": "Although the fix is conceptually straightforward (add a `_print_Indexed` method), an engineer will need time to inspect existing SymPy printer conventions (e.g., how `IndexedBase`, `Idx`, and other subscript-like constructs are printed) to ensure consistent behavior and avoid breaking existing output expectations. Writing and placing targeted tests in the correct printing test suite, plus running the relevant test subset (and possibly full printing tests), will take a significant fraction of the time. The change is localized but needs verification for multi-index cases and interaction with `lambdify`/`pycode` output formatting.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 20, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"Although the fix is conceptually straightforward (add a `_print_Indexed` method), an engineer will need time to inspect existing SymPy printer conventions (e.g., how `IndexedBase`, `Idx`, and other subscript-like constructs are printed) to ensure consistent behavior and avoid breaking existing output expectations. Writing and placing targeted tests in the correct printing test suite, plus running the relevant test subset (and possibly full printing tests), will take a significant fraction of the time. The change is localized but needs verification for multi-index cases and interaction with `lambdify`/`pycode` output formatting.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 20,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:32.349871"}
{"instance_id": "sympy__sympy-16886", "repo": "sympy/sympy", "estimated_minutes": 45.0, "justification": "The issue is clearly defined and likely requires a small change to a Morse-code mapping table in `sympy.crypto.crypto`. Even though the code fix is probably a one-line edit, a contributor still needs to locate the mapping usage, confirm there are no other related tables (encode vs decode), and ensure the change doesn't break round-trip behavior. Adding/updating a targeted unit test and running the relevant test suite will take a meaningful fraction of the time.", "time_breakdown": {"understanding_and_investigation": 15, "implementation": 10, "testing_and_verification": 20}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "1", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 45,\n  \"justification\": \"The issue is clearly defined and likely requires a small change to a Morse-code mapping table in `sympy.crypto.crypto`. Even though the code fix is probably a one-line edit, a contributor still needs to locate the mapping usage, confirm there are no other related tables (encode vs decode), and ensure the change doesn't break round-trip behavior. Adding/updating a targeted unit test and running the relevant test suite will take a meaningful fraction of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 15,\n    \"implementation\": 10,\n    \"testing_and_verification\": 20\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "15 min - 1 hour", "processed_at": "2026-01-23T17:48:32.501491"}
{"instance_id": "sympy__sympy-15599", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "Although the symptom is simple (Mod(3*i, 2) should become Mod(i, 2)), the correct fix requires careful analysis of Mod\u2019s existing simplification rules to avoid invalid rewrites in cases involving division, non-integer coefficients, and mixed numeric types (e.g., floats). Implementing the change will likely require tightening the conditions under which factors are reduced modulo the modulus (e.g., only safe for integer/rational coefficients with appropriate assumptions), and adding targeted regression tests for the reported case plus edge cases mentioned in the discussion. Running and interpreting SymPy\u2019s relevant test suite to ensure no behavioral regressions (especially around arithmetic/mod simplification) will take a non-trivial amount of time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the symptom is simple (Mod(3*i, 2) should become Mod(i, 2)), the correct fix requires careful analysis of Mod\u2019s existing simplification rules to avoid invalid rewrites in cases involving division, non-integer coefficients, and mixed numeric types (e.g., floats). Implementing the change will likely require tightening the conditions under which factors are reduced modulo the modulus (e.g., only safe for integer/rational coefficients with appropriate assumptions), and adding targeted regression tests for the reported case plus edge cases mentioned in the discussion. Running and interpreting SymPy\u2019s relevant test suite to ensure no behavioral regressions (especially around arithmetic/mod simplification) will take a non-trivial amount of time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:32.569307"}
{"instance_id": "sympy__sympy-16792", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "The issue is clearly reproducible but requires understanding how autowrap/codegen infer C signatures from the expression\u2019s free symbols versus the explicitly provided args, which is subtle in SymPy\u2019s code generation pipeline. The fix will likely involve ensuring argument types are derived from the declared `args` (including MatrixSymbol/array types) even when unused in the expression, and updating the Cython wrapper generation accordingly. Proper regression tests are needed to cover constant expressions with array arguments and to ensure no regressions across other backends or mixed scalar/array signatures.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is clearly reproducible but requires understanding how autowrap/codegen infer C signatures from the expression\u2019s free symbols versus the explicitly provided args, which is subtle in SymPy\u2019s code generation pipeline. The fix will likely involve ensuring argument types are derived from the declared `args` (including MatrixSymbol/array types) even when unused in the expression, and updating the Cython wrapper generation accordingly. Proper regression tests are needed to cover constant expressions with array arguments and to ensure no regressions across other backends or mixed scalar/array signatures.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:32.923645"}
{"instance_id": "sympy__sympy-17318", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "Although the crash is reproducible with a small input, determining the correct fix location requires understanding how sqrtdenest, _sqrt_match, split_surds, and rad_rationalize interact and what their input contracts are. The issue likely needs hardening in split_surds (to safely handle empty/non-surd inputs) and possibly additional guards to prevent infinite recursion in rad_rationalize, plus regression tests for both behaviors. Implementing the fix is not large, but validating it against SymPy\u2019s simplification/rationalization edge cases and running the relevant test suite adds meaningful time.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the crash is reproducible with a small input, determining the correct fix location requires understanding how sqrtdenest, _sqrt_match, split_surds, and rad_rationalize interact and what their input contracts are. The issue likely needs hardening in split_surds (to safely handle empty/non-surd inputs) and possibly additional guards to prevent infinite recursion in rad_rationalize, plus regression tests for both behaviors. Implementing the fix is not large, but validating it against SymPy\u2019s simplification/rationalization edge cases and running the relevant test suite adds meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:34.235115"}
{"instance_id": "sympy__sympy-14976", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "The issue is clearly reproducible but requires investigating SymPy's lambdify code-generation path for the 'mpmath' module to find why Rational constants are emitted as Python numeric literals (e.g., `232/3`) instead of being constructed via mpmath at runtime. The fix likely involves adjusting the mpmath-specific printer or translation table so that `Rational(p, q)` is printed as something like `mp.mpf(p)/q` (or an equivalent mpmath-safe form) to preserve arbitrary precision during evaluation. Proper tests must confirm the generated source and/or numerical behavior (e.g., via nsolve or direct evaluation at high precision) and ensure no regressions for other numeric types or modules.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is clearly reproducible but requires investigating SymPy's lambdify code-generation path for the 'mpmath' module to find why Rational constants are emitted as Python numeric literals (e.g., `232/3`) instead of being constructed via mpmath at runtime. The fix likely involves adjusting the mpmath-specific printer or translation table so that `Rational(p, q)` is printed as something like `mp.mpf(p)/q` (or an equivalent mpmath-safe form) to preserve arbitrary precision during evaluation. Proper tests must confirm the generated source and/or numerical behavior (e.g., via nsolve or direct evaluation at high precision) and ensure no regressions for other numeric types or modules.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:34.237248"}
{"instance_id": "sympy__sympy-15809", "repo": "sympy/sympy", "estimated_minutes": 110.0, "justification": "This change is conceptually simple (returning `oo`/`-oo` for empty `Min()`/`Max()`), but it requires investigating SymPy\u2019s current `Min`/`Max` construction and evaluation logic to ensure the new behavior is consistent with patterns like `Add()`/`Mul()` on empty argument lists. The engineer will need to update the constructor logic (likely in the `__new__` path) without breaking evaluation flags or assumptions elsewhere in the codebase. Proper unit tests must be added to confirm the new return values and guard against regressions, and the relevant test suite portion should be run to validate nothing else depends on the prior `ValueError` behavior.", "time_breakdown": {"understanding_and_investigation": 40, "implementation": 20, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 110,\n  \"justification\": \"This change is conceptually simple (returning `oo`/`-oo` for empty `Min()`/`Max()`), but it requires investigating SymPy\u2019s current `Min`/`Max` construction and evaluation logic to ensure the new behavior is consistent with patterns like `Add()`/`Mul()` on empty argument lists. The engineer will need to update the constructor logic (likely in the `__new__` path) without breaking evaluation flags or assumptions elsewhere in the codebase. Proper unit tests must be added to confirm the new return values and guard against regressions, and the relevant test suite portion should be run to validate nothing else depends on the prior `ValueError` behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 40,\n    \"implementation\": 20,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:34.478670"}
{"instance_id": "sympy__sympy-13551", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "The issue has a clear reproducer and points to a specific suspicious line, but fixing it correctly requires understanding SymPy's Product evaluation heuristics to avoid breaking other simplification paths. The fix will likely involve removing or tightening an invalid transformation (treating a product over an Add as distributive) and potentially adding a targeted closed-form rewrite to q_pochhammer for patterns like \\(\\prod (a + b q^k)\\). Proper regression tests are needed to ensure both the reported examples and related Product behaviors remain correct across symbolic and numeric substitutions.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 75, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue has a clear reproducer and points to a specific suspicious line, but fixing it correctly requires understanding SymPy's Product evaluation heuristics to avoid breaking other simplification paths. The fix will likely involve removing or tightening an invalid transformation (treating a product over an Add as distributive) and potentially adding a targeted closed-form rewrite to q_pochhammer for patterns like \\\\(\\\\prod (a + b q^k)\\\\). Proper regression tests are needed to ensure both the reported examples and related Product behaviors remain correct across symbolic and numeric substitutions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 75,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:34.497140"}
{"instance_id": "sympy__sympy-17139", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue has a clear reproducer and stack trace pointing to a specific conditional in simplify/fu.py that performs an invalid ordering comparison on a complex exponent (I). Fixing it likely involves replacing direct relational comparison (rv.exp < 0) with SymPy\u2019s sign/assumption-based predicates (e.g., is_negative) or guarding against non-real exponents, which is a small code change but requires care to avoid altering simplification behavior for valid real exponents. Proper regression tests should be added to cover complex-exponent cases and to ensure no regressions in trig simplification pathways that use the same rule.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue has a clear reproducer and stack trace pointing to a specific conditional in simplify/fu.py that performs an invalid ordering comparison on a complex exponent (I). Fixing it likely involves replacing direct relational comparison (rv.exp < 0) with SymPy\u2019s sign/assumption-based predicates (e.g., is_negative) or guarding against non-real exponents, which is a small code change but requires care to avoid altering simplification behavior for valid real exponents. Proper regression tests should be added to cover complex-exponent cases and to ensure no regressions in trig simplification pathways that use the same rule.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:34.790727"}
{"instance_id": "sympy__sympy-18189", "repo": "sympy/sympy", "estimated_minutes": 75.0, "justification": "The issue is clearly reproducible and the hint points directly to a likely root cause: a recursive call to `diophantine` that drops the `permute` argument when `syms` are reordered. Implementing the fix is a small, localized change, but SymPy requires adding a regression test and running relevant solver/diophantine tests to ensure no behavioral regressions. Most of the time will be spent confirming expected solution sets across symbol orderings and validating the change against existing test coverage.", "time_breakdown": {"understanding_and_investigation": 20, "implementation": 10, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "minimal", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 75,\n  \"justification\": \"The issue is clearly reproducible and the hint points directly to a likely root cause: a recursive call to `diophantine` that drops the `permute` argument when `syms` are reordered. Implementing the fix is a small, localized change, but SymPy requires adding a regression test and running relevant solver/diophantine tests to ensure no behavioral regressions. Most of the time will be spent confirming expected solution sets across symbol orderings and validating the change against existing test coverage.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 20,\n    \"implementation\": 10,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"minimal\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:35.046757"}
{"instance_id": "sympy__sympy-14531", "repo": "sympy/sympy", "estimated_minutes": 240.0, "justification": "The issue points to printer settings (e.g., `sympy_integers=True`) not being propagated when printing certain compound objects like `Eq` and `Limit`, which likely means some printer methods are bypassing `self._print(...)` and/or instantiating/using secondary printers without forwarding settings. Fixing this in SymPy typically requires moderate code investigation across the printing subsystem (StrPrinter plus at least one codegen-related printer), then implementing a consistent settings-propagation approach. Additional time is needed to update or replace an existing test that currently asserts the incorrect `python(Eq(x, y))` behavior and to run targeted printing/codegen tests to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 105, "implementation": 60, "testing_and_verification": 75}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"The issue points to printer settings (e.g., `sympy_integers=True`) not being propagated when printing certain compound objects like `Eq` and `Limit`, which likely means some printer methods are bypassing `self._print(...)` and/or instantiating/using secondary printers without forwarding settings. Fixing this in SymPy typically requires moderate code investigation across the printing subsystem (StrPrinter plus at least one codegen-related printer), then implementing a consistent settings-propagation approach. Additional time is needed to update or replace an existing test that currently asserts the incorrect `python(Eq(x, y))` behavior and to run targeted printing/codegen tests to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 105,\n    \"implementation\": 60,\n    \"testing_and_verification\": 75\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:36.087927"}
{"instance_id": "sympy__sympy-16450", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "This requires investigating how `posify` constructs replacement Symbols/Dummys and why it currently drops explicit assumptions like `finite=True` while re-deriving a bundle of assumptions implied by `positive=True`. The fix is likely localized (update `posify` to preserve existing explicit assumptions and only add/override positivity-related ones when needed), but it must be done carefully to avoid creating inconsistent assumption sets. Proper tests should cover `finite`, `infinite`, and a couple of other explicit assumptions (e.g., integer/rational) to ensure assumptions are preserved and no regressions occur.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"This requires investigating how `posify` constructs replacement Symbols/Dummys and why it currently drops explicit assumptions like `finite=True` while re-deriving a bundle of assumptions implied by `positive=True`. The fix is likely localized (update `posify` to preserve existing explicit assumptions and only add/override positivity-related ones when needed), but it must be done carefully to avoid creating inconsistent assumption sets. Proper tests should cover `finite`, `infinite`, and a couple of other explicit assumptions (e.g., integer/rational) to ensure assumptions are preserved and no regressions occur.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:36.159875"}
{"instance_id": "sympy__sympy-17630", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "Although the issue has a clear reproducer, the engineer will need to trace how BlockMatrix block multiplication constructs and simplifies block entries, and why some zero-valued blocks lose their matrix shape and become scalar Zero. The fix will likely require adjusting block-multiplication (or post-processing) to preserve dimensional zero blocks as ZeroMatrix (or another shaped MatrixExpr) while ensuring no regressions in existing simplification behavior. Adding targeted tests for chained block multiplications with ZeroMatrix blocks and verifying against the broader matrix-expressions test suite contributes meaningful time.", "time_breakdown": {"understanding_and_investigation": 60, "implementation": 45, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the issue has a clear reproducer, the engineer will need to trace how BlockMatrix block multiplication constructs and simplifies block entries, and why some zero-valued blocks lose their matrix shape and become scalar Zero. The fix will likely require adjusting block-multiplication (or post-processing) to preserve dimensional zero blocks as ZeroMatrix (or another shaped MatrixExpr) while ensuring no regressions in existing simplification behavior. Adding targeted tests for chained block multiplications with ZeroMatrix blocks and verifying against the broader matrix-expressions test suite contributes meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 60,\n    \"implementation\": 45,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:37.541717"}
{"instance_id": "sympy__sympy-18211", "repo": "sympy/sympy", "estimated_minutes": 90.0, "justification": "The issue has a clear reproducer and a plausible fix location: Relational._eval_as_set delegates to solve_univariate_inequality, which can raise NotImplementedError and should instead fall back to a ConditionSet. Implementing the try/except is straightforward, but a contributor will need to confirm the intended semantics (e.g., only over Reals, and only for this codepath) and add regression tests to ensure the behavior change is correct and doesn\u2019t mask other errors. Running and iterating on targeted solver/relational tests in SymPy typically takes a non-trivial amount of time compared to the code change itself.", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 20, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue has a clear reproducer and a plausible fix location: Relational._eval_as_set delegates to solve_univariate_inequality, which can raise NotImplementedError and should instead fall back to a ConditionSet. Implementing the try/except is straightforward, but a contributor will need to confirm the intended semantics (e.g., only over Reals, and only for this codepath) and add regression tests to ensure the behavior change is correct and doesn\u2019t mask other errors. Running and iterating on targeted solver/relational tests in SymPy typically takes a non-trivial amount of time compared to the code change itself.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 20,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:38.434363"}
{"instance_id": "sympy__sympy-18763", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible but requires understanding SymPy's LaTeX printer precedence/parenthesization logic, particularly how `Subs` is rendered when it appears inside a `Mul`. The fix will likely involve adjusting `_print_Subs` (or the generic parenthesize/precedence handling) so the substituted expression is wrapped in parentheses when needed, while ensuring no regressions for already-correct `Subs` LaTeX output. Adding targeted tests for `Subs` in multiplicative and additive contexts and running the printing test suite will take a meaningful portion of the total time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 40, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible but requires understanding SymPy's LaTeX printer precedence/parenthesization logic, particularly how `Subs` is rendered when it appears inside a `Mul`. The fix will likely involve adjusting `_print_Subs` (or the generic parenthesize/precedence handling) so the substituted expression is wrapped in parentheses when needed, while ensuring no regressions for already-correct `Subs` LaTeX output. Adding targeted tests for `Subs` in multiplicative and additive contexts and running the printing test suite will take a meaningful portion of the total time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 40,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:38.794372"}
{"instance_id": "sympy__sympy-19040", "repo": "sympy/sympy", "estimated_minutes": 90.0, "justification": "The issue is clearly reproducible and is likely caused by a small bug (noted as a typo) in sympy/polys/factortools.py, but an engineer will still need time to trace how extension handling flows through the factoring pipeline to confirm the root cause and avoid collateral changes. The actual code fix is probably small (a line or two), yet SymPy\u2019s polynomial factoring code is subtle enough that careful review and a regression test are necessary. Writing/placing the correct test and running the relevant polys test suite (and possibly a few extra checks for related extension scenarios) will take a meaningful fraction of the time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 20, "testing_and_verification": 35}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clearly reproducible and is likely caused by a small bug (noted as a typo) in sympy/polys/factortools.py, but an engineer will still need time to trace how extension handling flows through the factoring pipeline to confirm the root cause and avoid collateral changes. The actual code fix is probably small (a line or two), yet SymPy\u2019s polynomial factoring code is subtle enough that careful review and a regression test are necessary. Writing/placing the correct test and running the relevant polys test suite (and possibly a few extra checks for related extension scenarios) will take a meaningful fraction of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 20,\n    \"testing_and_verification\": 35\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:39.144717"}
{"instance_id": "sympy__sympy-16597", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "Although the symptom is easy to reproduce, fixing it correctly requires understanding SymPy\u2019s assumptions lattice (notably the distinction between real vs extended_real and what \u201cfinite\u201d means for Symbols). The likely fix is to adjust implication rules in the core assumptions engine (e.g., making integer/rational/even imply finite), but this can have subtle knock-on effects across simplification and solving. An experienced engineer would need to add targeted tests and run a meaningful subset of the test suite to ensure no regressions in areas that depend on current assumption behavior.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 35, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the symptom is easy to reproduce, fixing it correctly requires understanding SymPy\u2019s assumptions lattice (notably the distinction between real vs extended_real and what \u201cfinite\u201d means for Symbols). The likely fix is to adjust implication rules in the core assumptions engine (e.g., making integer/rational/even imply finite), but this can have subtle knock-on effects across simplification and solving. An experienced engineer would need to add targeted tests and run a meaningful subset of the test suite to ensure no regressions in areas that depend on current assumption behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 35,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:39.316200"}
{"instance_id": "sympy__sympy-18199", "repo": "sympy/sympy", "estimated_minutes": 90.0, "justification": "The issue is clear and easily reproducible: when a % p == 0, x = 0 (mod p) must be a solution to x**n = a (mod p), but nthroot_mod currently omits it. An engineer will still need to inspect nthroot_mod\u2019s existing control flow (including behavior for all_roots and possibly non-prime moduli/prime powers) to ensure the fix is consistent with current design and doesn\u2019t break other cases. Adding focused regression tests and running SymPy\u2019s relevant test suite will take a substantial portion of the time.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 20, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clear and easily reproducible: when a % p == 0, x = 0 (mod p) must be a solution to x**n = a (mod p), but nthroot_mod currently omits it. An engineer will still need to inspect nthroot_mod\u2019s existing control flow (including behavior for all_roots and possibly non-prime moduli/prime powers) to ensure the fix is consistent with current design and doesn\u2019t break other cases. Adding focused regression tests and running SymPy\u2019s relevant test suite will take a substantial portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 20,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "1-4 hours", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:40.045851"}
{"instance_id": "sympy__sympy-20154", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "This change requires investigating the current implementation of `partitions()` in `sympy.utilities.iterables`, understanding why it reuses a single dictionary object, and assessing any intended performance/behavioral guarantees implied by the docstring and existing callers. Implementing the fix is likely small (yielding a copy or introducing an opt-in/out flag), but care is needed because changing iterator semantics can subtly affect downstream code and performance expectations. Additional time is needed to add/adjust tests to ensure yielded partitions are independent objects and to run the relevant SymPy test suite to catch regressions.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"This change requires investigating the current implementation of `partitions()` in `sympy.utilities.iterables`, understanding why it reuses a single dictionary object, and assessing any intended performance/behavioral guarantees implied by the docstring and existing callers. Implementing the fix is likely small (yielding a copy or introducing an opt-in/out flag), but care is needed because changing iterator semantics can subtly affect downstream code and performance expectations. Additional time is needed to add/adjust tests to ensure yielded partitions are independent objects and to run the relevant SymPy test suite to catch regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:40.214250"}
{"instance_id": "sympy__sympy-19346", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "Although the issue is easy to reproduce, fixing it cleanly requires inspecting how `srepr`/`ReprPrinter` handles Python container types and why `list`/`tuple` are special-cased while `set`/`dict` fall back to default `repr`. Implementing correct printing for `set` and `dict` likely involves adding printer methods (e.g., `_print_set`, `_print_dict`) and deciding on deterministic ordering for stable outputs, which is important for tests and downstream usage. Writing robust tests must account for ordering/normalization (especially for sets/dicts) and verifying no regressions in existing `srepr` behavior.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 35, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"Although the issue is easy to reproduce, fixing it cleanly requires inspecting how `srepr`/`ReprPrinter` handles Python container types and why `list`/`tuple` are special-cased while `set`/`dict` fall back to default `repr`. Implementing correct printing for `set` and `dict` likely involves adding printer methods (e.g., `_print_set`, `_print_dict`) and deciding on deterministic ordering for stable outputs, which is important for tests and downstream usage. Writing robust tests must account for ordering/normalization (especially for sets/dicts) and verifying no regressions in existing `srepr` behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 35,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:40.450050"}
{"instance_id": "sympy__sympy-19637", "repo": "sympy/sympy", "estimated_minutes": 90.0, "justification": "The issue has a clear reproduction case and points directly to a specific function (kernS) in sympy.core.sympify, making it likely a localized bug (e.g., a conditional path where a local variable is not initialized). However, an engineer will still need to inspect the parsing/sympify logic and ensure the fix is correct for multiple input shapes, not just the provided fraction example. Adding a regression test and running SymPy's relevant test subset (and possibly a small broader subset) will take a meaningful portion of the time.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 20, "testing_and_verification": 35}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue has a clear reproduction case and points directly to a specific function (kernS) in sympy.core.sympify, making it likely a localized bug (e.g., a conditional path where a local variable is not initialized). However, an engineer will still need to inspect the parsing/sympify logic and ensure the fix is correct for multiple input shapes, not just the provided fraction example. Adding a regression test and running SymPy's relevant test subset (and possibly a small broader subset) will take a meaningful portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 20,\n    \"testing_and_verification\": 35\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:40.634287"}
{"instance_id": "sympy__sympy-15345", "repo": "sympy/sympy", "estimated_minutes": 90.0, "justification": "The issue is clearly reproducible and likely isolated to the Mathematica printer, where SymPy's `Max` falls back to a generic function-printing path that emits parentheses instead of Mathematica-style square brackets. Fixing it should involve adding/adjusting printer methods (e.g., `_print_Max`/`_print_Min` or the generic function formatting) in `sympy/printing/mathematica.py` and ensuring consistent argument formatting. Time is driven mainly by investigating existing printer conventions and adding regression tests to confirm correct output and avoid breaking other function printing behavior.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 25, "testing_and_verification": 30}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clearly reproducible and likely isolated to the Mathematica printer, where SymPy's `Max` falls back to a generic function-printing path that emits parentheses instead of Mathematica-style square brackets. Fixing it should involve adding/adjusting printer methods (e.g., `_print_Max`/`_print_Min` or the generic function formatting) in `sympy/printing/mathematica.py` and ensuring consistent argument formatting. Time is driven mainly by investigating existing printer conventions and adding regression tests to confirm correct output and avoid breaking other function printing behavior.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 25,\n    \"testing_and_verification\": 30\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:40.889890"}
{"instance_id": "sympy__sympy-18698", "repo": "sympy/sympy", "estimated_minutes": 240.0, "justification": "Although the core bug (duplicated entries with the same multiplicity in the symbolic sqf_list output) is conceptually simple, fixing it correctly requires understanding how polytools.sqf_list delegates to low-level factor-list helpers and how results differ between Expr-level and Poly-level APIs. The change is likely to touch the sqf_list implementation (and possibly related sqf/sqf_norm helpers) plus documentation expectations around univariate-only behavior and generator handling. Proper regression tests must cover the reported example, ordering/normalization, and edge cases like multivariate inputs and constants to ensure consistent behavior without breaking existing callers.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 90}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 240,\n  \"justification\": \"Although the core bug (duplicated entries with the same multiplicity in the symbolic sqf_list output) is conceptually simple, fixing it correctly requires understanding how polytools.sqf_list delegates to low-level factor-list helpers and how results differ between Expr-level and Poly-level APIs. The change is likely to touch the sqf_list implementation (and possibly related sqf/sqf_norm helpers) plus documentation expectations around univariate-only behavior and generator handling. Proper regression tests must cover the reported example, ordering/normalization, and edge cases like multivariate inputs and constants to ensure consistent behavior without breaking existing callers.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 90\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": ">4 hours", "processed_at": "2026-01-23T17:48:40.896419"}
{"instance_id": "sympy__sympy-20428", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "Although the issue has a clear reproducer and a likely root cause (an unstripped dense polynomial representation `DMP([0], ...)`), fixing it correctly requires tracing how `Poly.clear_denoms()` constructs the returned polynomial and where stripping/normalization is supposed to happen. The change is likely small but must be placed at the correct abstraction layer (e.g., DMP normalization vs. Poly method) to avoid performance regressions and to ensure other polynomial operations consistently treat the result as zero. Writing robust regression tests is nontrivial because the failing input involves EX-domain constants and the bug manifests through multiple downstream methods (e.g., `is_zero`, `terms_gcd`, `primitive`).", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 50, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Although the issue has a clear reproducer and a likely root cause (an unstripped dense polynomial representation `DMP([0], ...)`), fixing it correctly requires tracing how `Poly.clear_denoms()` constructs the returned polynomial and where stripping/normalization is supposed to happen. The change is likely small but must be placed at the correct abstraction layer (e.g., DMP normalization vs. Poly method) to avoid performance regressions and to ensure other polynomial operations consistently treat the result as zero. Writing robust regression tests is nontrivial because the failing input involves EX-domain constants and the bug manifests through multiple downstream methods (e.g., `is_zero`, `terms_gcd`, `primitive`).\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 50,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:42.244518"}
{"instance_id": "sympy__sympy-19783", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "Although the issue has a clear reproduction snippet, fixing it likely requires understanding how SymPy\u2019s quantum expressions implement noncommutative multiplication and simplification hooks (e.g., _eval_mul / __mul__ dispatch) across Operator, Dagger, and IdentityOperator. The bug is probably due to IdentityOperator simplification rules handling Operator but not Dagger-wrapped operators (or the Dagger class not delegating multiplication simplification properly), which requires moderate investigation of class hierarchies and method resolution. Properly addressing it should include adding targeted tests (and possibly a few edge-case tests like Identity*Dagger(A) and products inside larger expressions) and running the relevant test suite subset to ensure no regressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 35, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the issue has a clear reproduction snippet, fixing it likely requires understanding how SymPy\u2019s quantum expressions implement noncommutative multiplication and simplification hooks (e.g., _eval_mul / __mul__ dispatch) across Operator, Dagger, and IdentityOperator. The bug is probably due to IdentityOperator simplification rules handling Operator but not Dagger-wrapped operators (or the Dagger class not delegating multiplication simplification properly), which requires moderate investigation of class hierarchies and method resolution. Properly addressing it should include adding targeted tests (and possibly a few edge-case tests like Identity*Dagger(A) and products inside larger expressions) and running the relevant test suite subset to ensure no regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 35,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:43.448081"}
{"instance_id": "sympy__sympy-21847", "repo": "sympy/sympy", "estimated_minutes": 110.0, "justification": "The issue is clearly reproducible and the likely fix is narrowly scoped (a small logic change in itermonomials), but an engineer will still need to inspect how degrees are computed across commutative/noncommutative branches and confirm intended semantics for both integer and per-variable min_degrees. The bulk of the work is adding robust tests in test_monomials.py to cover multiple cases (exact-degree filtering, max>min, and regression coverage for both code paths) and running the relevant SymPy test suite subsets to ensure no regressions. Overall, this is a straightforward bug fix with moderate verification overhead typical for SymPy\u2019s polynomial utilities.", "time_breakdown": {"understanding_and_investigation": 35, "implementation": 15, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 110,\n  \"justification\": \"The issue is clearly reproducible and the likely fix is narrowly scoped (a small logic change in itermonomials), but an engineer will still need to inspect how degrees are computed across commutative/noncommutative branches and confirm intended semantics for both integer and per-variable min_degrees. The bulk of the work is adding robust tests in test_monomials.py to cover multiple cases (exact-degree filtering, max>min, and regression coverage for both code paths) and running the relevant SymPy test suite subsets to ensure no regressions. Overall, this is a straightforward bug fix with moderate verification overhead typical for SymPy\u2019s polynomial utilities.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 35,\n    \"implementation\": 15,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:43.488082"}
{"instance_id": "sympy__sympy-19954", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "The issue has clear reproduction steps and points to a specific failure location (minimal_blocks called from sylow_subgroup), but fixing it likely requires understanding the block-finding algorithm and how it mutates internal lists to avoid IndexError and preserve correctness. The engineer will need to trace the minimal_blocks logic for certain dihedral group actions, implement a safe iteration/deletion strategy (or adjust the algorithm\u2019s invariants), and ensure the change doesn\u2019t break other group/block computations. Proper regression tests should be added for the reported dihedral cases and a small set of related groups to confirm the Sylow computation works and no regressions are introduced.", "time_breakdown": {"understanding_and_investigation": 80, "implementation": 45, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue has clear reproduction steps and points to a specific failure location (minimal_blocks called from sylow_subgroup), but fixing it likely requires understanding the block-finding algorithm and how it mutates internal lists to avoid IndexError and preserve correctness. The engineer will need to trace the minimal_blocks logic for certain dihedral group actions, implement a safe iteration/deletion strategy (or adjust the algorithm\u2019s invariants), and ensure the change doesn\u2019t break other group/block computations. Proper regression tests should be added for the reported dihedral cases and a small set of related groups to confirm the Sylow computation works and no regressions are introduced.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 80,\n    \"implementation\": 45,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:43.501263"}
{"instance_id": "sympy__sympy-21612", "repo": "sympy/sympy", "estimated_minutes": 75.0, "justification": "Although the issue is reported as a LaTeX parsing bug, reproducing it and inspecting the resulting expression shows it is primarily a string-printing parenthesization problem in SymPy\u2019s StrPrinter for Mul/Pow combinations. The fix is small (a targeted condition change in the printer) but requires careful verification to avoid introducing new precedence/parentheses regressions in other printed forms. Adding a focused regression test and running relevant printer/parsing tests accounts for a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 15, "testing_and_verification": 35}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 75,\n  \"justification\": \"Although the issue is reported as a LaTeX parsing bug, reproducing it and inspecting the resulting expression shows it is primarily a string-printing parenthesization problem in SymPy\u2019s StrPrinter for Mul/Pow combinations. The fix is small (a targeted condition change in the printer) but requires careful verification to avoid introducing new precedence/parentheses regressions in other printed forms. Adding a focused regression test and running relevant printer/parsing tests accounts for a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 15,\n    \"testing_and_verification\": 35\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:44.121238"}
{"instance_id": "sympy__sympy-20590", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is well-localized (regression introduced when Basic started inheriting DefaultPrinting), but confirming the exact inheritance/slot behavior and any unintended side-effects across many Basic subclasses requires some code investigation. The likely fix (adding an empty __slots__ = () to DefaultPrinting) is small, but it needs careful validation that it restores slot-based memory/immutability expectations without breaking multiple inheritance patterns. Writing a regression test and running an appropriate subset (or full) of SymPy's test suite to ensure no printing-related regressions will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 15, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-localized (regression introduced when Basic started inheriting DefaultPrinting), but confirming the exact inheritance/slot behavior and any unintended side-effects across many Basic subclasses requires some code investigation. The likely fix (adding an empty __slots__ = () to DefaultPrinting) is small, but it needs careful validation that it restores slot-based memory/immutability expectations without breaking multiple inheritance patterns. Writing a regression test and running an appropriate subset (or full) of SymPy's test suite to ensure no printing-related regressions will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 15,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:44.514156"}
{"instance_id": "sympy__sympy-20916", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is well-reproduced and likely comes from a symbol-name parsing regular expression in the pretty-printing conventions that currently assumes ASCII letters (e.g., using `[a-zA-Z]`) and therefore fails to split Unicode Greek letters from trailing digits. Fixing it is probably localized (one core regex/function) but requires careful adjustment to avoid changing behavior for existing ASCII symbols and edge cases (underscores, multi-digit subscripts, mixed Unicode/ASCII). Writing targeted pretty-print regression tests and running the relevant SymPy printing test suite will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is well-reproduced and likely comes from a symbol-name parsing regular expression in the pretty-printing conventions that currently assumes ASCII letters (e.g., using `[a-zA-Z]`) and therefore fails to split Unicode Greek letters from trailing digits. Fixing it is probably localized (one core regex/function) but requires careful adjustment to avoid changing behavior for existing ASCII symbols and edge cases (underscores, multi-digit subscripts, mixed Unicode/ASCII). Writing targeted pretty-print regression tests and running the relevant SymPy printing test suite will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:45.537109"}
{"instance_id": "sympy__sympy-21379", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "Although the immediate fix is small (catching PolynomialError around the gcd call in Mod.eval), an engineer will need time to reproduce the issue reliably, trace the stack through assumptions/is_real/Mod, and confirm the intended behavior for Piecewise-containing expressions. Adding regression tests will require choosing stable minimal reproductions (e.g., direct Mod with Piecewise and the reported subs/nfloat scenario) and ensuring they pass across SymPy\u2019s evaluation/caching behavior. Running the relevant test suites and checking for unintended simplification regressions in Mod/gcd handling adds additional verification time.", "time_breakdown": {"understanding_and_investigation": 65, "implementation": 25, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the immediate fix is small (catching PolynomialError around the gcd call in Mod.eval), an engineer will need time to reproduce the issue reliably, trace the stack through assumptions/is_real/Mod, and confirm the intended behavior for Piecewise-containing expressions. Adding regression tests will require choosing stable minimal reproductions (e.g., direct Mod with Piecewise and the reported subs/nfloat scenario) and ensuring they pass across SymPy\u2019s evaluation/caching behavior. Running the relevant test suites and checking for unintended simplification regressions in Mod/gcd handling adds additional verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 65,\n    \"implementation\": 25,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:46.406003"}
{"instance_id": "sympy__sympy-22456", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "Fixing argument invariance for a SymPy `Basic` subclass typically requires understanding how the class currently stores its construction data (here via `kwargs()` rather than `args`) and adjusting `__new__`/internal attributes so that `expr.func(*expr.args)` reconstructs the same object. This is likely localized to `codegen.ast` but must be done carefully to preserve existing behavior and hashing/canonicalization semantics. Writing targeted tests for `String` construction/reconstruction and running the relevant test suite adds meaningful time but should remain contained.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 50, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Fixing argument invariance for a SymPy `Basic` subclass typically requires understanding how the class currently stores its construction data (here via `kwargs()` rather than `args`) and adjusting `__new__`/internal attributes so that `expr.func(*expr.args)` reconstructs the same object. This is likely localized to `codegen.ast` but must be done carefully to preserve existing behavior and hashing/canonicalization semantics. Writing targeted tests for `String` construction/reconstruction and running the relevant test suite adds meaningful time but should remain contained.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 50,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:46.957030"}
{"instance_id": "sympy__sympy-20438", "repo": "sympy/sympy", "estimated_minutes": 210.0, "justification": "Reproducing and diagnosing this issue likely requires digging into SymPy's set logic for ProductSet, subset checks, and how equality simplification reduces set relations (the observed Complement-related AttributeError suggests an unexpected set-expression type propagating into relational simplification). Implementing a correct ProductSet.is_subset(FiniteSet) behavior will require careful handling of finiteness, tuple-structure membership, and fallback to symbolic/indeterminate results without breaking other Set subclasses. Proper regression tests will need to cover subset symmetry, equality simplification, and edge cases (finite vs infinite factors, non-tuple FiniteSet elements), and running SymPy's relevant test suite portion will add nontrivial verification time.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Reproducing and diagnosing this issue likely requires digging into SymPy's set logic for ProductSet, subset checks, and how equality simplification reduces set relations (the observed Complement-related AttributeError suggests an unexpected set-expression type propagating into relational simplification). Implementing a correct ProductSet.is_subset(FiniteSet) behavior will require careful handling of finiteness, tuple-structure membership, and fallback to symbolic/indeterminate results without breaking other Set subclasses. Proper regression tests will need to cover subset symmetry, equality simplification, and edge cases (finite vs infinite factors, non-tuple FiniteSet elements), and running SymPy's relevant test suite portion will add nontrivial verification time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:47.182976"}
{"instance_id": "sympy__sympy-22914", "repo": "sympy/sympy", "estimated_minutes": 90.0, "justification": "The issue is clearly reproducible and the intended fix is straightforward (mapping SymPy Min/Max to Python builtins via PythonCodePrinter). However, an engineer will still need to locate the correct printing infrastructure, confirm no existing Min/Max handling exists for pycode, and ensure the change aligns with SymPy printing conventions. Most of the time will be spent adding and running targeted tests to prevent regressions and verify behavior across typical Min/Max argument patterns.", "time_breakdown": {"understanding_and_investigation": 25, "implementation": 20, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "basic", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is clearly reproducible and the intended fix is straightforward (mapping SymPy Min/Max to Python builtins via PythonCodePrinter). However, an engineer will still need to locate the correct printing infrastructure, confirm no existing Min/Max handling exists for pycode, and ensure the change aligns with SymPy printing conventions. Most of the time will be spent adding and running targeted tests to prevent regressions and verify behavior across typical Min/Max argument patterns.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 25,\n    \"implementation\": 20,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"basic\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:47.509267"}
{"instance_id": "sympy__sympy-21596", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "The issue is reproducible and well-specified, but the root cause likely involves subtle logic in SymPy's Set intersection/membership code paths for ImageSet with a complex-valued expression and intersection with Reals. An engineer will need to trace how `intersect(Reals)` simplifies and why membership changes from `False` to `True`, which typically requires inspecting multiple layers (intersection dispatch, assumptions about real-valuedness, and ImageSet parameter constraints). Implementing a correct fix will also require adding targeted tests to prevent regressions for other ImageSet/Reals interactions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is reproducible and well-specified, but the root cause likely involves subtle logic in SymPy's Set intersection/membership code paths for ImageSet with a complex-valued expression and intersection with Reals. An engineer will need to trace how `intersect(Reals)` simplifies and why membership changes from `False` to `True`, which typically requires inspecting multiple layers (intersection dispatch, assumptions about real-valuedness, and ImageSet parameter constraints). Implementing a correct fix will also require adding targeted tests to prevent regressions for other ImageSet/Reals interactions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:47.993116"}
{"instance_id": "sympy__sympy-22080", "repo": "sympy/sympy", "estimated_minutes": 210.0, "justification": "Although the repro is clear, the root cause spans the interaction between lambdify's module-selection path (notably when modules=[]), the Python code printer (pycode), and operator precedence/parenthesization for unary minus vs the % operator. Fixing it robustly typically requires careful adjustments to precedence handling (or explicit parenthesization rules) without breaking many existing printing expectations (Mod(x, y) vs x % y) and ensuring lambdify-generated code matches runtime semantics. Writing targeted regression tests for both lambdify(modules=[]) and pycode output, and running SymPy\u2019s test suite to catch subtle printing regressions, adds meaningful time.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the repro is clear, the root cause spans the interaction between lambdify's module-selection path (notably when modules=[]), the Python code printer (pycode), and operator precedence/parenthesization for unary minus vs the % operator. Fixing it robustly typically requires careful adjustments to precedence handling (or explicit parenthesization rules) without breaking many existing printing expectations (Mod(x, y) vs x % y) and ensuring lambdify-generated code matches runtime semantics. Writing targeted regression tests for both lambdify(modules=[]) and pycode output, and running SymPy\u2019s test suite to catch subtle printing regressions, adds meaningful time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:48.706286"}
{"instance_id": "sympy__sympy-23824", "repo": "sympy/sympy", "estimated_minutes": 90.0, "justification": "The issue is well-specified with a minimal reproducer and a clear suspected cause (re-inserting stripped leading gamma matrices in reverse order), so investigation should be contained. The fix itself is likely a small change in kahane_simplify() (e.g., adjusting an insertion loop or list handling), but care is needed to ensure ordering is preserved across other simplification paths. Adding a focused regression test and running the relevant SymPy test suite subset will take a non-trivial amount of time due to repo conventions and test runtime.", "time_breakdown": {"understanding_and_investigation": 30, "implementation": 20, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "1", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 90,\n  \"justification\": \"The issue is well-specified with a minimal reproducer and a clear suspected cause (re-inserting stripped leading gamma matrices in reverse order), so investigation should be contained. The fix itself is likely a small change in kahane_simplify() (e.g., adjusting an insertion loop or list handling), but care is needed to ensure ordering is preserved across other simplification paths. Adding a focused regression test and running the relevant SymPy test suite subset will take a non-trivial amount of time due to repo conventions and test runtime.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 30,\n    \"implementation\": 20,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"1\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:49.611725"}
{"instance_id": "sympy__sympy-20801", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is clear to reproduce but likely involves SymPy\u2019s nontrivial equality dispatch rules between numeric atoms (Float/Integer) and Boolean atoms, which can lead to asymmetric results depending on which __eq__ implementation runs first. An experienced engineer will need to locate where Float equality is coercing BooleanFalse (likely via numeric conversion) and adjust it to return a consistent result (probably making Float-vs-Boolean comparisons return False or NotImplemented to let the other side decide). The fix should be small, but careful investigation and regression testing are needed because equality semantics are widely used and can have subtle ripple effects.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 25, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clear to reproduce but likely involves SymPy\u2019s nontrivial equality dispatch rules between numeric atoms (Float/Integer) and Boolean atoms, which can lead to asymmetric results depending on which __eq__ implementation runs first. An experienced engineer will need to locate where Float equality is coercing BooleanFalse (likely via numeric conversion) and adjust it to return a consistent result (probably making Float-vs-Boolean comparisons return False or NotImplemented to let the other side decide). The fix should be small, but careful investigation and regression testing are needed because equality semantics are widely used and can have subtle ripple effects.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 25,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:50.257842"}
{"instance_id": "sympy__sympy-24443", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue has a clear reproducer and points to a specific location in `homomorphisms.py`, but fixing it correctly requires understanding how `_image()` and `_check_homomorphism` represent words in generators for `PermutationGroup` elements (including inverses). The implementation is likely a small-to-medium change (e.g., normalizing inverted generators or using a more robust generator-to-image lookup), but it must be validated against group-theoretic edge cases. Writing targeted regression tests for permutation-group homomorphisms (including inverted-generator paths) and running the combinatorics test suite will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue has a clear reproducer and points to a specific location in `homomorphisms.py`, but fixing it correctly requires understanding how `_image()` and `_check_homomorphism` represent words in generators for `PermutationGroup` elements (including inverses). The implementation is likely a small-to-medium change (e.g., normalizing inverted generators or using a more robust generator-to-image lookup), but it must be validated against group-theoretic edge cases. Writing targeted regression tests for permutation-group homomorphisms (including inverted-generator paths) and running the combinatorics test suite will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:50.398449"}
{"instance_id": "sympy__sympy-17655", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "Although the issue looks like a missing `__rmul__`, in SymPy the left operand (e.g., `Float`) often constructs a `Mul` eagerly, so `Point.__rmul__` may not be reached unless SymPy\u2019s priority/dispatch mechanisms are handled correctly. An engineer will likely need to inspect how `Point` participates in SymPy\u2019s arithmetic dispatch (e.g., `__sympy_priority__`, `call_highest_priority`, and existing `__mul__` behavior) to ensure `2*Point` produces a scaled `Point` rather than a `Mul`. The fix should be small but requires careful integration and targeted tests to avoid breaking symbolic multiplication behavior elsewhere in `sympy.geometry`.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"Although the issue looks like a missing `__rmul__`, in SymPy the left operand (e.g., `Float`) often constructs a `Mul` eagerly, so `Point.__rmul__` may not be reached unless SymPy\u2019s priority/dispatch mechanisms are handled correctly. An engineer will likely need to inspect how `Point` participates in SymPy\u2019s arithmetic dispatch (e.g., `__sympy_priority__`, `call_highest_priority`, and existing `__mul__` behavior) to ensure `2*Point` produces a scaled `Point` rather than a `Mul`. The fix should be small but requires careful integration and targeted tests to avoid breaking symbolic multiplication behavior elsewhere in `sympy.geometry`.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:50.685533"}
{"instance_id": "sympy__sympy-24539", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible and localized to `PolyElement.as_expr()` in `sympy/polys/rings.py`, but fixing it correctly requires understanding how ring elements are converted to SymPy expressions and how symbol ordering/naming is handled across the polys subsystem. The implementation itself is likely a small change (ensuring the provided symbols are actually used), but writing robust tests and verifying no regressions across different ring configurations (e.g., different numbers of generators, symbol types) adds meaningful time. SymPy\u2019s polys code has established conventions and edge cases, so some investigation and careful verification are necessary.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 25, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "straightforward"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible and localized to `PolyElement.as_expr()` in `sympy/polys/rings.py`, but fixing it correctly requires understanding how ring elements are converted to SymPy expressions and how symbol ordering/naming is handled across the polys subsystem. The implementation itself is likely a small change (ensuring the provided symbols are actually used), but writing robust tests and verifying no regressions across different ring configurations (e.g., different numbers of generators, symbol types) adds meaningful time. SymPy\u2019s polys code has established conventions and edge cases, so some investigation and careful verification are necessary.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 25,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"straightforward\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:51.241724"}
{"instance_id": "sympy__sympy-23534", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible but likely rooted in the internal parsing/recursion logic of `symbols()` when it receives an iterable of specifications, where the `cls` argument is not consistently propagated and defaults back to `Symbol`. Fixing this will require tracing how `symbols()` handles nested inputs and range syntax (e.g., `q:2`) and ensuring behavior stays consistent across all supported input shapes. A proper fix should include targeted regression tests for iterable/tuple inputs and verification that no existing `symbols()` behaviors regress.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 30, "testing_and_verification": 35}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible but likely rooted in the internal parsing/recursion logic of `symbols()` when it receives an iterable of specifications, where the `cls` argument is not consistently propagated and defaults back to `Symbol`. Fixing this will require tracing how `symbols()` handles nested inputs and range syntax (e.g., `q:2`) and ensuring behavior stays consistent across all supported input shapes. A proper fix should include targeted regression tests for iterable/tuple inputs and verification that no existing `symbols()` behaviors regress.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 30,\n    \"testing_and_verification\": 35\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:51.250700"}
{"instance_id": "sympy__sympy-23262", "repo": "sympy/sympy", "estimated_minutes": 120.0, "justification": "The issue is clearly reproducible but requires moderate code investigation because it involves the interaction between `lambdify` and the Python code printer, and the regression was introduced by a specific prior change. The fix itself is likely small (ensuring one-element tuples are printed with a trailing comma when the printer receives a Python `tuple`), but care is needed to avoid breaking other output formats and code paths in `lambdify`. Writing targeted regression tests and running the relevant test suite to ensure no regressions will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 45, "implementation": 30, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 120,\n  \"justification\": \"The issue is clearly reproducible but requires moderate code investigation because it involves the interaction between `lambdify` and the Python code printer, and the regression was introduced by a specific prior change. The fix itself is likely small (ensuring one-element tuples are printed with a trailing comma when the printer receives a Python `tuple`), but care is needed to avoid breaking other output formats and code paths in `lambdify`. Writing targeted regression tests and running the relevant test suite to ensure no regressions will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 45,\n    \"implementation\": 30,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:52.842160"}
{"instance_id": "sympy__sympy-24562", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "The issue is reproducible and points directly to a specific code region in Rational construction logic, but an engineer will still need time to confirm the regression from 1.8 to 1.11.1 and ensure the fix is correct for all mixed-type (string/float/int) inputs. The change is localized (likely in sympy/core/numbers.py) but touches a core numeric type, so careful handling of edge cases and running a meaningful subset of SymPy\u2019s test suite is required. Adding targeted tests (including the suggested parametrized cases) and verifying no regressions in Rational parsing/construction will take a significant portion of the time.", "time_breakdown": {"understanding_and_investigation": 50, "implementation": 40, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is reproducible and points directly to a specific code region in Rational construction logic, but an engineer will still need time to confirm the regression from 1.8 to 1.11.1 and ensure the fix is correct for all mixed-type (string/float/int) inputs. The change is localized (likely in sympy/core/numbers.py) but touches a core numeric type, so careful handling of edge cases and running a meaningful subset of SymPy\u2019s test suite is required. Adding targeted tests (including the suggested parametrized cases) and verifying no regressions in Rational parsing/construction will take a significant portion of the time.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 50,\n    \"implementation\": 40,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:52.959043"}
{"instance_id": "sympy__sympy-24213", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "The issue is reproducible and points directly at UnitSystem._collect_factor_and_dimension raising on an Add where two dimensions are mathematically equivalent but not recognized as equal (velocity vs acceleration*time). Fixing this likely requires investigating how Dimension objects are represented/canonicalized and adjusting the comparison logic to simplify dimensions (or compare via dimensional dependencies) before deciding they mismatch. Implementing the fix should be localized but requires care to avoid changing semantics of dimension checking across unit systems, and will need targeted tests plus running the relevant SymPy physics.units test suite to guard against regressions.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 60, "testing_and_verification": 45}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"The issue is reproducible and points directly at UnitSystem._collect_factor_and_dimension raising on an Add where two dimensions are mathematically equivalent but not recognized as equal (velocity vs acceleration*time). Fixing this likely requires investigating how Dimension objects are represented/canonicalized and adjusting the comparison logic to simplify dimensions (or compare via dimensional dependencies) before deciding they mismatch. Implementing the fix should be localized but requires care to avoid changing semantics of dimension checking across unit systems, and will need targeted tests plus running the relevant SymPy physics.units test suite to guard against regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 60,\n    \"testing_and_verification\": 45\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:53.039364"}
{"instance_id": "sympy__sympy-24066", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "The issue is well-reproduced but likely stems from subtle logic in the units dimension-collection code path for transcendental functions (e.g., exp) where \u201cdimensionless\u201d is being checked too strictly or before simplification/canonicalization. An engineer will need to trace how _collect_factor_and_dimension computes dimensions for the exp argument versus the standalone expr case, and ensure the dimensionless check uses the dimension system\u2019s normalization rather than direct structural equality. The fix should be localized (likely 1\u20133 files) but requires careful regression testing because unit/dimension inference is widely used and small changes can affect many expressions.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is well-reproduced but likely stems from subtle logic in the units dimension-collection code path for transcendental functions (e.g., exp) where \u201cdimensionless\u201d is being checked too strictly or before simplification/canonicalization. An engineer will need to trace how _collect_factor_and_dimension computes dimensions for the exp argument versus the standalone expr case, and ensure the dimensionless check uses the dimension system\u2019s normalization rather than direct structural equality. The fix should be localized (likely 1\u20133 files) but requires careful regression testing because unit/dimension inference is widely used and small changes can affect many expressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:53.797367"}
{"instance_id": "sympy__sympy-23413", "repo": "sympy/sympy", "estimated_minutes": 210.0, "justification": "This appears to be a subtle correctness bug in the Hermite normal form implementation where the algorithm (or its DomainMatrix-backed pathway) is incorrectly treating certain pivot configurations as rank-deficient and then truncating rows/columns in the returned matrix. Reproducing the failure is straightforward, but identifying exactly where shape is being reduced (and ensuring the fix preserves documented HNF invariants across multiple matrix shapes and pivot placements) will require moderate-to-deep code investigation and careful reasoning about the underlying integer matrix normal form algorithm. A robust fix will also require adding targeted regression tests for multiple pivot positions and verifying no regressions across existing normal-forms tests.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 60, "testing_and_verification": 60}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 210,\n  \"justification\": \"This appears to be a subtle correctness bug in the Hermite normal form implementation where the algorithm (or its DomainMatrix-backed pathway) is incorrectly treating certain pivot configurations as rank-deficient and then truncating rows/columns in the returned matrix. Reproducing the failure is straightforward, but identifying exactly where shape is being reduced (and ensuring the fix preserves documented HNF invariants across multiple matrix shapes and pivot placements) will require moderate-to-deep code investigation and careful reasoning about the underlying integer matrix normal form algorithm. A robust fix will also require adding targeted regression tests for multiple pivot positions and verifying no regressions across existing normal-forms tests.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 60,\n    \"testing_and_verification\": 60\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:54.523604"}
{"instance_id": "sympy__sympy-23950", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "Fixing this requires understanding how SymPy represents booleans vs sets and how `as_set()` is expected to behave across `Boolean`, `Relational`, and `Contains`, then implementing a consistent conversion that avoids returning a non-Set object. The change likely involves adding/overriding `as_set` logic (e.g., `Contains(x, S) -> S`, otherwise a `ConditionSet`) and ensuring `Piecewise` and other callers that expect a Set don\u2019t break. Writing focused tests for `Contains.as_set()`, the `Piecewise` regression, and key simplification/edge cases (False/True, multiple free symbols) plus running the relevant test suite makes this a medium-sized change.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 55, "testing_and_verification": 55}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"Fixing this requires understanding how SymPy represents booleans vs sets and how `as_set()` is expected to behave across `Boolean`, `Relational`, and `Contains`, then implementing a consistent conversion that avoids returning a non-Set object. The change likely involves adding/overriding `as_set` logic (e.g., `Contains(x, S) -> S`, otherwise a `ConditionSet`) and ensuring `Piecewise` and other callers that expect a Set don\u2019t break. Writing focused tests for `Contains.as_set()`, the `Piecewise` regression, and key simplification/edge cases (False/True, multiple free symbols) plus running the relevant test suite makes this a medium-sized change.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 55,\n    \"testing_and_verification\": 55\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:54.816084"}
{"instance_id": "sympy__sympy-21930", "repo": "sympy/sympy", "estimated_minutes": 165.0, "justification": "Although the bug is easy to reproduce, fixing it cleanly requires understanding how SymPy\u2019s LaTeX printer interacts with custom printers in the second quantization classes, and where grouping should be introduced without affecting other outputs. The likely fix is small (ensuring the LaTeX emitted for daggered operators is grouped so exponentiation produces `{...}^{2}`), but it must be validated against existing printing conventions and potential regressions in other LaTeX cases. Writing targeted tests for `Bd(a)**2` inside `Commutator` and possibly related operator powers will take non-trivial time due to SymPy\u2019s extensive printing test suite patterns.", "time_breakdown": {"understanding_and_investigation": 75, "implementation": 40, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 165,\n  \"justification\": \"Although the bug is easy to reproduce, fixing it cleanly requires understanding how SymPy\u2019s LaTeX printer interacts with custom printers in the second quantization classes, and where grouping should be introduced without affecting other outputs. The likely fix is small (ensuring the LaTeX emitted for daggered operators is grouped so exponentiation produces `{...}^{2}`), but it must be validated against existing printing conventions and potential regressions in other LaTeX cases. Writing targeted tests for `Bd(a)**2` inside `Commutator` and possibly related operator powers will take non-trivial time due to SymPy\u2019s extensive printing test suite patterns.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 75,\n    \"implementation\": 40,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:55.763304"}
{"instance_id": "sympy__sympy-24661", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "Although the user-facing symptom is simple, the fix requires understanding how `parse_expr(evaluate=False)` rewrites Python AST nodes and extending that machinery to handle `ast.Compare` (including chained comparisons) without triggering SymPy\u2019s automatic evaluation to `True/False`. Implementation is likely localized to the parser transformer logic, but needs careful handling of multiple comparison operators and ensuring behavior matches existing evaluation semantics elsewhere. Proper regression tests should cover `parse_expr` and `sympify` on simple and chained inequalities and verify no regressions in normal `evaluate=True` parsing.", "time_breakdown": {"understanding_and_investigation": 55, "implementation": 45, "testing_and_verification": 50}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"Although the user-facing symptom is simple, the fix requires understanding how `parse_expr(evaluate=False)` rewrites Python AST nodes and extending that machinery to handle `ast.Compare` (including chained comparisons) without triggering SymPy\u2019s automatic evaluation to `True/False`. Implementation is likely localized to the parser transformer logic, but needs careful handling of multiple comparison operators and ensuring behavior matches existing evaluation semantics elsewhere. Proper regression tests should cover `parse_expr` and `sympify` on simple and chained inequalities and verify no regressions in normal `evaluate=True` parsing.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 55,\n    \"implementation\": 45,\n    \"testing_and_verification\": 50\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "15 min - 1 hour", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:48:55.829299"}
{"instance_id": "sympy__sympy-19495", "repo": "sympy/sympy", "estimated_minutes": 180.0, "justification": "This issue appears to be a subtle substitution/scoping bug in how ConditionSet performs .subs when its base set is an ImageSet, likely involving bound-variable handling (alpha-renaming) and preventing accidental capture or mis-substitution of the ConditionSet\u2019s bound symbol. Reproducing the behavior is straightforward, but locating the exact point where ConditionSet rewrites its predicate (often into membership/Contains forms) and where subs introduces the wrong bound symbol will require moderate code investigation across SymPy\u2019s set and substitution internals. Implementing a correct fix will likely require adjusting ConditionSet._eval_subs (or related set substitution logic) to treat the bound symbol and ImageSet/Lambda dummy symbols correctly, plus adding regression tests for multiple substitution modes (plain subs, simultaneous=True, xreplace) to prevent regressions.", "time_breakdown": {"understanding_and_investigation": 85, "implementation": 55, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "challenging"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 180,\n  \"justification\": \"This issue appears to be a subtle substitution/scoping bug in how ConditionSet performs .subs when its base set is an ImageSet, likely involving bound-variable handling (alpha-renaming) and preventing accidental capture or mis-substitution of the ConditionSet\u2019s bound symbol. Reproducing the behavior is straightforward, but locating the exact point where ConditionSet rewrites its predicate (often into membership/Contains forms) and where subs introduces the wrong bound symbol will require moderate code investigation across SymPy\u2019s set and substitution internals. Implementing a correct fix will likely require adjusting ConditionSet._eval_subs (or related set substitution logic) to treat the bound symbol and ImageSet/Lambda dummy symbols correctly, plus adding regression tests for multiple substitution modes (plain subs, simultaneous=True, xreplace) to prevent regressions.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 85,\n    \"implementation\": 55,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"challenging\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:49:02.304205"}
{"instance_id": "sympy__sympy-22714", "repo": "sympy/sympy", "estimated_minutes": 150.0, "justification": "The issue is reproducible and narrowly scoped, but it sits at the intersection of sympify/parse_expr evaluation control and geometry object construction, so some time is needed to trace why `evaluate(False)` changes how `Integer` (and potentially other known classes) are resolved during parsing. The fix is likely small (ensuring the parser still resolves SymPy classes like `Integer` correctly, or avoiding inappropriate realness checks triggered by unevaluated parser results), but it requires careful validation to avoid breaking other `evaluate(False)` parsing behaviors. Adding a regression test and running relevant subsets of the test suite are necessary to ensure no regressions in parsing or geometry.", "time_breakdown": {"understanding_and_investigation": 70, "implementation": 40, "testing_and_verification": 40}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "simple", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "```json\n{\n  \"estimated_minutes\": 150,\n  \"justification\": \"The issue is reproducible and narrowly scoped, but it sits at the intersection of sympify/parse_expr evaluation control and geometry object construction, so some time is needed to trace why `evaluate(False)` changes how `Integer` (and potentially other known classes) are resolved during parsing. The fix is likely small (ensuring the parser still resolves SymPy classes like `Integer` correctly, or avoiding inappropriate realness checks triggered by unevaluated parser results), but it requires careful validation to avoid breaking other `evaluate(False)` parsing behaviors. Adding a regression test and running relevant subsets of the test suite are necessary to ensure no regressions in parsing or geometry.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 70,\n    \"implementation\": 40,\n    \"testing_and_verification\": 40\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"simple\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}\n```", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:49:06.338954"}
{"instance_id": "pytest-dev__pytest-10081", "repo": "pytest-dev/pytest", "estimated_minutes": 210.0, "justification": "Although the reproduction is clear, the failure involves an interaction between pytest\u2019s unittest integration and the --pdb debugging workflow, which typically requires tracing through runner/setup/teardown sequencing and any special-case logic for skipped items. Identifying why unittest.TestCase.tearDown is being invoked only under --pdb (and not in normal runs) will take moderate code investigation and debugging. The fix itself is likely small (guarding teardown execution for skipped unittest items or correcting the phase behavior), but adding a robust non-interactive regression test around --pdb behavior is comparatively time-consuming.", "time_breakdown": {"understanding_and_investigation": 90, "implementation": 50, "testing_and_verification": 70}, "complexity_indicators": {"code_investigation_needed": "moderate", "number_of_files_likely_affected": "2-3", "testing_complexity": "moderate", "domain_knowledge_required": "intermediate", "debugging_difficulty": "moderate"}, "model_used": "openai/gpt-5.2-2025-12-11", "raw_response": "{\n  \"estimated_minutes\": 210,\n  \"justification\": \"Although the reproduction is clear, the failure involves an interaction between pytest\u2019s unittest integration and the --pdb debugging workflow, which typically requires tracing through runner/setup/teardown sequencing and any special-case logic for skipped items. Identifying why unittest.TestCase.tearDown is being invoked only under --pdb (and not in normal runs) will take moderate code investigation and debugging. The fix itself is likely small (guarding teardown execution for skipped unittest items or correcting the phase behavior), but adding a robust non-interactive regression test around --pdb behavior is comparatively time-consuming.\",\n  \"time_breakdown\": {\n    \"understanding_and_investigation\": 90,\n    \"implementation\": 50,\n    \"testing_and_verification\": 70\n  },\n  \"complexity_indicators\": {\n    \"code_investigation_needed\": \"moderate\",\n    \"number_of_files_likely_affected\": \"2-3\",\n    \"testing_complexity\": \"moderate\",\n    \"domain_knowledge_required\": \"intermediate\",\n    \"debugging_difficulty\": \"moderate\"\n  }\n}", "ground_truth_difficulty": "<15 min fix", "estimated_bucket": "1-4 hours", "processed_at": "2026-01-23T17:49:06.941175"}
